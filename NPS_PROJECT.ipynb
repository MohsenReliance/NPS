{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Bxim82lMi0mt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier, DMatrix\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import spacy\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from spacy.tokens import DocBin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_columns(row):\n",
        "    return ' '.join(str(cell) for cell in row if not pd.isna(cell))"
      ],
      "metadata": {
        "id": "_W1iNzPPjWmJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NPS_CATEGORIES = pd.read_csv('/content/Categorization_NPS_DATA.csv', header = 1)\n",
        "CORP_ENROLEES_RESPONSES = pd.read_csv('/content/CORP_ENROLLEES_NPS.csv')"
      ],
      "metadata": {
        "id": "NAoBg5bLi-e5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NPS_CATEGORIES_COI = NPS_CATEGORIES[['Response ID', 'Broad Category', 'Sub-driver']]\n",
        "CORP_ENROLEES_RESPONSES_COI = CORP_ENROLEES_RESPONSES[['Response ID', 'We are sorry. Please tell us why you chose that rating.',\n",
        "       '   Amazing. Please, tell us why you chose that rating.',\n",
        "       '   Please tell us why you chose that rating.']]\n",
        "\n",
        "CORP_ENROLLEES_NPS = pd.merge(CORP_ENROLEES_RESPONSES_COI, NPS_CATEGORIES_COI,\n",
        "                              left_on  = 'Response ID', right_on = 'Response ID')"
      ],
      "metadata": {
        "id": "1G_3w0qejB_I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CORP_ENROLLEES_NPS['CUSTOMER_RESPONSE'] = CORP_ENROLLEES_NPS[['We are sorry. Please tell us why you chose that rating.',\n",
        "       '   Amazing. Please, tell us why you chose that rating.',\n",
        "       '   Please tell us why you chose that rating.']].apply(merge_columns, axis=1)\n",
        "CORP_ENROLLEES_NPS.drop(columns=['We are sorry. Please tell us why you chose that rating.',\n",
        "       '   Amazing. Please, tell us why you chose that rating.',\n",
        "       '   Please tell us why you chose that rating.'], inplace=True)"
      ],
      "metadata": {
        "id": "8T3C3Bf-jXo1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CORP_ENROLLEES_NPS = CORP_ENROLLEES_NPS[CORP_ENROLLEES_NPS['Broad Category'].notna()]"
      ],
      "metadata": {
        "id": "sbdtM1pcjbpq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CORP_ENROLLEES_NPS['Broad Category'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvJE9ouQjdj0",
        "outputId": "c7554076-6404-4886-ef98-d88ef6e69bc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Poor RCC Quality', 'Good RCC Quality',\n",
              "       'Adequate provider network', 'Great Service',\n",
              "       'Poor Provider Quality', 'Good Provider Quality',\n",
              "       'Delayed Medication Pickup', 'Limited Health Coverage',\n",
              "       'Good consultation attitude', 'Poor customer education',\n",
              "       'Limited Provider Network', 'Long Provider Wait Time',\n",
              "       'Good listening skills', 'Delayed Medication Delivery',\n",
              "       'Great Telemedicine', 'Care Denial', 'Test result delay',\n",
              "       'Tariff issue', 'Quick medication delivery', 'Good staff attitude',\n",
              "       'Delayed medication delivery', 'Poor provider quality',\n",
              "       'Refund issue', 'No medication delivery', 'Telemedicine',\n",
              "       'Receipt of feedback', 'Limited health coverage', 'Care denial',\n",
              "       'Clean environment', 'Poor RCC quality',\n",
              "       'Poor provider onboarding process', 'Sufficient Health Coverage',\n",
              "       'Long provider wait time', 'Affordable care', 'Delayed refund',\n",
              "       'Broad Provider Network', 'Onboarding issue',\n",
              "       'Short Provider Wait Time', 'Medication Quality',\n",
              "       'Great telemedicine', 'Onboarding family issue', 'App issues',\n",
              "       'Poor service', 'Poor verification'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapping data to Topics.\n",
        "==========================="
      ],
      "metadata": {
        "id": "pjyQPUM1jrJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merging Rationale:\n",
        "- Healthcare Service Quality: Merges 'Quality of Care' and 'Service Aspects' as both relate to the patient's experience and satisfaction with the healthcare service's quality and responsiveness.\n",
        "\n",
        "- Healthcare Access and Infrastructure: Combines 'Provider Network' and 'Coverage' as both are crucial for ensuring access to healthcare services and can often intersect in discussions about what services are accessible and under what conditions.\n",
        "\n",
        "- Healthcare Administration: Keeps as a separate category since administrative issues might span various aspects, from paperwork to processing times, that are not directly related to the quality or access but to the efficiency and experience of healthcare administration.\n",
        "\n",
        "- Telemedicine: Keeps as a separted category as we need to segment the issues related to our telemedicine services.\n",
        "\n",
        "- Medication Related issues: This is related to the medication quality and medication delievery.\n",
        "\n",
        "By merging these labels, we focus on broader, more impactful categories that can help in analyzing the data more effectively, especially if the original labels are too granular or if there's considerable overlap in the context they represent"
      ],
      "metadata": {
        "id": "dlvnwsKFjti6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mapping of labels to new categories\n",
        "label_mapping = {\n",
        "    **dict.fromkeys(['Good RCC Quality', 'Good Provider Quality', 'Good consultation attitude', 'Good listening skills', 'Good staff attitude'], 'Quality of Care'),\n",
        "    **dict.fromkeys(['Poor RCC Quality', 'Poor RCC quality', 'Poor Provider Quality', 'Poor customer education', 'Poor provider quality', 'Poor service'], 'Quality of Care'),\n",
        "    **dict.fromkeys(['Great Service', 'Great Telemedicine', 'Great telemedicine', 'Clean environment', 'Receipt of feedback'], 'Service Aspects'),\n",
        "    **dict.fromkeys(['Care Denial', 'Care denial', 'Delayed Refund', 'Poor verification'], 'Service Aspects'),\n",
        "    **dict.fromkeys(['Adequate provider network', 'Broad Provider Network'], 'Provider Network'),\n",
        "    **dict.fromkeys(['Limited Provider Network', 'Limited provider network'], 'Provider Network'),\n",
        "    **dict.fromkeys(['Delayed Medication Pickup', 'Delayed Medication Delivery', 'Delayed medication delivery', 'Quick medication delivery', 'No medication delivery'], 'Medication-Related Issues'),\n",
        "    'Medication Quality': 'Medication-Related Issues',\n",
        "    **dict.fromkeys(['Telemedicine', 'Great Telemedicine', 'Great telemedicine'], 'Telemedicine'),\n",
        "    **dict.fromkeys(['Sufficient Health Coverage', 'Affordable care'], 'Coverage'),\n",
        "    **dict.fromkeys(['Limited Health Coverage', 'Limited health coverage'], 'Coverage'),\n",
        "    **dict.fromkeys(['Long Provider Wait Time', 'Long provider wait time', 'Short Provider Wait Time', 'Poor provider onboarding process', 'Onboarding issue', 'Onboarding family issue', 'Receipt of feedback', 'Test result delay'], 'Administrative and Process Issues'),\n",
        "    **dict.fromkeys(['Tariff issue', 'Refund issue', 'Delayed refund'], 'Administrative and Process Issues'),\n",
        "    'App issues': 'Service Aspects'\n",
        "}\n",
        "\n",
        "# Replacing the original labels with the new categories in the DataFrame\n",
        "CORP_ENROLLEES_NPS['Main Topics'] = CORP_ENROLLEES_NPS['Broad Category'].replace(label_mapping)"
      ],
      "metadata": {
        "id": "gKA0EH9Ejkus"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {\n",
        "    'Administrative and Process Issues': 'Healthcare Administration',\n",
        "    'Coverage': 'Healthcare Access and Infrastructure',\n",
        "    'Medication-Related Issues': 'Medication-Related Issues',\n",
        "    'Provider Network': 'Healthcare Access and Infrastructure',\n",
        "    'Quality of Care': 'Healthcare Service Quality',\n",
        "    'Service Aspects': 'Healthcare Service Quality',\n",
        "    'Telemedicine': 'Telemedicine'\n",
        "}\n",
        "\n",
        "# Apply the mapping to create a new column with merged labels\n",
        "CORP_ENROLLEES_NPS['Merged Label'] = CORP_ENROLLEES_NPS['Main Topics'].map(label_mapping)"
      ],
      "metadata": {
        "id": "NF5MsyzOjz2p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CORP_ENROLLEES_NPS['Merged Label'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWU2X0h_j_Pm",
        "outputId": "1239257e-c87f-4521-a285-e92cb6066eb9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Healthcare Service Quality',\n",
              "       'Healthcare Access and Infrastructure',\n",
              "       'Medication-Related Issues', 'Healthcare Administration',\n",
              "       'Telemedicine'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "def clean_text(text):\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize\n",
        "    tokens = text.split()\n",
        "    # Remove stopwords and lemmatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords.words('english')]\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtQ7aO2QkCx_",
        "outputId": "f2b5be3c-6b54-47f5-c12a-f8f18790d72b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CORP_ENROLLEES_NPS['Clean_Response'] = [clean_text(text) for text in CORP_ENROLLEES_NPS['CUSTOMER_RESPONSE']]"
      ],
      "metadata": {
        "id": "UcjhbZVGkbaa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelling"
      ],
      "metadata": {
        "id": "gk6ke7bKkgPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "CORP_ENROLLEES_NPS['category_encoded'] = label_encoder.fit_transform(CORP_ENROLLEES_NPS['Merged Label'])\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
        "clean_vectors = vectorizer.fit_transform(CORP_ENROLLEES_NPS['Clean_Response'])"
      ],
      "metadata": {
        "id": "bIGnQsRtkd6n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(use_label_encoder=False)\n",
        "param_grid = {'objective': 'multi:softprob', 'num_class': 5, 'min_child_weight': 5, 'max_depth': 7, 'learning_rate': 0.01, 'lambda': 1, 'gamma': 0, 'eval_metric': 'mlogloss', 'colsample_bytree': 0.7, 'alpha': 0}"
      ],
      "metadata": {
        "id": "Rh8sZKuLkx2M"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(clean_vectors, CORP_ENROLLEES_NPS['category_encoded'], test_size=0.2)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "dtrain = DMatrix(X_train2, label=y_train2)\n",
        "dtest = DMatrix(X_test2, label=y_test2)\n",
        "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "dtrain = DMatrix(X_train2, label=y_train2)\n",
        "dtest = DMatrix(X_test2, label=y_test2)\n",
        "evallist = [(dtrain, 'train'), (dtest, 'eval')]"
      ],
      "metadata": {
        "id": "VHXesp4Lk9d_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = xgb.train(\n",
        "                param_grid\n",
        "                ,dtrain\n",
        "                ,evals = evallist\n",
        "                ,num_boost_round=2000\n",
        "                ,early_stopping_rounds=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c2KnPdSlGCW",
        "outputId": "b3b66323-a5cf-47af-eefc-89d79d4ce3ef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.59411\teval-mlogloss:1.59521\n",
            "[1]\ttrain-mlogloss:1.57831\teval-mlogloss:1.58102\n",
            "[2]\ttrain-mlogloss:1.56314\teval-mlogloss:1.56720\n",
            "[3]\ttrain-mlogloss:1.54804\teval-mlogloss:1.55327\n",
            "[4]\ttrain-mlogloss:1.53503\teval-mlogloss:1.54121\n",
            "[5]\ttrain-mlogloss:1.52162\teval-mlogloss:1.52912\n",
            "[6]\ttrain-mlogloss:1.50731\teval-mlogloss:1.51590\n",
            "[7]\ttrain-mlogloss:1.49421\teval-mlogloss:1.50401\n",
            "[8]\ttrain-mlogloss:1.48055\teval-mlogloss:1.49138\n",
            "[9]\ttrain-mlogloss:1.46793\teval-mlogloss:1.47983\n",
            "[10]\ttrain-mlogloss:1.45516\teval-mlogloss:1.46811\n",
            "[11]\ttrain-mlogloss:1.44260\teval-mlogloss:1.45645\n",
            "[12]\ttrain-mlogloss:1.43015\teval-mlogloss:1.44488\n",
            "[13]\ttrain-mlogloss:1.41833\teval-mlogloss:1.43394\n",
            "[14]\ttrain-mlogloss:1.40672\teval-mlogloss:1.42347\n",
            "[15]\ttrain-mlogloss:1.39440\teval-mlogloss:1.41228\n",
            "[16]\ttrain-mlogloss:1.38266\teval-mlogloss:1.40171\n",
            "[17]\ttrain-mlogloss:1.37214\teval-mlogloss:1.39227\n",
            "[18]\ttrain-mlogloss:1.36099\teval-mlogloss:1.38230\n",
            "[19]\ttrain-mlogloss:1.34994\teval-mlogloss:1.37224\n",
            "[20]\ttrain-mlogloss:1.33878\teval-mlogloss:1.36223\n",
            "[21]\ttrain-mlogloss:1.32772\teval-mlogloss:1.35224\n",
            "[22]\ttrain-mlogloss:1.31739\teval-mlogloss:1.34275\n",
            "[23]\ttrain-mlogloss:1.30727\teval-mlogloss:1.33377\n",
            "[24]\ttrain-mlogloss:1.29690\teval-mlogloss:1.32462\n",
            "[25]\ttrain-mlogloss:1.28710\teval-mlogloss:1.31600\n",
            "[26]\ttrain-mlogloss:1.27768\teval-mlogloss:1.30760\n",
            "[27]\ttrain-mlogloss:1.26854\teval-mlogloss:1.29930\n",
            "[28]\ttrain-mlogloss:1.25912\teval-mlogloss:1.29076\n",
            "[29]\ttrain-mlogloss:1.25001\teval-mlogloss:1.28253\n",
            "[30]\ttrain-mlogloss:1.24051\teval-mlogloss:1.27406\n",
            "[31]\ttrain-mlogloss:1.23179\teval-mlogloss:1.26632\n",
            "[32]\ttrain-mlogloss:1.22279\teval-mlogloss:1.25825\n",
            "[33]\ttrain-mlogloss:1.21365\teval-mlogloss:1.24999\n",
            "[34]\ttrain-mlogloss:1.20490\teval-mlogloss:1.24236\n",
            "[35]\ttrain-mlogloss:1.19669\teval-mlogloss:1.23521\n",
            "[36]\ttrain-mlogloss:1.18805\teval-mlogloss:1.22768\n",
            "[37]\ttrain-mlogloss:1.17956\teval-mlogloss:1.22002\n",
            "[38]\ttrain-mlogloss:1.17131\teval-mlogloss:1.21290\n",
            "[39]\ttrain-mlogloss:1.16312\teval-mlogloss:1.20551\n",
            "[40]\ttrain-mlogloss:1.15503\teval-mlogloss:1.19842\n",
            "[41]\ttrain-mlogloss:1.14755\teval-mlogloss:1.19206\n",
            "[42]\ttrain-mlogloss:1.13957\teval-mlogloss:1.18524\n",
            "[43]\ttrain-mlogloss:1.13177\teval-mlogloss:1.17840\n",
            "[44]\ttrain-mlogloss:1.12378\teval-mlogloss:1.17127\n",
            "[45]\ttrain-mlogloss:1.11647\teval-mlogloss:1.16504\n",
            "[46]\ttrain-mlogloss:1.10881\teval-mlogloss:1.15820\n",
            "[47]\ttrain-mlogloss:1.10126\teval-mlogloss:1.15161\n",
            "[48]\ttrain-mlogloss:1.09421\teval-mlogloss:1.14556\n",
            "[49]\ttrain-mlogloss:1.08685\teval-mlogloss:1.13891\n",
            "[50]\ttrain-mlogloss:1.08043\teval-mlogloss:1.13349\n",
            "[51]\ttrain-mlogloss:1.07352\teval-mlogloss:1.12749\n",
            "[52]\ttrain-mlogloss:1.06658\teval-mlogloss:1.12121\n",
            "[53]\ttrain-mlogloss:1.06026\teval-mlogloss:1.11576\n",
            "[54]\ttrain-mlogloss:1.05370\teval-mlogloss:1.10997\n",
            "[55]\ttrain-mlogloss:1.04707\teval-mlogloss:1.10407\n",
            "[56]\ttrain-mlogloss:1.04057\teval-mlogloss:1.09843\n",
            "[57]\ttrain-mlogloss:1.03387\teval-mlogloss:1.09264\n",
            "[58]\ttrain-mlogloss:1.02788\teval-mlogloss:1.08743\n",
            "[59]\ttrain-mlogloss:1.02132\teval-mlogloss:1.08155\n",
            "[60]\ttrain-mlogloss:1.01547\teval-mlogloss:1.07642\n",
            "[61]\ttrain-mlogloss:1.00977\teval-mlogloss:1.07146\n",
            "[62]\ttrain-mlogloss:1.00378\teval-mlogloss:1.06623\n",
            "[63]\ttrain-mlogloss:0.99757\teval-mlogloss:1.06083\n",
            "[64]\ttrain-mlogloss:0.99157\teval-mlogloss:1.05580\n",
            "[65]\ttrain-mlogloss:0.98561\teval-mlogloss:1.05051\n",
            "[66]\ttrain-mlogloss:0.97983\teval-mlogloss:1.04536\n",
            "[67]\ttrain-mlogloss:0.97430\teval-mlogloss:1.04067\n",
            "[68]\ttrain-mlogloss:0.96842\teval-mlogloss:1.03553\n",
            "[69]\ttrain-mlogloss:0.96299\teval-mlogloss:1.03071\n",
            "[70]\ttrain-mlogloss:0.95728\teval-mlogloss:1.02574\n",
            "[71]\ttrain-mlogloss:0.95214\teval-mlogloss:1.02133\n",
            "[72]\ttrain-mlogloss:0.94714\teval-mlogloss:1.01685\n",
            "[73]\ttrain-mlogloss:0.94179\teval-mlogloss:1.01200\n",
            "[74]\ttrain-mlogloss:0.93651\teval-mlogloss:1.00764\n",
            "[75]\ttrain-mlogloss:0.93110\teval-mlogloss:1.00311\n",
            "[76]\ttrain-mlogloss:0.92571\teval-mlogloss:0.99855\n",
            "[77]\ttrain-mlogloss:0.92042\teval-mlogloss:0.99404\n",
            "[78]\ttrain-mlogloss:0.91542\teval-mlogloss:0.98965\n",
            "[79]\ttrain-mlogloss:0.91086\teval-mlogloss:0.98573\n",
            "[80]\ttrain-mlogloss:0.90585\teval-mlogloss:0.98148\n",
            "[81]\ttrain-mlogloss:0.90137\teval-mlogloss:0.97800\n",
            "[82]\ttrain-mlogloss:0.89648\teval-mlogloss:0.97386\n",
            "[83]\ttrain-mlogloss:0.89193\teval-mlogloss:0.96996\n",
            "[84]\ttrain-mlogloss:0.88726\teval-mlogloss:0.96596\n",
            "[85]\ttrain-mlogloss:0.88265\teval-mlogloss:0.96206\n",
            "[86]\ttrain-mlogloss:0.87804\teval-mlogloss:0.95820\n",
            "[87]\ttrain-mlogloss:0.87333\teval-mlogloss:0.95416\n",
            "[88]\ttrain-mlogloss:0.86882\teval-mlogloss:0.95021\n",
            "[89]\ttrain-mlogloss:0.86428\teval-mlogloss:0.94655\n",
            "[90]\ttrain-mlogloss:0.85976\teval-mlogloss:0.94261\n",
            "[91]\ttrain-mlogloss:0.85519\teval-mlogloss:0.93874\n",
            "[92]\ttrain-mlogloss:0.85075\teval-mlogloss:0.93494\n",
            "[93]\ttrain-mlogloss:0.84686\teval-mlogloss:0.93173\n",
            "[94]\ttrain-mlogloss:0.84259\teval-mlogloss:0.92813\n",
            "[95]\ttrain-mlogloss:0.83832\teval-mlogloss:0.92463\n",
            "[96]\ttrain-mlogloss:0.83396\teval-mlogloss:0.92087\n",
            "[97]\ttrain-mlogloss:0.82954\teval-mlogloss:0.91724\n",
            "[98]\ttrain-mlogloss:0.82529\teval-mlogloss:0.91372\n",
            "[99]\ttrain-mlogloss:0.82138\teval-mlogloss:0.91054\n",
            "[100]\ttrain-mlogloss:0.81765\teval-mlogloss:0.90732\n",
            "[101]\ttrain-mlogloss:0.81344\teval-mlogloss:0.90402\n",
            "[102]\ttrain-mlogloss:0.80956\teval-mlogloss:0.90107\n",
            "[103]\ttrain-mlogloss:0.80583\teval-mlogloss:0.89805\n",
            "[104]\ttrain-mlogloss:0.80173\teval-mlogloss:0.89462\n",
            "[105]\ttrain-mlogloss:0.79774\teval-mlogloss:0.89127\n",
            "[106]\ttrain-mlogloss:0.79416\teval-mlogloss:0.88831\n",
            "[107]\ttrain-mlogloss:0.79025\teval-mlogloss:0.88505\n",
            "[108]\ttrain-mlogloss:0.78662\teval-mlogloss:0.88204\n",
            "[109]\ttrain-mlogloss:0.78302\teval-mlogloss:0.87913\n",
            "[110]\ttrain-mlogloss:0.77919\teval-mlogloss:0.87580\n",
            "[111]\ttrain-mlogloss:0.77563\teval-mlogloss:0.87273\n",
            "[112]\ttrain-mlogloss:0.77240\teval-mlogloss:0.87014\n",
            "[113]\ttrain-mlogloss:0.76871\teval-mlogloss:0.86728\n",
            "[114]\ttrain-mlogloss:0.76519\teval-mlogloss:0.86433\n",
            "[115]\ttrain-mlogloss:0.76166\teval-mlogloss:0.86132\n",
            "[116]\ttrain-mlogloss:0.75808\teval-mlogloss:0.85853\n",
            "[117]\ttrain-mlogloss:0.75492\teval-mlogloss:0.85585\n",
            "[118]\ttrain-mlogloss:0.75157\teval-mlogloss:0.85280\n",
            "[119]\ttrain-mlogloss:0.74833\teval-mlogloss:0.85012\n",
            "[120]\ttrain-mlogloss:0.74524\teval-mlogloss:0.84788\n",
            "[121]\ttrain-mlogloss:0.74205\teval-mlogloss:0.84534\n",
            "[122]\ttrain-mlogloss:0.73871\teval-mlogloss:0.84279\n",
            "[123]\ttrain-mlogloss:0.73565\teval-mlogloss:0.84035\n",
            "[124]\ttrain-mlogloss:0.73245\teval-mlogloss:0.83794\n",
            "[125]\ttrain-mlogloss:0.72916\teval-mlogloss:0.83519\n",
            "[126]\ttrain-mlogloss:0.72631\teval-mlogloss:0.83311\n",
            "[127]\ttrain-mlogloss:0.72324\teval-mlogloss:0.83081\n",
            "[128]\ttrain-mlogloss:0.72028\teval-mlogloss:0.82864\n",
            "[129]\ttrain-mlogloss:0.71705\teval-mlogloss:0.82606\n",
            "[130]\ttrain-mlogloss:0.71395\teval-mlogloss:0.82342\n",
            "[131]\ttrain-mlogloss:0.71113\teval-mlogloss:0.82112\n",
            "[132]\ttrain-mlogloss:0.70804\teval-mlogloss:0.81851\n",
            "[133]\ttrain-mlogloss:0.70530\teval-mlogloss:0.81638\n",
            "[134]\ttrain-mlogloss:0.70269\teval-mlogloss:0.81445\n",
            "[135]\ttrain-mlogloss:0.69978\teval-mlogloss:0.81216\n",
            "[136]\ttrain-mlogloss:0.69696\teval-mlogloss:0.80992\n",
            "[137]\ttrain-mlogloss:0.69416\teval-mlogloss:0.80773\n",
            "[138]\ttrain-mlogloss:0.69147\teval-mlogloss:0.80572\n",
            "[139]\ttrain-mlogloss:0.68878\teval-mlogloss:0.80367\n",
            "[140]\ttrain-mlogloss:0.68632\teval-mlogloss:0.80193\n",
            "[141]\ttrain-mlogloss:0.68367\teval-mlogloss:0.79987\n",
            "[142]\ttrain-mlogloss:0.68108\teval-mlogloss:0.79766\n",
            "[143]\ttrain-mlogloss:0.67863\teval-mlogloss:0.79576\n",
            "[144]\ttrain-mlogloss:0.67596\teval-mlogloss:0.79347\n",
            "[145]\ttrain-mlogloss:0.67337\teval-mlogloss:0.79128\n",
            "[146]\ttrain-mlogloss:0.67061\teval-mlogloss:0.78903\n",
            "[147]\ttrain-mlogloss:0.66803\teval-mlogloss:0.78687\n",
            "[148]\ttrain-mlogloss:0.66537\teval-mlogloss:0.78470\n",
            "[149]\ttrain-mlogloss:0.66279\teval-mlogloss:0.78262\n",
            "[150]\ttrain-mlogloss:0.66036\teval-mlogloss:0.78095\n",
            "[151]\ttrain-mlogloss:0.65775\teval-mlogloss:0.77889\n",
            "[152]\ttrain-mlogloss:0.65514\teval-mlogloss:0.77698\n",
            "[153]\ttrain-mlogloss:0.65276\teval-mlogloss:0.77504\n",
            "[154]\ttrain-mlogloss:0.65041\teval-mlogloss:0.77329\n",
            "[155]\ttrain-mlogloss:0.64791\teval-mlogloss:0.77142\n",
            "[156]\ttrain-mlogloss:0.64554\teval-mlogloss:0.76957\n",
            "[157]\ttrain-mlogloss:0.64316\teval-mlogloss:0.76796\n",
            "[158]\ttrain-mlogloss:0.64076\teval-mlogloss:0.76621\n",
            "[159]\ttrain-mlogloss:0.63848\teval-mlogloss:0.76450\n",
            "[160]\ttrain-mlogloss:0.63628\teval-mlogloss:0.76295\n",
            "[161]\ttrain-mlogloss:0.63399\teval-mlogloss:0.76124\n",
            "[162]\ttrain-mlogloss:0.63188\teval-mlogloss:0.75957\n",
            "[163]\ttrain-mlogloss:0.62958\teval-mlogloss:0.75776\n",
            "[164]\ttrain-mlogloss:0.62723\teval-mlogloss:0.75606\n",
            "[165]\ttrain-mlogloss:0.62497\teval-mlogloss:0.75464\n",
            "[166]\ttrain-mlogloss:0.62275\teval-mlogloss:0.75294\n",
            "[167]\ttrain-mlogloss:0.62062\teval-mlogloss:0.75129\n",
            "[168]\ttrain-mlogloss:0.61847\teval-mlogloss:0.74974\n",
            "[169]\ttrain-mlogloss:0.61634\teval-mlogloss:0.74809\n",
            "[170]\ttrain-mlogloss:0.61417\teval-mlogloss:0.74639\n",
            "[171]\ttrain-mlogloss:0.61206\teval-mlogloss:0.74467\n",
            "[172]\ttrain-mlogloss:0.61004\teval-mlogloss:0.74332\n",
            "[173]\ttrain-mlogloss:0.60790\teval-mlogloss:0.74174\n",
            "[174]\ttrain-mlogloss:0.60597\teval-mlogloss:0.74037\n",
            "[175]\ttrain-mlogloss:0.60398\teval-mlogloss:0.73885\n",
            "[176]\ttrain-mlogloss:0.60188\teval-mlogloss:0.73725\n",
            "[177]\ttrain-mlogloss:0.59999\teval-mlogloss:0.73588\n",
            "[178]\ttrain-mlogloss:0.59806\teval-mlogloss:0.73473\n",
            "[179]\ttrain-mlogloss:0.59606\teval-mlogloss:0.73325\n",
            "[180]\ttrain-mlogloss:0.59419\teval-mlogloss:0.73196\n",
            "[181]\ttrain-mlogloss:0.59227\teval-mlogloss:0.73045\n",
            "[182]\ttrain-mlogloss:0.59030\teval-mlogloss:0.72892\n",
            "[183]\ttrain-mlogloss:0.58841\teval-mlogloss:0.72783\n",
            "[184]\ttrain-mlogloss:0.58658\teval-mlogloss:0.72650\n",
            "[185]\ttrain-mlogloss:0.58468\teval-mlogloss:0.72510\n",
            "[186]\ttrain-mlogloss:0.58293\teval-mlogloss:0.72388\n",
            "[187]\ttrain-mlogloss:0.58127\teval-mlogloss:0.72277\n",
            "[188]\ttrain-mlogloss:0.57958\teval-mlogloss:0.72163\n",
            "[189]\ttrain-mlogloss:0.57787\teval-mlogloss:0.72024\n",
            "[190]\ttrain-mlogloss:0.57618\teval-mlogloss:0.71911\n",
            "[191]\ttrain-mlogloss:0.57448\teval-mlogloss:0.71780\n",
            "[192]\ttrain-mlogloss:0.57268\teval-mlogloss:0.71637\n",
            "[193]\ttrain-mlogloss:0.57102\teval-mlogloss:0.71528\n",
            "[194]\ttrain-mlogloss:0.56918\teval-mlogloss:0.71407\n",
            "[195]\ttrain-mlogloss:0.56743\teval-mlogloss:0.71263\n",
            "[196]\ttrain-mlogloss:0.56576\teval-mlogloss:0.71153\n",
            "[197]\ttrain-mlogloss:0.56405\teval-mlogloss:0.71028\n",
            "[198]\ttrain-mlogloss:0.56245\teval-mlogloss:0.70924\n",
            "[199]\ttrain-mlogloss:0.56080\teval-mlogloss:0.70816\n",
            "[200]\ttrain-mlogloss:0.55947\teval-mlogloss:0.70742\n",
            "[201]\ttrain-mlogloss:0.55770\teval-mlogloss:0.70605\n",
            "[202]\ttrain-mlogloss:0.55603\teval-mlogloss:0.70475\n",
            "[203]\ttrain-mlogloss:0.55442\teval-mlogloss:0.70360\n",
            "[204]\ttrain-mlogloss:0.55290\teval-mlogloss:0.70273\n",
            "[205]\ttrain-mlogloss:0.55127\teval-mlogloss:0.70140\n",
            "[206]\ttrain-mlogloss:0.54967\teval-mlogloss:0.70021\n",
            "[207]\ttrain-mlogloss:0.54806\teval-mlogloss:0.69911\n",
            "[208]\ttrain-mlogloss:0.54651\teval-mlogloss:0.69808\n",
            "[209]\ttrain-mlogloss:0.54510\teval-mlogloss:0.69729\n",
            "[210]\ttrain-mlogloss:0.54363\teval-mlogloss:0.69639\n",
            "[211]\ttrain-mlogloss:0.54212\teval-mlogloss:0.69535\n",
            "[212]\ttrain-mlogloss:0.54067\teval-mlogloss:0.69444\n",
            "[213]\ttrain-mlogloss:0.53918\teval-mlogloss:0.69339\n",
            "[214]\ttrain-mlogloss:0.53760\teval-mlogloss:0.69228\n",
            "[215]\ttrain-mlogloss:0.53619\teval-mlogloss:0.69134\n",
            "[216]\ttrain-mlogloss:0.53476\teval-mlogloss:0.69042\n",
            "[217]\ttrain-mlogloss:0.53327\teval-mlogloss:0.68948\n",
            "[218]\ttrain-mlogloss:0.53184\teval-mlogloss:0.68833\n",
            "[219]\ttrain-mlogloss:0.53043\teval-mlogloss:0.68740\n",
            "[220]\ttrain-mlogloss:0.52898\teval-mlogloss:0.68624\n",
            "[221]\ttrain-mlogloss:0.52765\teval-mlogloss:0.68550\n",
            "[222]\ttrain-mlogloss:0.52611\teval-mlogloss:0.68452\n",
            "[223]\ttrain-mlogloss:0.52476\teval-mlogloss:0.68377\n",
            "[224]\ttrain-mlogloss:0.52338\teval-mlogloss:0.68286\n",
            "[225]\ttrain-mlogloss:0.52194\teval-mlogloss:0.68190\n",
            "[226]\ttrain-mlogloss:0.52071\teval-mlogloss:0.68085\n",
            "[227]\ttrain-mlogloss:0.51935\teval-mlogloss:0.67988\n",
            "[228]\ttrain-mlogloss:0.51802\teval-mlogloss:0.67888\n",
            "[229]\ttrain-mlogloss:0.51684\teval-mlogloss:0.67836\n",
            "[230]\ttrain-mlogloss:0.51566\teval-mlogloss:0.67758\n",
            "[231]\ttrain-mlogloss:0.51435\teval-mlogloss:0.67676\n",
            "[232]\ttrain-mlogloss:0.51306\teval-mlogloss:0.67599\n",
            "[233]\ttrain-mlogloss:0.51183\teval-mlogloss:0.67528\n",
            "[234]\ttrain-mlogloss:0.51054\teval-mlogloss:0.67455\n",
            "[235]\ttrain-mlogloss:0.50929\teval-mlogloss:0.67361\n",
            "[236]\ttrain-mlogloss:0.50797\teval-mlogloss:0.67255\n",
            "[237]\ttrain-mlogloss:0.50673\teval-mlogloss:0.67176\n",
            "[238]\ttrain-mlogloss:0.50552\teval-mlogloss:0.67091\n",
            "[239]\ttrain-mlogloss:0.50426\teval-mlogloss:0.67020\n",
            "[240]\ttrain-mlogloss:0.50307\teval-mlogloss:0.66955\n",
            "[241]\ttrain-mlogloss:0.50194\teval-mlogloss:0.66893\n",
            "[242]\ttrain-mlogloss:0.50086\teval-mlogloss:0.66810\n",
            "[243]\ttrain-mlogloss:0.49964\teval-mlogloss:0.66742\n",
            "[244]\ttrain-mlogloss:0.49844\teval-mlogloss:0.66659\n",
            "[245]\ttrain-mlogloss:0.49727\teval-mlogloss:0.66594\n",
            "[246]\ttrain-mlogloss:0.49611\teval-mlogloss:0.66537\n",
            "[247]\ttrain-mlogloss:0.49495\teval-mlogloss:0.66455\n",
            "[248]\ttrain-mlogloss:0.49382\teval-mlogloss:0.66377\n",
            "[249]\ttrain-mlogloss:0.49275\teval-mlogloss:0.66316\n",
            "[250]\ttrain-mlogloss:0.49161\teval-mlogloss:0.66248\n",
            "[251]\ttrain-mlogloss:0.49044\teval-mlogloss:0.66190\n",
            "[252]\ttrain-mlogloss:0.48941\teval-mlogloss:0.66101\n",
            "[253]\ttrain-mlogloss:0.48837\teval-mlogloss:0.66052\n",
            "[254]\ttrain-mlogloss:0.48722\teval-mlogloss:0.65972\n",
            "[255]\ttrain-mlogloss:0.48616\teval-mlogloss:0.65916\n",
            "[256]\ttrain-mlogloss:0.48507\teval-mlogloss:0.65834\n",
            "[257]\ttrain-mlogloss:0.48394\teval-mlogloss:0.65762\n",
            "[258]\ttrain-mlogloss:0.48285\teval-mlogloss:0.65708\n",
            "[259]\ttrain-mlogloss:0.48177\teval-mlogloss:0.65643\n",
            "[260]\ttrain-mlogloss:0.48078\teval-mlogloss:0.65572\n",
            "[261]\ttrain-mlogloss:0.47974\teval-mlogloss:0.65509\n",
            "[262]\ttrain-mlogloss:0.47876\teval-mlogloss:0.65455\n",
            "[263]\ttrain-mlogloss:0.47774\teval-mlogloss:0.65372\n",
            "[264]\ttrain-mlogloss:0.47669\teval-mlogloss:0.65306\n",
            "[265]\ttrain-mlogloss:0.47566\teval-mlogloss:0.65259\n",
            "[266]\ttrain-mlogloss:0.47457\teval-mlogloss:0.65197\n",
            "[267]\ttrain-mlogloss:0.47356\teval-mlogloss:0.65132\n",
            "[268]\ttrain-mlogloss:0.47259\teval-mlogloss:0.65045\n",
            "[269]\ttrain-mlogloss:0.47165\teval-mlogloss:0.65005\n",
            "[270]\ttrain-mlogloss:0.47075\teval-mlogloss:0.64964\n",
            "[271]\ttrain-mlogloss:0.46977\teval-mlogloss:0.64891\n",
            "[272]\ttrain-mlogloss:0.46879\teval-mlogloss:0.64831\n",
            "[273]\ttrain-mlogloss:0.46784\teval-mlogloss:0.64779\n",
            "[274]\ttrain-mlogloss:0.46688\teval-mlogloss:0.64717\n",
            "[275]\ttrain-mlogloss:0.46592\teval-mlogloss:0.64677\n",
            "[276]\ttrain-mlogloss:0.46499\teval-mlogloss:0.64618\n",
            "[277]\ttrain-mlogloss:0.46412\teval-mlogloss:0.64585\n",
            "[278]\ttrain-mlogloss:0.46316\teval-mlogloss:0.64529\n",
            "[279]\ttrain-mlogloss:0.46225\teval-mlogloss:0.64474\n",
            "[280]\ttrain-mlogloss:0.46133\teval-mlogloss:0.64426\n",
            "[281]\ttrain-mlogloss:0.46047\teval-mlogloss:0.64383\n",
            "[282]\ttrain-mlogloss:0.45962\teval-mlogloss:0.64333\n",
            "[283]\ttrain-mlogloss:0.45871\teval-mlogloss:0.64285\n",
            "[284]\ttrain-mlogloss:0.45782\teval-mlogloss:0.64237\n",
            "[285]\ttrain-mlogloss:0.45698\teval-mlogloss:0.64212\n",
            "[286]\ttrain-mlogloss:0.45603\teval-mlogloss:0.64163\n",
            "[287]\ttrain-mlogloss:0.45510\teval-mlogloss:0.64101\n",
            "[288]\ttrain-mlogloss:0.45419\teval-mlogloss:0.64032\n",
            "[289]\ttrain-mlogloss:0.45338\teval-mlogloss:0.64004\n",
            "[290]\ttrain-mlogloss:0.45258\teval-mlogloss:0.63973\n",
            "[291]\ttrain-mlogloss:0.45177\teval-mlogloss:0.63937\n",
            "[292]\ttrain-mlogloss:0.45092\teval-mlogloss:0.63891\n",
            "[293]\ttrain-mlogloss:0.45007\teval-mlogloss:0.63851\n",
            "[294]\ttrain-mlogloss:0.44927\teval-mlogloss:0.63827\n",
            "[295]\ttrain-mlogloss:0.44838\teval-mlogloss:0.63764\n",
            "[296]\ttrain-mlogloss:0.44757\teval-mlogloss:0.63711\n",
            "[297]\ttrain-mlogloss:0.44670\teval-mlogloss:0.63666\n",
            "[298]\ttrain-mlogloss:0.44596\teval-mlogloss:0.63617\n",
            "[299]\ttrain-mlogloss:0.44516\teval-mlogloss:0.63578\n",
            "[300]\ttrain-mlogloss:0.44430\teval-mlogloss:0.63536\n",
            "[301]\ttrain-mlogloss:0.44358\teval-mlogloss:0.63495\n",
            "[302]\ttrain-mlogloss:0.44276\teval-mlogloss:0.63449\n",
            "[303]\ttrain-mlogloss:0.44205\teval-mlogloss:0.63419\n",
            "[304]\ttrain-mlogloss:0.44124\teval-mlogloss:0.63382\n",
            "[305]\ttrain-mlogloss:0.44048\teval-mlogloss:0.63338\n",
            "[306]\ttrain-mlogloss:0.43970\teval-mlogloss:0.63299\n",
            "[307]\ttrain-mlogloss:0.43897\teval-mlogloss:0.63275\n",
            "[308]\ttrain-mlogloss:0.43818\teval-mlogloss:0.63241\n",
            "[309]\ttrain-mlogloss:0.43739\teval-mlogloss:0.63194\n",
            "[310]\ttrain-mlogloss:0.43664\teval-mlogloss:0.63147\n",
            "[311]\ttrain-mlogloss:0.43590\teval-mlogloss:0.63111\n",
            "[312]\ttrain-mlogloss:0.43515\teval-mlogloss:0.63081\n",
            "[313]\ttrain-mlogloss:0.43441\teval-mlogloss:0.63047\n",
            "[314]\ttrain-mlogloss:0.43364\teval-mlogloss:0.62999\n",
            "[315]\ttrain-mlogloss:0.43290\teval-mlogloss:0.62966\n",
            "[316]\ttrain-mlogloss:0.43212\teval-mlogloss:0.62909\n",
            "[317]\ttrain-mlogloss:0.43146\teval-mlogloss:0.62882\n",
            "[318]\ttrain-mlogloss:0.43068\teval-mlogloss:0.62853\n",
            "[319]\ttrain-mlogloss:0.43005\teval-mlogloss:0.62819\n",
            "[320]\ttrain-mlogloss:0.42937\teval-mlogloss:0.62791\n",
            "[321]\ttrain-mlogloss:0.42863\teval-mlogloss:0.62760\n",
            "[322]\ttrain-mlogloss:0.42802\teval-mlogloss:0.62735\n",
            "[323]\ttrain-mlogloss:0.42739\teval-mlogloss:0.62713\n",
            "[324]\ttrain-mlogloss:0.42672\teval-mlogloss:0.62688\n",
            "[325]\ttrain-mlogloss:0.42597\teval-mlogloss:0.62638\n",
            "[326]\ttrain-mlogloss:0.42524\teval-mlogloss:0.62593\n",
            "[327]\ttrain-mlogloss:0.42449\teval-mlogloss:0.62551\n",
            "[328]\ttrain-mlogloss:0.42377\teval-mlogloss:0.62499\n",
            "[329]\ttrain-mlogloss:0.42306\teval-mlogloss:0.62458\n",
            "[330]\ttrain-mlogloss:0.42247\teval-mlogloss:0.62430\n",
            "[331]\ttrain-mlogloss:0.42179\teval-mlogloss:0.62395\n",
            "[332]\ttrain-mlogloss:0.42114\teval-mlogloss:0.62367\n",
            "[333]\ttrain-mlogloss:0.42052\teval-mlogloss:0.62352\n",
            "[334]\ttrain-mlogloss:0.41988\teval-mlogloss:0.62323\n",
            "[335]\ttrain-mlogloss:0.41924\teval-mlogloss:0.62298\n",
            "[336]\ttrain-mlogloss:0.41856\teval-mlogloss:0.62275\n",
            "[337]\ttrain-mlogloss:0.41785\teval-mlogloss:0.62236\n",
            "[338]\ttrain-mlogloss:0.41721\teval-mlogloss:0.62206\n",
            "[339]\ttrain-mlogloss:0.41657\teval-mlogloss:0.62195\n",
            "[340]\ttrain-mlogloss:0.41590\teval-mlogloss:0.62154\n",
            "[341]\ttrain-mlogloss:0.41526\teval-mlogloss:0.62134\n",
            "[342]\ttrain-mlogloss:0.41462\teval-mlogloss:0.62092\n",
            "[343]\ttrain-mlogloss:0.41397\teval-mlogloss:0.62061\n",
            "[344]\ttrain-mlogloss:0.41327\teval-mlogloss:0.62024\n",
            "[345]\ttrain-mlogloss:0.41264\teval-mlogloss:0.62002\n",
            "[346]\ttrain-mlogloss:0.41201\teval-mlogloss:0.61965\n",
            "[347]\ttrain-mlogloss:0.41144\teval-mlogloss:0.61930\n",
            "[348]\ttrain-mlogloss:0.41082\teval-mlogloss:0.61906\n",
            "[349]\ttrain-mlogloss:0.41018\teval-mlogloss:0.61879\n",
            "[350]\ttrain-mlogloss:0.40956\teval-mlogloss:0.61854\n",
            "[351]\ttrain-mlogloss:0.40895\teval-mlogloss:0.61828\n",
            "[352]\ttrain-mlogloss:0.40836\teval-mlogloss:0.61802\n",
            "[353]\ttrain-mlogloss:0.40772\teval-mlogloss:0.61777\n",
            "[354]\ttrain-mlogloss:0.40709\teval-mlogloss:0.61753\n",
            "[355]\ttrain-mlogloss:0.40649\teval-mlogloss:0.61728\n",
            "[356]\ttrain-mlogloss:0.40587\teval-mlogloss:0.61693\n",
            "[357]\ttrain-mlogloss:0.40529\teval-mlogloss:0.61669\n",
            "[358]\ttrain-mlogloss:0.40472\teval-mlogloss:0.61642\n",
            "[359]\ttrain-mlogloss:0.40414\teval-mlogloss:0.61629\n",
            "[360]\ttrain-mlogloss:0.40357\teval-mlogloss:0.61592\n",
            "[361]\ttrain-mlogloss:0.40300\teval-mlogloss:0.61559\n",
            "[362]\ttrain-mlogloss:0.40242\teval-mlogloss:0.61532\n",
            "[363]\ttrain-mlogloss:0.40186\teval-mlogloss:0.61504\n",
            "[364]\ttrain-mlogloss:0.40123\teval-mlogloss:0.61474\n",
            "[365]\ttrain-mlogloss:0.40066\teval-mlogloss:0.61443\n",
            "[366]\ttrain-mlogloss:0.40010\teval-mlogloss:0.61412\n",
            "[367]\ttrain-mlogloss:0.39964\teval-mlogloss:0.61404\n",
            "[368]\ttrain-mlogloss:0.39908\teval-mlogloss:0.61386\n",
            "[369]\ttrain-mlogloss:0.39851\teval-mlogloss:0.61369\n",
            "[370]\ttrain-mlogloss:0.39792\teval-mlogloss:0.61345\n",
            "[371]\ttrain-mlogloss:0.39734\teval-mlogloss:0.61297\n",
            "[372]\ttrain-mlogloss:0.39681\teval-mlogloss:0.61278\n",
            "[373]\ttrain-mlogloss:0.39635\teval-mlogloss:0.61264\n",
            "[374]\ttrain-mlogloss:0.39585\teval-mlogloss:0.61239\n",
            "[375]\ttrain-mlogloss:0.39533\teval-mlogloss:0.61217\n",
            "[376]\ttrain-mlogloss:0.39481\teval-mlogloss:0.61199\n",
            "[377]\ttrain-mlogloss:0.39432\teval-mlogloss:0.61172\n",
            "[378]\ttrain-mlogloss:0.39375\teval-mlogloss:0.61143\n",
            "[379]\ttrain-mlogloss:0.39319\teval-mlogloss:0.61118\n",
            "[380]\ttrain-mlogloss:0.39263\teval-mlogloss:0.61082\n",
            "[381]\ttrain-mlogloss:0.39211\teval-mlogloss:0.61060\n",
            "[382]\ttrain-mlogloss:0.39160\teval-mlogloss:0.61038\n",
            "[383]\ttrain-mlogloss:0.39105\teval-mlogloss:0.61008\n",
            "[384]\ttrain-mlogloss:0.39053\teval-mlogloss:0.60989\n",
            "[385]\ttrain-mlogloss:0.38999\teval-mlogloss:0.60971\n",
            "[386]\ttrain-mlogloss:0.38952\teval-mlogloss:0.60960\n",
            "[387]\ttrain-mlogloss:0.38902\teval-mlogloss:0.60931\n",
            "[388]\ttrain-mlogloss:0.38852\teval-mlogloss:0.60901\n",
            "[389]\ttrain-mlogloss:0.38807\teval-mlogloss:0.60887\n",
            "[390]\ttrain-mlogloss:0.38757\teval-mlogloss:0.60876\n",
            "[391]\ttrain-mlogloss:0.38705\teval-mlogloss:0.60872\n",
            "[392]\ttrain-mlogloss:0.38656\teval-mlogloss:0.60852\n",
            "[393]\ttrain-mlogloss:0.38608\teval-mlogloss:0.60815\n",
            "[394]\ttrain-mlogloss:0.38565\teval-mlogloss:0.60787\n",
            "[395]\ttrain-mlogloss:0.38517\teval-mlogloss:0.60777\n",
            "[396]\ttrain-mlogloss:0.38465\teval-mlogloss:0.60754\n",
            "[397]\ttrain-mlogloss:0.38420\teval-mlogloss:0.60738\n",
            "[398]\ttrain-mlogloss:0.38370\teval-mlogloss:0.60715\n",
            "[399]\ttrain-mlogloss:0.38326\teval-mlogloss:0.60695\n",
            "[400]\ttrain-mlogloss:0.38278\teval-mlogloss:0.60666\n",
            "[401]\ttrain-mlogloss:0.38228\teval-mlogloss:0.60661\n",
            "[402]\ttrain-mlogloss:0.38178\teval-mlogloss:0.60644\n",
            "[403]\ttrain-mlogloss:0.38126\teval-mlogloss:0.60619\n",
            "[404]\ttrain-mlogloss:0.38078\teval-mlogloss:0.60606\n",
            "[405]\ttrain-mlogloss:0.38028\teval-mlogloss:0.60595\n",
            "[406]\ttrain-mlogloss:0.37982\teval-mlogloss:0.60579\n",
            "[407]\ttrain-mlogloss:0.37933\teval-mlogloss:0.60551\n",
            "[408]\ttrain-mlogloss:0.37885\teval-mlogloss:0.60544\n",
            "[409]\ttrain-mlogloss:0.37838\teval-mlogloss:0.60526\n",
            "[410]\ttrain-mlogloss:0.37787\teval-mlogloss:0.60498\n",
            "[411]\ttrain-mlogloss:0.37743\teval-mlogloss:0.60484\n",
            "[412]\ttrain-mlogloss:0.37698\teval-mlogloss:0.60470\n",
            "[413]\ttrain-mlogloss:0.37655\teval-mlogloss:0.60449\n",
            "[414]\ttrain-mlogloss:0.37610\teval-mlogloss:0.60439\n",
            "[415]\ttrain-mlogloss:0.37561\teval-mlogloss:0.60418\n",
            "[416]\ttrain-mlogloss:0.37519\teval-mlogloss:0.60418\n",
            "[417]\ttrain-mlogloss:0.37477\teval-mlogloss:0.60403\n",
            "[418]\ttrain-mlogloss:0.37432\teval-mlogloss:0.60388\n",
            "[419]\ttrain-mlogloss:0.37387\teval-mlogloss:0.60374\n",
            "[420]\ttrain-mlogloss:0.37342\teval-mlogloss:0.60347\n",
            "[421]\ttrain-mlogloss:0.37300\teval-mlogloss:0.60331\n",
            "[422]\ttrain-mlogloss:0.37261\teval-mlogloss:0.60309\n",
            "[423]\ttrain-mlogloss:0.37219\teval-mlogloss:0.60289\n",
            "[424]\ttrain-mlogloss:0.37174\teval-mlogloss:0.60263\n",
            "[425]\ttrain-mlogloss:0.37129\teval-mlogloss:0.60243\n",
            "[426]\ttrain-mlogloss:0.37089\teval-mlogloss:0.60244\n",
            "[427]\ttrain-mlogloss:0.37047\teval-mlogloss:0.60228\n",
            "[428]\ttrain-mlogloss:0.37006\teval-mlogloss:0.60224\n",
            "[429]\ttrain-mlogloss:0.36961\teval-mlogloss:0.60203\n",
            "[430]\ttrain-mlogloss:0.36918\teval-mlogloss:0.60183\n",
            "[431]\ttrain-mlogloss:0.36875\teval-mlogloss:0.60160\n",
            "[432]\ttrain-mlogloss:0.36828\teval-mlogloss:0.60150\n",
            "[433]\ttrain-mlogloss:0.36783\teval-mlogloss:0.60137\n",
            "[434]\ttrain-mlogloss:0.36744\teval-mlogloss:0.60124\n",
            "[435]\ttrain-mlogloss:0.36700\teval-mlogloss:0.60103\n",
            "[436]\ttrain-mlogloss:0.36659\teval-mlogloss:0.60092\n",
            "[437]\ttrain-mlogloss:0.36617\teval-mlogloss:0.60079\n",
            "[438]\ttrain-mlogloss:0.36579\teval-mlogloss:0.60059\n",
            "[439]\ttrain-mlogloss:0.36538\teval-mlogloss:0.60050\n",
            "[440]\ttrain-mlogloss:0.36496\teval-mlogloss:0.60035\n",
            "[441]\ttrain-mlogloss:0.36456\teval-mlogloss:0.60039\n",
            "[442]\ttrain-mlogloss:0.36423\teval-mlogloss:0.60033\n",
            "[443]\ttrain-mlogloss:0.36387\teval-mlogloss:0.60028\n",
            "[444]\ttrain-mlogloss:0.36352\teval-mlogloss:0.60029\n",
            "[445]\ttrain-mlogloss:0.36319\teval-mlogloss:0.60015\n",
            "[446]\ttrain-mlogloss:0.36285\teval-mlogloss:0.60013\n",
            "[447]\ttrain-mlogloss:0.36247\teval-mlogloss:0.60003\n",
            "[448]\ttrain-mlogloss:0.36211\teval-mlogloss:0.59993\n",
            "[449]\ttrain-mlogloss:0.36175\teval-mlogloss:0.59984\n",
            "[450]\ttrain-mlogloss:0.36138\teval-mlogloss:0.59969\n",
            "[451]\ttrain-mlogloss:0.36099\teval-mlogloss:0.59965\n",
            "[452]\ttrain-mlogloss:0.36058\teval-mlogloss:0.59951\n",
            "[453]\ttrain-mlogloss:0.36023\teval-mlogloss:0.59949\n",
            "[454]\ttrain-mlogloss:0.35987\teval-mlogloss:0.59930\n",
            "[455]\ttrain-mlogloss:0.35947\teval-mlogloss:0.59921\n",
            "[456]\ttrain-mlogloss:0.35913\teval-mlogloss:0.59912\n",
            "[457]\ttrain-mlogloss:0.35877\teval-mlogloss:0.59887\n",
            "[458]\ttrain-mlogloss:0.35840\teval-mlogloss:0.59868\n",
            "[459]\ttrain-mlogloss:0.35810\teval-mlogloss:0.59854\n",
            "[460]\ttrain-mlogloss:0.35777\teval-mlogloss:0.59849\n",
            "[461]\ttrain-mlogloss:0.35740\teval-mlogloss:0.59849\n",
            "[462]\ttrain-mlogloss:0.35703\teval-mlogloss:0.59848\n",
            "[463]\ttrain-mlogloss:0.35666\teval-mlogloss:0.59826\n",
            "[464]\ttrain-mlogloss:0.35633\teval-mlogloss:0.59808\n",
            "[465]\ttrain-mlogloss:0.35604\teval-mlogloss:0.59795\n",
            "[466]\ttrain-mlogloss:0.35568\teval-mlogloss:0.59793\n",
            "[467]\ttrain-mlogloss:0.35536\teval-mlogloss:0.59792\n",
            "[468]\ttrain-mlogloss:0.35502\teval-mlogloss:0.59784\n",
            "[469]\ttrain-mlogloss:0.35467\teval-mlogloss:0.59782\n",
            "[470]\ttrain-mlogloss:0.35433\teval-mlogloss:0.59789\n",
            "[471]\ttrain-mlogloss:0.35399\teval-mlogloss:0.59792\n",
            "[472]\ttrain-mlogloss:0.35366\teval-mlogloss:0.59791\n",
            "[473]\ttrain-mlogloss:0.35332\teval-mlogloss:0.59780\n",
            "[474]\ttrain-mlogloss:0.35298\teval-mlogloss:0.59782\n",
            "[475]\ttrain-mlogloss:0.35266\teval-mlogloss:0.59776\n",
            "[476]\ttrain-mlogloss:0.35230\teval-mlogloss:0.59765\n",
            "[477]\ttrain-mlogloss:0.35191\teval-mlogloss:0.59752\n",
            "[478]\ttrain-mlogloss:0.35158\teval-mlogloss:0.59743\n",
            "[479]\ttrain-mlogloss:0.35126\teval-mlogloss:0.59728\n",
            "[480]\ttrain-mlogloss:0.35095\teval-mlogloss:0.59718\n",
            "[481]\ttrain-mlogloss:0.35063\teval-mlogloss:0.59713\n",
            "[482]\ttrain-mlogloss:0.35034\teval-mlogloss:0.59715\n",
            "[483]\ttrain-mlogloss:0.34999\teval-mlogloss:0.59708\n",
            "[484]\ttrain-mlogloss:0.34970\teval-mlogloss:0.59696\n",
            "[485]\ttrain-mlogloss:0.34937\teval-mlogloss:0.59684\n",
            "[486]\ttrain-mlogloss:0.34906\teval-mlogloss:0.59682\n",
            "[487]\ttrain-mlogloss:0.34875\teval-mlogloss:0.59669\n",
            "[488]\ttrain-mlogloss:0.34842\teval-mlogloss:0.59664\n",
            "[489]\ttrain-mlogloss:0.34810\teval-mlogloss:0.59663\n",
            "[490]\ttrain-mlogloss:0.34779\teval-mlogloss:0.59666\n",
            "[491]\ttrain-mlogloss:0.34750\teval-mlogloss:0.59664\n",
            "[492]\ttrain-mlogloss:0.34721\teval-mlogloss:0.59672\n",
            "[493]\ttrain-mlogloss:0.34689\teval-mlogloss:0.59657\n",
            "[494]\ttrain-mlogloss:0.34660\teval-mlogloss:0.59656\n",
            "[495]\ttrain-mlogloss:0.34629\teval-mlogloss:0.59647\n",
            "[496]\ttrain-mlogloss:0.34602\teval-mlogloss:0.59650\n",
            "[497]\ttrain-mlogloss:0.34573\teval-mlogloss:0.59640\n",
            "[498]\ttrain-mlogloss:0.34544\teval-mlogloss:0.59634\n",
            "[499]\ttrain-mlogloss:0.34514\teval-mlogloss:0.59628\n",
            "[500]\ttrain-mlogloss:0.34485\teval-mlogloss:0.59628\n",
            "[501]\ttrain-mlogloss:0.34454\teval-mlogloss:0.59625\n",
            "[502]\ttrain-mlogloss:0.34424\teval-mlogloss:0.59609\n",
            "[503]\ttrain-mlogloss:0.34393\teval-mlogloss:0.59609\n",
            "[504]\ttrain-mlogloss:0.34368\teval-mlogloss:0.59599\n",
            "[505]\ttrain-mlogloss:0.34342\teval-mlogloss:0.59597\n",
            "[506]\ttrain-mlogloss:0.34315\teval-mlogloss:0.59602\n",
            "[507]\ttrain-mlogloss:0.34285\teval-mlogloss:0.59587\n",
            "[508]\ttrain-mlogloss:0.34252\teval-mlogloss:0.59591\n",
            "[509]\ttrain-mlogloss:0.34220\teval-mlogloss:0.59578\n",
            "[510]\ttrain-mlogloss:0.34192\teval-mlogloss:0.59570\n",
            "[511]\ttrain-mlogloss:0.34161\teval-mlogloss:0.59561\n",
            "[512]\ttrain-mlogloss:0.34132\teval-mlogloss:0.59557\n",
            "[513]\ttrain-mlogloss:0.34103\teval-mlogloss:0.59558\n",
            "[514]\ttrain-mlogloss:0.34077\teval-mlogloss:0.59569\n",
            "[515]\ttrain-mlogloss:0.34051\teval-mlogloss:0.59564\n",
            "[516]\ttrain-mlogloss:0.34023\teval-mlogloss:0.59548\n",
            "[517]\ttrain-mlogloss:0.33995\teval-mlogloss:0.59553\n",
            "[518]\ttrain-mlogloss:0.33967\teval-mlogloss:0.59548\n",
            "[519]\ttrain-mlogloss:0.33940\teval-mlogloss:0.59539\n",
            "[520]\ttrain-mlogloss:0.33910\teval-mlogloss:0.59534\n",
            "[521]\ttrain-mlogloss:0.33879\teval-mlogloss:0.59530\n",
            "[522]\ttrain-mlogloss:0.33851\teval-mlogloss:0.59534\n",
            "[523]\ttrain-mlogloss:0.33825\teval-mlogloss:0.59530\n",
            "[524]\ttrain-mlogloss:0.33799\teval-mlogloss:0.59526\n",
            "[525]\ttrain-mlogloss:0.33773\teval-mlogloss:0.59521\n",
            "[526]\ttrain-mlogloss:0.33748\teval-mlogloss:0.59522\n",
            "[527]\ttrain-mlogloss:0.33721\teval-mlogloss:0.59517\n",
            "[528]\ttrain-mlogloss:0.33693\teval-mlogloss:0.59515\n",
            "[529]\ttrain-mlogloss:0.33667\teval-mlogloss:0.59506\n",
            "[530]\ttrain-mlogloss:0.33637\teval-mlogloss:0.59503\n",
            "[531]\ttrain-mlogloss:0.33611\teval-mlogloss:0.59510\n",
            "[532]\ttrain-mlogloss:0.33586\teval-mlogloss:0.59503\n",
            "[533]\ttrain-mlogloss:0.33559\teval-mlogloss:0.59499\n",
            "[534]\ttrain-mlogloss:0.33533\teval-mlogloss:0.59500\n",
            "[535]\ttrain-mlogloss:0.33507\teval-mlogloss:0.59490\n",
            "[536]\ttrain-mlogloss:0.33481\teval-mlogloss:0.59505\n",
            "[537]\ttrain-mlogloss:0.33455\teval-mlogloss:0.59514\n",
            "[538]\ttrain-mlogloss:0.33432\teval-mlogloss:0.59506\n",
            "[539]\ttrain-mlogloss:0.33404\teval-mlogloss:0.59502\n",
            "[540]\ttrain-mlogloss:0.33378\teval-mlogloss:0.59510\n",
            "[541]\ttrain-mlogloss:0.33355\teval-mlogloss:0.59513\n",
            "[542]\ttrain-mlogloss:0.33326\teval-mlogloss:0.59514\n",
            "[543]\ttrain-mlogloss:0.33299\teval-mlogloss:0.59503\n",
            "[544]\ttrain-mlogloss:0.33274\teval-mlogloss:0.59491\n",
            "[545]\ttrain-mlogloss:0.33247\teval-mlogloss:0.59488\n",
            "[546]\ttrain-mlogloss:0.33223\teval-mlogloss:0.59486\n",
            "[547]\ttrain-mlogloss:0.33198\teval-mlogloss:0.59488\n",
            "[548]\ttrain-mlogloss:0.33173\teval-mlogloss:0.59475\n",
            "[549]\ttrain-mlogloss:0.33149\teval-mlogloss:0.59474\n",
            "[550]\ttrain-mlogloss:0.33125\teval-mlogloss:0.59488\n",
            "[551]\ttrain-mlogloss:0.33099\teval-mlogloss:0.59474\n",
            "[552]\ttrain-mlogloss:0.33073\teval-mlogloss:0.59472\n",
            "[553]\ttrain-mlogloss:0.33051\teval-mlogloss:0.59455\n",
            "[554]\ttrain-mlogloss:0.33021\teval-mlogloss:0.59461\n",
            "[555]\ttrain-mlogloss:0.32995\teval-mlogloss:0.59449\n",
            "[556]\ttrain-mlogloss:0.32971\teval-mlogloss:0.59442\n",
            "[557]\ttrain-mlogloss:0.32944\teval-mlogloss:0.59441\n",
            "[558]\ttrain-mlogloss:0.32921\teval-mlogloss:0.59432\n",
            "[559]\ttrain-mlogloss:0.32894\teval-mlogloss:0.59430\n",
            "[560]\ttrain-mlogloss:0.32867\teval-mlogloss:0.59425\n",
            "[561]\ttrain-mlogloss:0.32845\teval-mlogloss:0.59424\n",
            "[562]\ttrain-mlogloss:0.32817\teval-mlogloss:0.59420\n",
            "[563]\ttrain-mlogloss:0.32794\teval-mlogloss:0.59418\n",
            "[564]\ttrain-mlogloss:0.32770\teval-mlogloss:0.59415\n",
            "[565]\ttrain-mlogloss:0.32749\teval-mlogloss:0.59405\n",
            "[566]\ttrain-mlogloss:0.32724\teval-mlogloss:0.59403\n",
            "[567]\ttrain-mlogloss:0.32701\teval-mlogloss:0.59402\n",
            "[568]\ttrain-mlogloss:0.32679\teval-mlogloss:0.59399\n",
            "[569]\ttrain-mlogloss:0.32655\teval-mlogloss:0.59400\n",
            "[570]\ttrain-mlogloss:0.32632\teval-mlogloss:0.59404\n",
            "[571]\ttrain-mlogloss:0.32607\teval-mlogloss:0.59410\n",
            "[572]\ttrain-mlogloss:0.32585\teval-mlogloss:0.59402\n",
            "[573]\ttrain-mlogloss:0.32559\teval-mlogloss:0.59393\n",
            "[574]\ttrain-mlogloss:0.32536\teval-mlogloss:0.59380\n",
            "[575]\ttrain-mlogloss:0.32514\teval-mlogloss:0.59388\n",
            "[576]\ttrain-mlogloss:0.32489\teval-mlogloss:0.59382\n",
            "[577]\ttrain-mlogloss:0.32462\teval-mlogloss:0.59382\n",
            "[578]\ttrain-mlogloss:0.32440\teval-mlogloss:0.59389\n",
            "[579]\ttrain-mlogloss:0.32415\teval-mlogloss:0.59387\n",
            "[580]\ttrain-mlogloss:0.32393\teval-mlogloss:0.59385\n",
            "[581]\ttrain-mlogloss:0.32370\teval-mlogloss:0.59368\n",
            "[582]\ttrain-mlogloss:0.32347\teval-mlogloss:0.59383\n",
            "[583]\ttrain-mlogloss:0.32323\teval-mlogloss:0.59375\n",
            "[584]\ttrain-mlogloss:0.32301\teval-mlogloss:0.59369\n",
            "[585]\ttrain-mlogloss:0.32279\teval-mlogloss:0.59360\n",
            "[586]\ttrain-mlogloss:0.32258\teval-mlogloss:0.59359\n",
            "[587]\ttrain-mlogloss:0.32237\teval-mlogloss:0.59356\n",
            "[588]\ttrain-mlogloss:0.32218\teval-mlogloss:0.59356\n",
            "[589]\ttrain-mlogloss:0.32198\teval-mlogloss:0.59345\n",
            "[590]\ttrain-mlogloss:0.32177\teval-mlogloss:0.59336\n",
            "[591]\ttrain-mlogloss:0.32156\teval-mlogloss:0.59349\n",
            "[592]\ttrain-mlogloss:0.32132\teval-mlogloss:0.59344\n",
            "[593]\ttrain-mlogloss:0.32108\teval-mlogloss:0.59337\n",
            "[594]\ttrain-mlogloss:0.32082\teval-mlogloss:0.59337\n",
            "[595]\ttrain-mlogloss:0.32060\teval-mlogloss:0.59335\n",
            "[596]\ttrain-mlogloss:0.32039\teval-mlogloss:0.59336\n",
            "[597]\ttrain-mlogloss:0.32017\teval-mlogloss:0.59332\n",
            "[598]\ttrain-mlogloss:0.31999\teval-mlogloss:0.59342\n",
            "[599]\ttrain-mlogloss:0.31978\teval-mlogloss:0.59337\n",
            "[600]\ttrain-mlogloss:0.31958\teval-mlogloss:0.59327\n",
            "[601]\ttrain-mlogloss:0.31937\teval-mlogloss:0.59332\n",
            "[602]\ttrain-mlogloss:0.31915\teval-mlogloss:0.59327\n",
            "[603]\ttrain-mlogloss:0.31897\teval-mlogloss:0.59323\n",
            "[604]\ttrain-mlogloss:0.31877\teval-mlogloss:0.59322\n",
            "[605]\ttrain-mlogloss:0.31859\teval-mlogloss:0.59339\n",
            "[606]\ttrain-mlogloss:0.31838\teval-mlogloss:0.59335\n",
            "[607]\ttrain-mlogloss:0.31813\teval-mlogloss:0.59318\n",
            "[608]\ttrain-mlogloss:0.31794\teval-mlogloss:0.59322\n",
            "[609]\ttrain-mlogloss:0.31773\teval-mlogloss:0.59315\n",
            "[610]\ttrain-mlogloss:0.31753\teval-mlogloss:0.59303\n",
            "[611]\ttrain-mlogloss:0.31734\teval-mlogloss:0.59300\n",
            "[612]\ttrain-mlogloss:0.31713\teval-mlogloss:0.59291\n",
            "[613]\ttrain-mlogloss:0.31694\teval-mlogloss:0.59285\n",
            "[614]\ttrain-mlogloss:0.31674\teval-mlogloss:0.59288\n",
            "[615]\ttrain-mlogloss:0.31656\teval-mlogloss:0.59292\n",
            "[616]\ttrain-mlogloss:0.31635\teval-mlogloss:0.59282\n",
            "[617]\ttrain-mlogloss:0.31616\teval-mlogloss:0.59279\n",
            "[618]\ttrain-mlogloss:0.31597\teval-mlogloss:0.59288\n",
            "[619]\ttrain-mlogloss:0.31577\teval-mlogloss:0.59279\n",
            "[620]\ttrain-mlogloss:0.31556\teval-mlogloss:0.59278\n",
            "[621]\ttrain-mlogloss:0.31533\teval-mlogloss:0.59269\n",
            "[622]\ttrain-mlogloss:0.31515\teval-mlogloss:0.59276\n",
            "[623]\ttrain-mlogloss:0.31495\teval-mlogloss:0.59274\n",
            "[624]\ttrain-mlogloss:0.31476\teval-mlogloss:0.59277\n",
            "[625]\ttrain-mlogloss:0.31458\teval-mlogloss:0.59283\n",
            "[626]\ttrain-mlogloss:0.31438\teval-mlogloss:0.59290\n",
            "[627]\ttrain-mlogloss:0.31419\teval-mlogloss:0.59293\n",
            "[628]\ttrain-mlogloss:0.31402\teval-mlogloss:0.59293\n",
            "[629]\ttrain-mlogloss:0.31383\teval-mlogloss:0.59292\n",
            "[630]\ttrain-mlogloss:0.31364\teval-mlogloss:0.59279\n",
            "[631]\ttrain-mlogloss:0.31339\teval-mlogloss:0.59265\n",
            "[632]\ttrain-mlogloss:0.31319\teval-mlogloss:0.59272\n",
            "[633]\ttrain-mlogloss:0.31298\teval-mlogloss:0.59255\n",
            "[634]\ttrain-mlogloss:0.31277\teval-mlogloss:0.59247\n",
            "[635]\ttrain-mlogloss:0.31259\teval-mlogloss:0.59244\n",
            "[636]\ttrain-mlogloss:0.31239\teval-mlogloss:0.59254\n",
            "[637]\ttrain-mlogloss:0.31220\teval-mlogloss:0.59263\n",
            "[638]\ttrain-mlogloss:0.31198\teval-mlogloss:0.59259\n",
            "[639]\ttrain-mlogloss:0.31180\teval-mlogloss:0.59273\n",
            "[640]\ttrain-mlogloss:0.31160\teval-mlogloss:0.59265\n",
            "[641]\ttrain-mlogloss:0.31139\teval-mlogloss:0.59261\n",
            "[642]\ttrain-mlogloss:0.31118\teval-mlogloss:0.59250\n",
            "[643]\ttrain-mlogloss:0.31096\teval-mlogloss:0.59246\n",
            "[644]\ttrain-mlogloss:0.31070\teval-mlogloss:0.59247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = trained_model.predict(DMatrix(X_test)).argmax(axis=1)\n",
        "y_pred_train = trained_model.predict(DMatrix(X_train)).argmax(axis=1)\n",
        "\n",
        "print(\"XGBoost Classification Report with Evaluation Set:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"\\n\\nXGBoost Classification Report for training set:\")\n",
        "print(classification_report(y_train, y_pred_train, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASL2rFQnlIEQ",
        "outputId": "2b18b93f-283d-460e-9cc1-1c64d4ab76a7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Classification Report with Evaluation Set:\n",
            "                                      precision    recall  f1-score   support\n",
            "\n",
            "Healthcare Access and Infrastructure       0.00      0.00      0.00        13\n",
            "           Healthcare Administration       0.50      0.28      0.36        25\n",
            "          Healthcare Service Quality       0.84      0.98      0.90       194\n",
            "           Medication-Related Issues       0.52      0.58      0.55        24\n",
            "                        Telemedicine       1.00      0.07      0.13        14\n",
            "\n",
            "                            accuracy                           0.79       270\n",
            "                           macro avg       0.57      0.38      0.39       270\n",
            "                        weighted avg       0.75      0.79      0.74       270\n",
            "\n",
            "\n",
            "\n",
            "XGBoost Classification Report for training set:\n",
            "                                      precision    recall  f1-score   support\n",
            "\n",
            "Healthcare Access and Infrastructure       0.79      0.27      0.41        55\n",
            "           Healthcare Administration       0.78      0.68      0.73        94\n",
            "          Healthcare Service Quality       0.90      0.97      0.93       784\n",
            "           Medication-Related Issues       0.86      0.84      0.85       122\n",
            "                        Telemedicine       0.92      0.48      0.63        25\n",
            "\n",
            "                            accuracy                           0.88      1080\n",
            "                           macro avg       0.85      0.65      0.71      1080\n",
            "                        weighted avg       0.88      0.88      0.87      1080\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment Analysis"
      ],
      "metadata": {
        "id": "lyr0a_Lml2Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQxttkOXlpBE",
        "outputId": "c9c4f7c5-f916-4463-831b-c00a386b7676"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_sentiment(sentence):\n",
        "    sentiment_scores = analyzer.polarity_scores(sentence)\n",
        "    if sentiment_scores['compound'] >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif sentiment_scores['compound'] <= -0.05:\n",
        "        return 'Negative'\n",
        "CORP_ENROLLEES_NPS['SENTIMENT_CLASSIFICATION'] = CORP_ENROLLEES_NPS['CUSTOMER_RESPONSE'].apply(classify_sentiment)"
      ],
      "metadata": {
        "id": "s4V2Sc2xmgUA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CORP_ENROLLEES_NPS['SENTIMENT_CLASSIFICATION'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rhd5Wz2mjXF",
        "outputId": "4039508f-1a6b-4b4b-95bd-7a7ba8d56c26"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive    749\n",
              "Negative    209\n",
              "Name: SENTIMENT_CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Subtopics Classification"
      ],
      "metadata": {
        "id": "OktOj5-4pkxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CORP_ENROLLEES_NPS = CORP_ENROLLEES_NPS[CORP_ENROLLEES_NPS['Sub-driver'].notna()]"
      ],
      "metadata": {
        "id": "K2f9HVcxsCFo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_group_subdrivers(text):\n",
        "    cleaned_text = text.lower().replace('-', ' ').replace('/', ' ').replace('_', ' ')\n",
        "    cleaned_text = ' '.join(cleaned_text.split())\n",
        "\n",
        "    if ((\"inadequate health benefits\" in cleaned_text) or (\"limited understanding of health benefits\" in cleaned_text) or (\"limited health benefit\" in cleaned_text) or (\"adequate health benefits\" in cleaned_text) or (\"sufficient health benefits\" in cleaned_text) or ('consultation time too short' in cleaned_text)):\n",
        "        return \"health benefits\"\n",
        "    elif (\"pa code\" in cleaned_text):\n",
        "        return \"pa code\"\n",
        "    elif ((\"short wait time\" in cleaned_text ) or ('long wait time' in cleaned_text)):\n",
        "      return \"waiting time\"\n",
        "    elif (('swift response' in cleaned_text) or ('not responsive' in cleaned_text) or ('delayed response' in cleaned_text)):\n",
        "      return \"Responsivenss\"\n",
        "    elif(('cheap medication' in cleaned_text) or ('quality medication' in cleaned_text) or ('delayed medication pickup' in cleaned_text) or ('medication pickup issue' in cleaned_text) or ('quick medication delivery'in cleaned_text) or ('delayed medication delivery' in cleaned_text) or ('substandard medication' in cleaned_text)):\n",
        "      return 'medication'\n",
        "    elif(('delayed feedback' in cleaned_text) or ('poor feedback tat' in cleaned_text) or ('lack of feedback' in cleaned_text)):\n",
        "      return \"feedback\"\n",
        "    elif (( 'poor issue resolution' in cleaned_text) or ('poor resolution process' in cleaned_text)):\n",
        "      return \"resolution\"\n",
        "    elif(('lack of knowledge of delivery status' in cleaned_text) or  ('lack of delivery status' in cleaned_text)):\n",
        "      return \"delivery status\"\n",
        "    elif(('poor staff attitude' in cleaned_text)  or ('poor treatment' in cleaned_text) or ('good staff attitude' in cleaned_text)):\n",
        "      return \"staff attitude\"\n",
        "    else:\n",
        "      return cleaned_text\n",
        "# Kolade's feedback: Merge PA_CODE with waiting time.\n",
        "# Apply the function to the 'Sub-driver' column and create a new 'Grouped_Sub-driver' column\n",
        "CORP_ENROLLEES_NPS['Grouped_Sub-driver'] = CORP_ENROLLEES_NPS['Sub-driver'].apply(clean_and_group_subdrivers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA8vmT1LmojE",
        "outputId": "6bb10ce2-d0e8-4ba9-ba11-7701d6b460bf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-f2ac100c744f>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  CORP_ENROLLEES_NPS['Grouped_Sub-driver'] = CORP_ENROLLEES_NPS['Sub-driver'].apply(clean_and_group_subdrivers)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = CORP_ENROLLEES_NPS['Grouped_Sub-driver'].value_counts()\n",
        "classes_to_keep = class_counts[class_counts > 20].index.tolist()\n",
        "filtered_NPS_data = CORP_ENROLLEES_NPS[CORP_ENROLLEES_NPS['Grouped_Sub-driver'].isin(classes_to_keep)]"
      ],
      "metadata": {
        "id": "LqJzyy3usTtg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_vectors = vectorizer.fit_transform(filtered_NPS_data['CUSTOMER_RESPONSE'])\n",
        "label_encoder = LabelEncoder()\n",
        "filtered_NPS_data['filtered_category_encoded'] = label_encoder.fit_transform(filtered_NPS_data['Grouped_Sub-driver'])\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fjLhzmBsTqt",
        "outputId": "5420f25c-bf5d-4171-aa1a-b991c8c7fa99"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-c427320c9346>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_NPS_data['filtered_category_encoded'] = label_encoder.fit_transform(filtered_NPS_data['Grouped_Sub-driver'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'objective': 'multi:softprob', 'num_class': 7, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.01, 'lambda': 1, 'gamma': 0, 'eval_metric': 'mlogloss', 'colsample_bytree': 0.7, 'alpha': 0}"
      ],
      "metadata": {
        "id": "59vmN-p1ssQT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(clean_vectors, filtered_NPS_data['filtered_category_encoded'], test_size=0.2)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "dtrain = DMatrix(X_train2, label=y_train2)\n",
        "dtest = DMatrix(X_test2, label=y_test2)\n",
        "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "dtrain = DMatrix(X_train2, label=y_train2)\n",
        "dtest = DMatrix(X_test2, label=y_test2)\n",
        "evallist = [(dtrain, 'train'), (dtest, 'eval')]"
      ],
      "metadata": {
        "id": "L-NAOdCIsTnw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = xgb.train(\n",
        "                param_grid\n",
        "                ,dtrain\n",
        "                ,evals = evallist\n",
        "                ,num_boost_round=2000\n",
        "                ,early_stopping_rounds=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdob1WeisTk6",
        "outputId": "c85979f3-940c-45ce-b646-df20e7f4bdf7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.92734\teval-mlogloss:1.92976\n",
            "[1]\ttrain-mlogloss:1.90939\teval-mlogloss:1.91409\n",
            "[2]\ttrain-mlogloss:1.89515\teval-mlogloss:1.90229\n",
            "[3]\ttrain-mlogloss:1.87992\teval-mlogloss:1.88863\n",
            "[4]\ttrain-mlogloss:1.86454\teval-mlogloss:1.87468\n",
            "[5]\ttrain-mlogloss:1.84973\teval-mlogloss:1.86334\n",
            "[6]\ttrain-mlogloss:1.83449\teval-mlogloss:1.85063\n",
            "[7]\ttrain-mlogloss:1.81952\teval-mlogloss:1.83859\n",
            "[8]\ttrain-mlogloss:1.80447\teval-mlogloss:1.82626\n",
            "[9]\ttrain-mlogloss:1.79141\teval-mlogloss:1.81617\n",
            "[10]\ttrain-mlogloss:1.77920\teval-mlogloss:1.80693\n",
            "[11]\ttrain-mlogloss:1.76453\teval-mlogloss:1.79433\n",
            "[12]\ttrain-mlogloss:1.75233\teval-mlogloss:1.78340\n",
            "[13]\ttrain-mlogloss:1.73789\teval-mlogloss:1.77088\n",
            "[14]\ttrain-mlogloss:1.72584\teval-mlogloss:1.76223\n",
            "[15]\ttrain-mlogloss:1.71225\teval-mlogloss:1.75126\n",
            "[16]\ttrain-mlogloss:1.69958\teval-mlogloss:1.74072\n",
            "[17]\ttrain-mlogloss:1.68726\teval-mlogloss:1.73065\n",
            "[18]\ttrain-mlogloss:1.67468\teval-mlogloss:1.71966\n",
            "[19]\ttrain-mlogloss:1.66216\teval-mlogloss:1.70983\n",
            "[20]\ttrain-mlogloss:1.65046\teval-mlogloss:1.69990\n",
            "[21]\ttrain-mlogloss:1.63886\teval-mlogloss:1.69050\n",
            "[22]\ttrain-mlogloss:1.62726\teval-mlogloss:1.68111\n",
            "[23]\ttrain-mlogloss:1.61585\teval-mlogloss:1.67292\n",
            "[24]\ttrain-mlogloss:1.60500\teval-mlogloss:1.66372\n",
            "[25]\ttrain-mlogloss:1.59402\teval-mlogloss:1.65597\n",
            "[26]\ttrain-mlogloss:1.58334\teval-mlogloss:1.64691\n",
            "[27]\ttrain-mlogloss:1.57374\teval-mlogloss:1.63863\n",
            "[28]\ttrain-mlogloss:1.56279\teval-mlogloss:1.63024\n",
            "[29]\ttrain-mlogloss:1.55228\teval-mlogloss:1.62111\n",
            "[30]\ttrain-mlogloss:1.54328\teval-mlogloss:1.61444\n",
            "[31]\ttrain-mlogloss:1.53280\teval-mlogloss:1.60672\n",
            "[32]\ttrain-mlogloss:1.52232\teval-mlogloss:1.59812\n",
            "[33]\ttrain-mlogloss:1.51336\teval-mlogloss:1.59090\n",
            "[34]\ttrain-mlogloss:1.50341\teval-mlogloss:1.58286\n",
            "[35]\ttrain-mlogloss:1.49420\teval-mlogloss:1.57582\n",
            "[36]\ttrain-mlogloss:1.48476\teval-mlogloss:1.56869\n",
            "[37]\ttrain-mlogloss:1.47523\teval-mlogloss:1.56105\n",
            "[38]\ttrain-mlogloss:1.46549\teval-mlogloss:1.55347\n",
            "[39]\ttrain-mlogloss:1.45624\teval-mlogloss:1.54597\n",
            "[40]\ttrain-mlogloss:1.44716\teval-mlogloss:1.53920\n",
            "[41]\ttrain-mlogloss:1.43835\teval-mlogloss:1.53211\n",
            "[42]\ttrain-mlogloss:1.42929\teval-mlogloss:1.52463\n",
            "[43]\ttrain-mlogloss:1.42040\teval-mlogloss:1.51743\n",
            "[44]\ttrain-mlogloss:1.41168\teval-mlogloss:1.50996\n",
            "[45]\ttrain-mlogloss:1.40379\teval-mlogloss:1.50415\n",
            "[46]\ttrain-mlogloss:1.39589\teval-mlogloss:1.49868\n",
            "[47]\ttrain-mlogloss:1.38748\teval-mlogloss:1.49254\n",
            "[48]\ttrain-mlogloss:1.37915\teval-mlogloss:1.48575\n",
            "[49]\ttrain-mlogloss:1.37095\teval-mlogloss:1.47927\n",
            "[50]\ttrain-mlogloss:1.36353\teval-mlogloss:1.47364\n",
            "[51]\ttrain-mlogloss:1.35596\teval-mlogloss:1.46775\n",
            "[52]\ttrain-mlogloss:1.34896\teval-mlogloss:1.46181\n",
            "[53]\ttrain-mlogloss:1.34171\teval-mlogloss:1.45661\n",
            "[54]\ttrain-mlogloss:1.33489\teval-mlogloss:1.45138\n",
            "[55]\ttrain-mlogloss:1.32780\teval-mlogloss:1.44591\n",
            "[56]\ttrain-mlogloss:1.32037\teval-mlogloss:1.44004\n",
            "[57]\ttrain-mlogloss:1.31287\teval-mlogloss:1.43411\n",
            "[58]\ttrain-mlogloss:1.30604\teval-mlogloss:1.42855\n",
            "[59]\ttrain-mlogloss:1.29897\teval-mlogloss:1.42319\n",
            "[60]\ttrain-mlogloss:1.29242\teval-mlogloss:1.41884\n",
            "[61]\ttrain-mlogloss:1.28570\teval-mlogloss:1.41420\n",
            "[62]\ttrain-mlogloss:1.27897\teval-mlogloss:1.40966\n",
            "[63]\ttrain-mlogloss:1.27199\teval-mlogloss:1.40449\n",
            "[64]\ttrain-mlogloss:1.26573\teval-mlogloss:1.40025\n",
            "[65]\ttrain-mlogloss:1.25913\teval-mlogloss:1.39560\n",
            "[66]\ttrain-mlogloss:1.25256\teval-mlogloss:1.39086\n",
            "[67]\ttrain-mlogloss:1.24628\teval-mlogloss:1.38575\n",
            "[68]\ttrain-mlogloss:1.24003\teval-mlogloss:1.38082\n",
            "[69]\ttrain-mlogloss:1.23435\teval-mlogloss:1.37647\n",
            "[70]\ttrain-mlogloss:1.22834\teval-mlogloss:1.37166\n",
            "[71]\ttrain-mlogloss:1.22201\teval-mlogloss:1.36715\n",
            "[72]\ttrain-mlogloss:1.21587\teval-mlogloss:1.36239\n",
            "[73]\ttrain-mlogloss:1.20971\teval-mlogloss:1.35814\n",
            "[74]\ttrain-mlogloss:1.20432\teval-mlogloss:1.35445\n",
            "[75]\ttrain-mlogloss:1.19852\teval-mlogloss:1.34968\n",
            "[76]\ttrain-mlogloss:1.19250\teval-mlogloss:1.34470\n",
            "[77]\ttrain-mlogloss:1.18657\teval-mlogloss:1.34080\n",
            "[78]\ttrain-mlogloss:1.18064\teval-mlogloss:1.33625\n",
            "[79]\ttrain-mlogloss:1.17530\teval-mlogloss:1.33246\n",
            "[80]\ttrain-mlogloss:1.17001\teval-mlogloss:1.32897\n",
            "[81]\ttrain-mlogloss:1.16460\teval-mlogloss:1.32574\n",
            "[82]\ttrain-mlogloss:1.15898\teval-mlogloss:1.32205\n",
            "[83]\ttrain-mlogloss:1.15345\teval-mlogloss:1.31812\n",
            "[84]\ttrain-mlogloss:1.14779\teval-mlogloss:1.31415\n",
            "[85]\ttrain-mlogloss:1.14248\teval-mlogloss:1.30981\n",
            "[86]\ttrain-mlogloss:1.13720\teval-mlogloss:1.30601\n",
            "[87]\ttrain-mlogloss:1.13181\teval-mlogloss:1.30223\n",
            "[88]\ttrain-mlogloss:1.12683\teval-mlogloss:1.29845\n",
            "[89]\ttrain-mlogloss:1.12153\teval-mlogloss:1.29429\n",
            "[90]\ttrain-mlogloss:1.11651\teval-mlogloss:1.29072\n",
            "[91]\ttrain-mlogloss:1.11139\teval-mlogloss:1.28697\n",
            "[92]\ttrain-mlogloss:1.10628\teval-mlogloss:1.28313\n",
            "[93]\ttrain-mlogloss:1.10133\teval-mlogloss:1.27982\n",
            "[94]\ttrain-mlogloss:1.09631\teval-mlogloss:1.27665\n",
            "[95]\ttrain-mlogloss:1.09113\teval-mlogloss:1.27295\n",
            "[96]\ttrain-mlogloss:1.08623\teval-mlogloss:1.27013\n",
            "[97]\ttrain-mlogloss:1.08151\teval-mlogloss:1.26691\n",
            "[98]\ttrain-mlogloss:1.07675\teval-mlogloss:1.26352\n",
            "[99]\ttrain-mlogloss:1.07225\teval-mlogloss:1.26055\n",
            "[100]\ttrain-mlogloss:1.06763\teval-mlogloss:1.25729\n",
            "[101]\ttrain-mlogloss:1.06289\teval-mlogloss:1.25389\n",
            "[102]\ttrain-mlogloss:1.05816\teval-mlogloss:1.25039\n",
            "[103]\ttrain-mlogloss:1.05356\teval-mlogloss:1.24722\n",
            "[104]\ttrain-mlogloss:1.04909\teval-mlogloss:1.24369\n",
            "[105]\ttrain-mlogloss:1.04435\teval-mlogloss:1.24030\n",
            "[106]\ttrain-mlogloss:1.03960\teval-mlogloss:1.23693\n",
            "[107]\ttrain-mlogloss:1.03504\teval-mlogloss:1.23421\n",
            "[108]\ttrain-mlogloss:1.03074\teval-mlogloss:1.23117\n",
            "[109]\ttrain-mlogloss:1.02646\teval-mlogloss:1.22857\n",
            "[110]\ttrain-mlogloss:1.02225\teval-mlogloss:1.22542\n",
            "[111]\ttrain-mlogloss:1.01781\teval-mlogloss:1.22204\n",
            "[112]\ttrain-mlogloss:1.01373\teval-mlogloss:1.21929\n",
            "[113]\ttrain-mlogloss:1.00968\teval-mlogloss:1.21616\n",
            "[114]\ttrain-mlogloss:1.00550\teval-mlogloss:1.21327\n",
            "[115]\ttrain-mlogloss:1.00130\teval-mlogloss:1.21022\n",
            "[116]\ttrain-mlogloss:0.99712\teval-mlogloss:1.20715\n",
            "[117]\ttrain-mlogloss:0.99304\teval-mlogloss:1.20464\n",
            "[118]\ttrain-mlogloss:0.98929\teval-mlogloss:1.20202\n",
            "[119]\ttrain-mlogloss:0.98523\teval-mlogloss:1.19956\n",
            "[120]\ttrain-mlogloss:0.98116\teval-mlogloss:1.19691\n",
            "[121]\ttrain-mlogloss:0.97734\teval-mlogloss:1.19451\n",
            "[122]\ttrain-mlogloss:0.97344\teval-mlogloss:1.19163\n",
            "[123]\ttrain-mlogloss:0.96958\teval-mlogloss:1.18931\n",
            "[124]\ttrain-mlogloss:0.96583\teval-mlogloss:1.18697\n",
            "[125]\ttrain-mlogloss:0.96203\teval-mlogloss:1.18457\n",
            "[126]\ttrain-mlogloss:0.95806\teval-mlogloss:1.18195\n",
            "[127]\ttrain-mlogloss:0.95438\teval-mlogloss:1.17923\n",
            "[128]\ttrain-mlogloss:0.95075\teval-mlogloss:1.17704\n",
            "[129]\ttrain-mlogloss:0.94695\teval-mlogloss:1.17488\n",
            "[130]\ttrain-mlogloss:0.94317\teval-mlogloss:1.17267\n",
            "[131]\ttrain-mlogloss:0.93942\teval-mlogloss:1.17001\n",
            "[132]\ttrain-mlogloss:0.93625\teval-mlogloss:1.16793\n",
            "[133]\ttrain-mlogloss:0.93280\teval-mlogloss:1.16576\n",
            "[134]\ttrain-mlogloss:0.92939\teval-mlogloss:1.16294\n",
            "[135]\ttrain-mlogloss:0.92580\teval-mlogloss:1.16081\n",
            "[136]\ttrain-mlogloss:0.92216\teval-mlogloss:1.15837\n",
            "[137]\ttrain-mlogloss:0.91870\teval-mlogloss:1.15650\n",
            "[138]\ttrain-mlogloss:0.91512\teval-mlogloss:1.15417\n",
            "[139]\ttrain-mlogloss:0.91192\teval-mlogloss:1.15205\n",
            "[140]\ttrain-mlogloss:0.90850\teval-mlogloss:1.14980\n",
            "[141]\ttrain-mlogloss:0.90496\teval-mlogloss:1.14763\n",
            "[142]\ttrain-mlogloss:0.90176\teval-mlogloss:1.14529\n",
            "[143]\ttrain-mlogloss:0.89854\teval-mlogloss:1.14360\n",
            "[144]\ttrain-mlogloss:0.89533\teval-mlogloss:1.14137\n",
            "[145]\ttrain-mlogloss:0.89208\teval-mlogloss:1.13945\n",
            "[146]\ttrain-mlogloss:0.88886\teval-mlogloss:1.13775\n",
            "[147]\ttrain-mlogloss:0.88571\teval-mlogloss:1.13580\n",
            "[148]\ttrain-mlogloss:0.88241\teval-mlogloss:1.13361\n",
            "[149]\ttrain-mlogloss:0.87940\teval-mlogloss:1.13200\n",
            "[150]\ttrain-mlogloss:0.87602\teval-mlogloss:1.13047\n",
            "[151]\ttrain-mlogloss:0.87297\teval-mlogloss:1.12842\n",
            "[152]\ttrain-mlogloss:0.86975\teval-mlogloss:1.12616\n",
            "[153]\ttrain-mlogloss:0.86701\teval-mlogloss:1.12508\n",
            "[154]\ttrain-mlogloss:0.86394\teval-mlogloss:1.12318\n",
            "[155]\ttrain-mlogloss:0.86074\teval-mlogloss:1.12128\n",
            "[156]\ttrain-mlogloss:0.85779\teval-mlogloss:1.11913\n",
            "[157]\ttrain-mlogloss:0.85467\teval-mlogloss:1.11776\n",
            "[158]\ttrain-mlogloss:0.85167\teval-mlogloss:1.11620\n",
            "[159]\ttrain-mlogloss:0.84874\teval-mlogloss:1.11450\n",
            "[160]\ttrain-mlogloss:0.84589\teval-mlogloss:1.11289\n",
            "[161]\ttrain-mlogloss:0.84295\teval-mlogloss:1.11094\n",
            "[162]\ttrain-mlogloss:0.83983\teval-mlogloss:1.10898\n",
            "[163]\ttrain-mlogloss:0.83703\teval-mlogloss:1.10736\n",
            "[164]\ttrain-mlogloss:0.83415\teval-mlogloss:1.10588\n",
            "[165]\ttrain-mlogloss:0.83116\teval-mlogloss:1.10412\n",
            "[166]\ttrain-mlogloss:0.82852\teval-mlogloss:1.10265\n",
            "[167]\ttrain-mlogloss:0.82591\teval-mlogloss:1.10074\n",
            "[168]\ttrain-mlogloss:0.82323\teval-mlogloss:1.09874\n",
            "[169]\ttrain-mlogloss:0.82045\teval-mlogloss:1.09728\n",
            "[170]\ttrain-mlogloss:0.81760\teval-mlogloss:1.09560\n",
            "[171]\ttrain-mlogloss:0.81476\teval-mlogloss:1.09365\n",
            "[172]\ttrain-mlogloss:0.81223\teval-mlogloss:1.09221\n",
            "[173]\ttrain-mlogloss:0.80956\teval-mlogloss:1.09011\n",
            "[174]\ttrain-mlogloss:0.80680\teval-mlogloss:1.08844\n",
            "[175]\ttrain-mlogloss:0.80403\teval-mlogloss:1.08659\n",
            "[176]\ttrain-mlogloss:0.80147\teval-mlogloss:1.08453\n",
            "[177]\ttrain-mlogloss:0.79885\teval-mlogloss:1.08283\n",
            "[178]\ttrain-mlogloss:0.79631\teval-mlogloss:1.08147\n",
            "[179]\ttrain-mlogloss:0.79365\teval-mlogloss:1.08013\n",
            "[180]\ttrain-mlogloss:0.79103\teval-mlogloss:1.07865\n",
            "[181]\ttrain-mlogloss:0.78831\teval-mlogloss:1.07706\n",
            "[182]\ttrain-mlogloss:0.78576\teval-mlogloss:1.07538\n",
            "[183]\ttrain-mlogloss:0.78317\teval-mlogloss:1.07353\n",
            "[184]\ttrain-mlogloss:0.78073\teval-mlogloss:1.07186\n",
            "[185]\ttrain-mlogloss:0.77834\teval-mlogloss:1.07099\n",
            "[186]\ttrain-mlogloss:0.77593\teval-mlogloss:1.07013\n",
            "[187]\ttrain-mlogloss:0.77351\teval-mlogloss:1.06895\n",
            "[188]\ttrain-mlogloss:0.77112\teval-mlogloss:1.06757\n",
            "[189]\ttrain-mlogloss:0.76874\teval-mlogloss:1.06667\n",
            "[190]\ttrain-mlogloss:0.76644\teval-mlogloss:1.06562\n",
            "[191]\ttrain-mlogloss:0.76408\teval-mlogloss:1.06431\n",
            "[192]\ttrain-mlogloss:0.76171\teval-mlogloss:1.06344\n",
            "[193]\ttrain-mlogloss:0.75929\teval-mlogloss:1.06203\n",
            "[194]\ttrain-mlogloss:0.75695\teval-mlogloss:1.06085\n",
            "[195]\ttrain-mlogloss:0.75468\teval-mlogloss:1.05951\n",
            "[196]\ttrain-mlogloss:0.75233\teval-mlogloss:1.05786\n",
            "[197]\ttrain-mlogloss:0.75010\teval-mlogloss:1.05643\n",
            "[198]\ttrain-mlogloss:0.74784\teval-mlogloss:1.05522\n",
            "[199]\ttrain-mlogloss:0.74556\teval-mlogloss:1.05370\n",
            "[200]\ttrain-mlogloss:0.74325\teval-mlogloss:1.05231\n",
            "[201]\ttrain-mlogloss:0.74093\teval-mlogloss:1.05091\n",
            "[202]\ttrain-mlogloss:0.73872\teval-mlogloss:1.04987\n",
            "[203]\ttrain-mlogloss:0.73643\teval-mlogloss:1.04863\n",
            "[204]\ttrain-mlogloss:0.73426\teval-mlogloss:1.04745\n",
            "[205]\ttrain-mlogloss:0.73217\teval-mlogloss:1.04640\n",
            "[206]\ttrain-mlogloss:0.72990\teval-mlogloss:1.04578\n",
            "[207]\ttrain-mlogloss:0.72776\teval-mlogloss:1.04448\n",
            "[208]\ttrain-mlogloss:0.72564\teval-mlogloss:1.04311\n",
            "[209]\ttrain-mlogloss:0.72354\teval-mlogloss:1.04142\n",
            "[210]\ttrain-mlogloss:0.72157\teval-mlogloss:1.04017\n",
            "[211]\ttrain-mlogloss:0.71955\teval-mlogloss:1.03910\n",
            "[212]\ttrain-mlogloss:0.71738\teval-mlogloss:1.03774\n",
            "[213]\ttrain-mlogloss:0.71529\teval-mlogloss:1.03649\n",
            "[214]\ttrain-mlogloss:0.71309\teval-mlogloss:1.03527\n",
            "[215]\ttrain-mlogloss:0.71091\teval-mlogloss:1.03378\n",
            "[216]\ttrain-mlogloss:0.70882\teval-mlogloss:1.03248\n",
            "[217]\ttrain-mlogloss:0.70685\teval-mlogloss:1.03128\n",
            "[218]\ttrain-mlogloss:0.70474\teval-mlogloss:1.03017\n",
            "[219]\ttrain-mlogloss:0.70267\teval-mlogloss:1.02908\n",
            "[220]\ttrain-mlogloss:0.70061\teval-mlogloss:1.02782\n",
            "[221]\ttrain-mlogloss:0.69870\teval-mlogloss:1.02713\n",
            "[222]\ttrain-mlogloss:0.69675\teval-mlogloss:1.02625\n",
            "[223]\ttrain-mlogloss:0.69474\teval-mlogloss:1.02491\n",
            "[224]\ttrain-mlogloss:0.69282\teval-mlogloss:1.02410\n",
            "[225]\ttrain-mlogloss:0.69079\teval-mlogloss:1.02338\n",
            "[226]\ttrain-mlogloss:0.68892\teval-mlogloss:1.02236\n",
            "[227]\ttrain-mlogloss:0.68701\teval-mlogloss:1.02128\n",
            "[228]\ttrain-mlogloss:0.68512\teval-mlogloss:1.02019\n",
            "[229]\ttrain-mlogloss:0.68331\teval-mlogloss:1.01937\n",
            "[230]\ttrain-mlogloss:0.68132\teval-mlogloss:1.01848\n",
            "[231]\ttrain-mlogloss:0.67944\teval-mlogloss:1.01778\n",
            "[232]\ttrain-mlogloss:0.67753\teval-mlogloss:1.01690\n",
            "[233]\ttrain-mlogloss:0.67559\teval-mlogloss:1.01562\n",
            "[234]\ttrain-mlogloss:0.67370\teval-mlogloss:1.01442\n",
            "[235]\ttrain-mlogloss:0.67171\teval-mlogloss:1.01332\n",
            "[236]\ttrain-mlogloss:0.66985\teval-mlogloss:1.01258\n",
            "[237]\ttrain-mlogloss:0.66802\teval-mlogloss:1.01171\n",
            "[238]\ttrain-mlogloss:0.66609\teval-mlogloss:1.01069\n",
            "[239]\ttrain-mlogloss:0.66419\teval-mlogloss:1.00945\n",
            "[240]\ttrain-mlogloss:0.66232\teval-mlogloss:1.00855\n",
            "[241]\ttrain-mlogloss:0.66064\teval-mlogloss:1.00794\n",
            "[242]\ttrain-mlogloss:0.65869\teval-mlogloss:1.00694\n",
            "[243]\ttrain-mlogloss:0.65680\teval-mlogloss:1.00586\n",
            "[244]\ttrain-mlogloss:0.65512\teval-mlogloss:1.00530\n",
            "[245]\ttrain-mlogloss:0.65337\teval-mlogloss:1.00429\n",
            "[246]\ttrain-mlogloss:0.65159\teval-mlogloss:1.00369\n",
            "[247]\ttrain-mlogloss:0.64981\teval-mlogloss:1.00284\n",
            "[248]\ttrain-mlogloss:0.64818\teval-mlogloss:1.00194\n",
            "[249]\ttrain-mlogloss:0.64641\teval-mlogloss:1.00156\n",
            "[250]\ttrain-mlogloss:0.64464\teval-mlogloss:1.00083\n",
            "[251]\ttrain-mlogloss:0.64292\teval-mlogloss:1.00021\n",
            "[252]\ttrain-mlogloss:0.64121\teval-mlogloss:0.99941\n",
            "[253]\ttrain-mlogloss:0.63980\teval-mlogloss:0.99865\n",
            "[254]\ttrain-mlogloss:0.63810\teval-mlogloss:0.99806\n",
            "[255]\ttrain-mlogloss:0.63658\teval-mlogloss:0.99749\n",
            "[256]\ttrain-mlogloss:0.63493\teval-mlogloss:0.99643\n",
            "[257]\ttrain-mlogloss:0.63332\teval-mlogloss:0.99558\n",
            "[258]\ttrain-mlogloss:0.63177\teval-mlogloss:0.99529\n",
            "[259]\ttrain-mlogloss:0.63016\teval-mlogloss:0.99501\n",
            "[260]\ttrain-mlogloss:0.62848\teval-mlogloss:0.99421\n",
            "[261]\ttrain-mlogloss:0.62688\teval-mlogloss:0.99332\n",
            "[262]\ttrain-mlogloss:0.62528\teval-mlogloss:0.99260\n",
            "[263]\ttrain-mlogloss:0.62370\teval-mlogloss:0.99191\n",
            "[264]\ttrain-mlogloss:0.62211\teval-mlogloss:0.99116\n",
            "[265]\ttrain-mlogloss:0.62051\teval-mlogloss:0.99012\n",
            "[266]\ttrain-mlogloss:0.61898\teval-mlogloss:0.98915\n",
            "[267]\ttrain-mlogloss:0.61749\teval-mlogloss:0.98832\n",
            "[268]\ttrain-mlogloss:0.61596\teval-mlogloss:0.98716\n",
            "[269]\ttrain-mlogloss:0.61438\teval-mlogloss:0.98631\n",
            "[270]\ttrain-mlogloss:0.61283\teval-mlogloss:0.98546\n",
            "[271]\ttrain-mlogloss:0.61133\teval-mlogloss:0.98487\n",
            "[272]\ttrain-mlogloss:0.60985\teval-mlogloss:0.98428\n",
            "[273]\ttrain-mlogloss:0.60836\teval-mlogloss:0.98367\n",
            "[274]\ttrain-mlogloss:0.60687\teval-mlogloss:0.98293\n",
            "[275]\ttrain-mlogloss:0.60542\teval-mlogloss:0.98232\n",
            "[276]\ttrain-mlogloss:0.60399\teval-mlogloss:0.98155\n",
            "[277]\ttrain-mlogloss:0.60239\teval-mlogloss:0.98104\n",
            "[278]\ttrain-mlogloss:0.60084\teval-mlogloss:0.98041\n",
            "[279]\ttrain-mlogloss:0.59940\teval-mlogloss:0.97949\n",
            "[280]\ttrain-mlogloss:0.59787\teval-mlogloss:0.97854\n",
            "[281]\ttrain-mlogloss:0.59644\teval-mlogloss:0.97809\n",
            "[282]\ttrain-mlogloss:0.59506\teval-mlogloss:0.97726\n",
            "[283]\ttrain-mlogloss:0.59369\teval-mlogloss:0.97643\n",
            "[284]\ttrain-mlogloss:0.59227\teval-mlogloss:0.97594\n",
            "[285]\ttrain-mlogloss:0.59082\teval-mlogloss:0.97542\n",
            "[286]\ttrain-mlogloss:0.58937\teval-mlogloss:0.97482\n",
            "[287]\ttrain-mlogloss:0.58800\teval-mlogloss:0.97430\n",
            "[288]\ttrain-mlogloss:0.58665\teval-mlogloss:0.97370\n",
            "[289]\ttrain-mlogloss:0.58532\teval-mlogloss:0.97328\n",
            "[290]\ttrain-mlogloss:0.58396\teval-mlogloss:0.97279\n",
            "[291]\ttrain-mlogloss:0.58263\teval-mlogloss:0.97218\n",
            "[292]\ttrain-mlogloss:0.58117\teval-mlogloss:0.97167\n",
            "[293]\ttrain-mlogloss:0.57977\teval-mlogloss:0.97106\n",
            "[294]\ttrain-mlogloss:0.57834\teval-mlogloss:0.97083\n",
            "[295]\ttrain-mlogloss:0.57692\teval-mlogloss:0.97011\n",
            "[296]\ttrain-mlogloss:0.57560\teval-mlogloss:0.96974\n",
            "[297]\ttrain-mlogloss:0.57423\teval-mlogloss:0.96923\n",
            "[298]\ttrain-mlogloss:0.57289\teval-mlogloss:0.96873\n",
            "[299]\ttrain-mlogloss:0.57164\teval-mlogloss:0.96836\n",
            "[300]\ttrain-mlogloss:0.57029\teval-mlogloss:0.96795\n",
            "[301]\ttrain-mlogloss:0.56894\teval-mlogloss:0.96728\n",
            "[302]\ttrain-mlogloss:0.56764\teval-mlogloss:0.96711\n",
            "[303]\ttrain-mlogloss:0.56646\teval-mlogloss:0.96678\n",
            "[304]\ttrain-mlogloss:0.56514\teval-mlogloss:0.96605\n",
            "[305]\ttrain-mlogloss:0.56392\teval-mlogloss:0.96556\n",
            "[306]\ttrain-mlogloss:0.56252\teval-mlogloss:0.96541\n",
            "[307]\ttrain-mlogloss:0.56116\teval-mlogloss:0.96483\n",
            "[308]\ttrain-mlogloss:0.55994\teval-mlogloss:0.96422\n",
            "[309]\ttrain-mlogloss:0.55861\teval-mlogloss:0.96363\n",
            "[310]\ttrain-mlogloss:0.55729\teval-mlogloss:0.96290\n",
            "[311]\ttrain-mlogloss:0.55599\teval-mlogloss:0.96226\n",
            "[312]\ttrain-mlogloss:0.55472\teval-mlogloss:0.96169\n",
            "[313]\ttrain-mlogloss:0.55352\teval-mlogloss:0.96132\n",
            "[314]\ttrain-mlogloss:0.55219\teval-mlogloss:0.96071\n",
            "[315]\ttrain-mlogloss:0.55086\teval-mlogloss:0.96019\n",
            "[316]\ttrain-mlogloss:0.54968\teval-mlogloss:0.95986\n",
            "[317]\ttrain-mlogloss:0.54845\teval-mlogloss:0.95929\n",
            "[318]\ttrain-mlogloss:0.54714\teval-mlogloss:0.95851\n",
            "[319]\ttrain-mlogloss:0.54585\teval-mlogloss:0.95804\n",
            "[320]\ttrain-mlogloss:0.54471\teval-mlogloss:0.95758\n",
            "[321]\ttrain-mlogloss:0.54344\teval-mlogloss:0.95697\n",
            "[322]\ttrain-mlogloss:0.54213\teval-mlogloss:0.95648\n",
            "[323]\ttrain-mlogloss:0.54092\teval-mlogloss:0.95617\n",
            "[324]\ttrain-mlogloss:0.53963\teval-mlogloss:0.95550\n",
            "[325]\ttrain-mlogloss:0.53842\teval-mlogloss:0.95520\n",
            "[326]\ttrain-mlogloss:0.53728\teval-mlogloss:0.95468\n",
            "[327]\ttrain-mlogloss:0.53599\teval-mlogloss:0.95421\n",
            "[328]\ttrain-mlogloss:0.53485\teval-mlogloss:0.95399\n",
            "[329]\ttrain-mlogloss:0.53368\teval-mlogloss:0.95333\n",
            "[330]\ttrain-mlogloss:0.53248\teval-mlogloss:0.95275\n",
            "[331]\ttrain-mlogloss:0.53138\teval-mlogloss:0.95239\n",
            "[332]\ttrain-mlogloss:0.53031\teval-mlogloss:0.95198\n",
            "[333]\ttrain-mlogloss:0.52910\teval-mlogloss:0.95192\n",
            "[334]\ttrain-mlogloss:0.52797\teval-mlogloss:0.95149\n",
            "[335]\ttrain-mlogloss:0.52681\teval-mlogloss:0.95118\n",
            "[336]\ttrain-mlogloss:0.52557\teval-mlogloss:0.95053\n",
            "[337]\ttrain-mlogloss:0.52444\teval-mlogloss:0.94994\n",
            "[338]\ttrain-mlogloss:0.52332\teval-mlogloss:0.94943\n",
            "[339]\ttrain-mlogloss:0.52213\teval-mlogloss:0.94910\n",
            "[340]\ttrain-mlogloss:0.52113\teval-mlogloss:0.94882\n",
            "[341]\ttrain-mlogloss:0.51996\teval-mlogloss:0.94834\n",
            "[342]\ttrain-mlogloss:0.51890\teval-mlogloss:0.94795\n",
            "[343]\ttrain-mlogloss:0.51777\teval-mlogloss:0.94763\n",
            "[344]\ttrain-mlogloss:0.51669\teval-mlogloss:0.94757\n",
            "[345]\ttrain-mlogloss:0.51559\teval-mlogloss:0.94748\n",
            "[346]\ttrain-mlogloss:0.51453\teval-mlogloss:0.94729\n",
            "[347]\ttrain-mlogloss:0.51353\teval-mlogloss:0.94726\n",
            "[348]\ttrain-mlogloss:0.51243\teval-mlogloss:0.94680\n",
            "[349]\ttrain-mlogloss:0.51135\teval-mlogloss:0.94636\n",
            "[350]\ttrain-mlogloss:0.51034\teval-mlogloss:0.94628\n",
            "[351]\ttrain-mlogloss:0.50934\teval-mlogloss:0.94555\n",
            "[352]\ttrain-mlogloss:0.50830\teval-mlogloss:0.94513\n",
            "[353]\ttrain-mlogloss:0.50723\teval-mlogloss:0.94446\n",
            "[354]\ttrain-mlogloss:0.50623\teval-mlogloss:0.94412\n",
            "[355]\ttrain-mlogloss:0.50535\teval-mlogloss:0.94385\n",
            "[356]\ttrain-mlogloss:0.50443\teval-mlogloss:0.94383\n",
            "[357]\ttrain-mlogloss:0.50339\teval-mlogloss:0.94354\n",
            "[358]\ttrain-mlogloss:0.50239\teval-mlogloss:0.94297\n",
            "[359]\ttrain-mlogloss:0.50147\teval-mlogloss:0.94257\n",
            "[360]\ttrain-mlogloss:0.50041\teval-mlogloss:0.94234\n",
            "[361]\ttrain-mlogloss:0.49949\teval-mlogloss:0.94167\n",
            "[362]\ttrain-mlogloss:0.49847\teval-mlogloss:0.94144\n",
            "[363]\ttrain-mlogloss:0.49744\teval-mlogloss:0.94135\n",
            "[364]\ttrain-mlogloss:0.49649\teval-mlogloss:0.94098\n",
            "[365]\ttrain-mlogloss:0.49556\teval-mlogloss:0.94105\n",
            "[366]\ttrain-mlogloss:0.49465\teval-mlogloss:0.94128\n",
            "[367]\ttrain-mlogloss:0.49377\teval-mlogloss:0.94134\n",
            "[368]\ttrain-mlogloss:0.49277\teval-mlogloss:0.94084\n",
            "[369]\ttrain-mlogloss:0.49192\teval-mlogloss:0.94071\n",
            "[370]\ttrain-mlogloss:0.49102\teval-mlogloss:0.94034\n",
            "[371]\ttrain-mlogloss:0.49011\teval-mlogloss:0.94015\n",
            "[372]\ttrain-mlogloss:0.48909\teval-mlogloss:0.94018\n",
            "[373]\ttrain-mlogloss:0.48817\teval-mlogloss:0.94009\n",
            "[374]\ttrain-mlogloss:0.48717\teval-mlogloss:0.93990\n",
            "[375]\ttrain-mlogloss:0.48625\teval-mlogloss:0.94000\n",
            "[376]\ttrain-mlogloss:0.48534\teval-mlogloss:0.93972\n",
            "[377]\ttrain-mlogloss:0.48444\teval-mlogloss:0.93960\n",
            "[378]\ttrain-mlogloss:0.48348\teval-mlogloss:0.93950\n",
            "[379]\ttrain-mlogloss:0.48251\teval-mlogloss:0.93917\n",
            "[380]\ttrain-mlogloss:0.48159\teval-mlogloss:0.93913\n",
            "[381]\ttrain-mlogloss:0.48068\teval-mlogloss:0.93875\n",
            "[382]\ttrain-mlogloss:0.47972\teval-mlogloss:0.93851\n",
            "[383]\ttrain-mlogloss:0.47884\teval-mlogloss:0.93822\n",
            "[384]\ttrain-mlogloss:0.47805\teval-mlogloss:0.93798\n",
            "[385]\ttrain-mlogloss:0.47715\teval-mlogloss:0.93773\n",
            "[386]\ttrain-mlogloss:0.47628\teval-mlogloss:0.93749\n",
            "[387]\ttrain-mlogloss:0.47547\teval-mlogloss:0.93727\n",
            "[388]\ttrain-mlogloss:0.47451\teval-mlogloss:0.93699\n",
            "[389]\ttrain-mlogloss:0.47369\teval-mlogloss:0.93656\n",
            "[390]\ttrain-mlogloss:0.47278\teval-mlogloss:0.93654\n",
            "[391]\ttrain-mlogloss:0.47197\teval-mlogloss:0.93629\n",
            "[392]\ttrain-mlogloss:0.47114\teval-mlogloss:0.93604\n",
            "[393]\ttrain-mlogloss:0.47034\teval-mlogloss:0.93594\n",
            "[394]\ttrain-mlogloss:0.46955\teval-mlogloss:0.93580\n",
            "[395]\ttrain-mlogloss:0.46866\teval-mlogloss:0.93548\n",
            "[396]\ttrain-mlogloss:0.46775\teval-mlogloss:0.93520\n",
            "[397]\ttrain-mlogloss:0.46694\teval-mlogloss:0.93506\n",
            "[398]\ttrain-mlogloss:0.46606\teval-mlogloss:0.93487\n",
            "[399]\ttrain-mlogloss:0.46528\teval-mlogloss:0.93449\n",
            "[400]\ttrain-mlogloss:0.46443\teval-mlogloss:0.93459\n",
            "[401]\ttrain-mlogloss:0.46366\teval-mlogloss:0.93418\n",
            "[402]\ttrain-mlogloss:0.46281\teval-mlogloss:0.93387\n",
            "[403]\ttrain-mlogloss:0.46190\teval-mlogloss:0.93375\n",
            "[404]\ttrain-mlogloss:0.46105\teval-mlogloss:0.93338\n",
            "[405]\ttrain-mlogloss:0.46024\teval-mlogloss:0.93327\n",
            "[406]\ttrain-mlogloss:0.45950\teval-mlogloss:0.93320\n",
            "[407]\ttrain-mlogloss:0.45863\teval-mlogloss:0.93327\n",
            "[408]\ttrain-mlogloss:0.45785\teval-mlogloss:0.93301\n",
            "[409]\ttrain-mlogloss:0.45706\teval-mlogloss:0.93304\n",
            "[410]\ttrain-mlogloss:0.45629\teval-mlogloss:0.93285\n",
            "[411]\ttrain-mlogloss:0.45555\teval-mlogloss:0.93277\n",
            "[412]\ttrain-mlogloss:0.45479\teval-mlogloss:0.93267\n",
            "[413]\ttrain-mlogloss:0.45410\teval-mlogloss:0.93256\n",
            "[414]\ttrain-mlogloss:0.45332\teval-mlogloss:0.93265\n",
            "[415]\ttrain-mlogloss:0.45255\teval-mlogloss:0.93251\n",
            "[416]\ttrain-mlogloss:0.45179\teval-mlogloss:0.93247\n",
            "[417]\ttrain-mlogloss:0.45103\teval-mlogloss:0.93264\n",
            "[418]\ttrain-mlogloss:0.45027\teval-mlogloss:0.93239\n",
            "[419]\ttrain-mlogloss:0.44956\teval-mlogloss:0.93212\n",
            "[420]\ttrain-mlogloss:0.44878\teval-mlogloss:0.93229\n",
            "[421]\ttrain-mlogloss:0.44803\teval-mlogloss:0.93241\n",
            "[422]\ttrain-mlogloss:0.44732\teval-mlogloss:0.93223\n",
            "[423]\ttrain-mlogloss:0.44658\teval-mlogloss:0.93210\n",
            "[424]\ttrain-mlogloss:0.44583\teval-mlogloss:0.93210\n",
            "[425]\ttrain-mlogloss:0.44509\teval-mlogloss:0.93194\n",
            "[426]\ttrain-mlogloss:0.44444\teval-mlogloss:0.93195\n",
            "[427]\ttrain-mlogloss:0.44365\teval-mlogloss:0.93176\n",
            "[428]\ttrain-mlogloss:0.44295\teval-mlogloss:0.93135\n",
            "[429]\ttrain-mlogloss:0.44219\teval-mlogloss:0.93082\n",
            "[430]\ttrain-mlogloss:0.44145\teval-mlogloss:0.93076\n",
            "[431]\ttrain-mlogloss:0.44075\teval-mlogloss:0.93040\n",
            "[432]\ttrain-mlogloss:0.44013\teval-mlogloss:0.93027\n",
            "[433]\ttrain-mlogloss:0.43942\teval-mlogloss:0.93046\n",
            "[434]\ttrain-mlogloss:0.43870\teval-mlogloss:0.93028\n",
            "[435]\ttrain-mlogloss:0.43798\teval-mlogloss:0.93015\n",
            "[436]\ttrain-mlogloss:0.43733\teval-mlogloss:0.93033\n",
            "[437]\ttrain-mlogloss:0.43664\teval-mlogloss:0.92995\n",
            "[438]\ttrain-mlogloss:0.43597\teval-mlogloss:0.92977\n",
            "[439]\ttrain-mlogloss:0.43526\teval-mlogloss:0.92949\n",
            "[440]\ttrain-mlogloss:0.43461\teval-mlogloss:0.92963\n",
            "[441]\ttrain-mlogloss:0.43392\teval-mlogloss:0.92940\n",
            "[442]\ttrain-mlogloss:0.43323\teval-mlogloss:0.92947\n",
            "[443]\ttrain-mlogloss:0.43251\teval-mlogloss:0.92958\n",
            "[444]\ttrain-mlogloss:0.43186\teval-mlogloss:0.92914\n",
            "[445]\ttrain-mlogloss:0.43118\teval-mlogloss:0.92907\n",
            "[446]\ttrain-mlogloss:0.43050\teval-mlogloss:0.92892\n",
            "[447]\ttrain-mlogloss:0.42986\teval-mlogloss:0.92897\n",
            "[448]\ttrain-mlogloss:0.42914\teval-mlogloss:0.92880\n",
            "[449]\ttrain-mlogloss:0.42847\teval-mlogloss:0.92847\n",
            "[450]\ttrain-mlogloss:0.42779\teval-mlogloss:0.92831\n",
            "[451]\ttrain-mlogloss:0.42715\teval-mlogloss:0.92821\n",
            "[452]\ttrain-mlogloss:0.42649\teval-mlogloss:0.92802\n",
            "[453]\ttrain-mlogloss:0.42587\teval-mlogloss:0.92764\n",
            "[454]\ttrain-mlogloss:0.42521\teval-mlogloss:0.92758\n",
            "[455]\ttrain-mlogloss:0.42456\teval-mlogloss:0.92747\n",
            "[456]\ttrain-mlogloss:0.42393\teval-mlogloss:0.92751\n",
            "[457]\ttrain-mlogloss:0.42321\teval-mlogloss:0.92718\n",
            "[458]\ttrain-mlogloss:0.42261\teval-mlogloss:0.92737\n",
            "[459]\ttrain-mlogloss:0.42195\teval-mlogloss:0.92724\n",
            "[460]\ttrain-mlogloss:0.42131\teval-mlogloss:0.92688\n",
            "[461]\ttrain-mlogloss:0.42074\teval-mlogloss:0.92693\n",
            "[462]\ttrain-mlogloss:0.42015\teval-mlogloss:0.92664\n",
            "[463]\ttrain-mlogloss:0.41956\teval-mlogloss:0.92649\n",
            "[464]\ttrain-mlogloss:0.41897\teval-mlogloss:0.92664\n",
            "[465]\ttrain-mlogloss:0.41840\teval-mlogloss:0.92642\n",
            "[466]\ttrain-mlogloss:0.41779\teval-mlogloss:0.92642\n",
            "[467]\ttrain-mlogloss:0.41718\teval-mlogloss:0.92631\n",
            "[468]\ttrain-mlogloss:0.41658\teval-mlogloss:0.92604\n",
            "[469]\ttrain-mlogloss:0.41602\teval-mlogloss:0.92590\n",
            "[470]\ttrain-mlogloss:0.41533\teval-mlogloss:0.92566\n",
            "[471]\ttrain-mlogloss:0.41467\teval-mlogloss:0.92548\n",
            "[472]\ttrain-mlogloss:0.41408\teval-mlogloss:0.92541\n",
            "[473]\ttrain-mlogloss:0.41349\teval-mlogloss:0.92523\n",
            "[474]\ttrain-mlogloss:0.41298\teval-mlogloss:0.92521\n",
            "[475]\ttrain-mlogloss:0.41242\teval-mlogloss:0.92491\n",
            "[476]\ttrain-mlogloss:0.41190\teval-mlogloss:0.92494\n",
            "[477]\ttrain-mlogloss:0.41133\teval-mlogloss:0.92500\n",
            "[478]\ttrain-mlogloss:0.41079\teval-mlogloss:0.92501\n",
            "[479]\ttrain-mlogloss:0.41026\teval-mlogloss:0.92478\n",
            "[480]\ttrain-mlogloss:0.40970\teval-mlogloss:0.92468\n",
            "[481]\ttrain-mlogloss:0.40915\teval-mlogloss:0.92458\n",
            "[482]\ttrain-mlogloss:0.40861\teval-mlogloss:0.92458\n",
            "[483]\ttrain-mlogloss:0.40807\teval-mlogloss:0.92465\n",
            "[484]\ttrain-mlogloss:0.40754\teval-mlogloss:0.92486\n",
            "[485]\ttrain-mlogloss:0.40698\teval-mlogloss:0.92450\n",
            "[486]\ttrain-mlogloss:0.40648\teval-mlogloss:0.92433\n",
            "[487]\ttrain-mlogloss:0.40593\teval-mlogloss:0.92415\n",
            "[488]\ttrain-mlogloss:0.40537\teval-mlogloss:0.92397\n",
            "[489]\ttrain-mlogloss:0.40484\teval-mlogloss:0.92401\n",
            "[490]\ttrain-mlogloss:0.40427\teval-mlogloss:0.92386\n",
            "[491]\ttrain-mlogloss:0.40372\teval-mlogloss:0.92386\n",
            "[492]\ttrain-mlogloss:0.40314\teval-mlogloss:0.92402\n",
            "[493]\ttrain-mlogloss:0.40266\teval-mlogloss:0.92410\n",
            "[494]\ttrain-mlogloss:0.40215\teval-mlogloss:0.92405\n",
            "[495]\ttrain-mlogloss:0.40166\teval-mlogloss:0.92396\n",
            "[496]\ttrain-mlogloss:0.40114\teval-mlogloss:0.92409\n",
            "[497]\ttrain-mlogloss:0.40061\teval-mlogloss:0.92401\n",
            "[498]\ttrain-mlogloss:0.40017\teval-mlogloss:0.92407\n",
            "[499]\ttrain-mlogloss:0.39964\teval-mlogloss:0.92399\n",
            "[500]\ttrain-mlogloss:0.39919\teval-mlogloss:0.92416\n",
            "[501]\ttrain-mlogloss:0.39871\teval-mlogloss:0.92408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = trained_model.predict(DMatrix(X_train)).argmax(axis=1)\n",
        "print(\"XGBoost Classification Report for training set:\")\n",
        "print(classification_report(y_train, y_pred_train, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrWzc54SsTiX",
        "outputId": "5c563b3c-0daf-4858-ac32-b1b926bc7573"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Classification Report for training set:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "  Responsivenss       0.91      0.97      0.94       276\n",
            "       feedback       0.92      0.48      0.63        25\n",
            "health benefits       0.80      0.43      0.56        28\n",
            "     medication       0.81      0.89      0.85       120\n",
            "        pa code       0.80      0.83      0.81        76\n",
            " staff attitude       0.95      0.78      0.86        27\n",
            "   waiting time       0.87      0.68      0.76        19\n",
            "\n",
            "       accuracy                           0.87       571\n",
            "      macro avg       0.87      0.72      0.77       571\n",
            "   weighted avg       0.87      0.87      0.86       571\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = trained_model.predict(DMatrix(X_test)).argmax(axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(\"XGBoost Classification Report with Evaluation Set:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOnXegZBsnLG",
        "outputId": "43cad2a3-c46a-472c-e4ba-04943f4e43ab"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Classification Report with Evaluation Set:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "  Responsivenss       0.84      0.97      0.90        74\n",
            "       feedback       0.50      0.14      0.22         7\n",
            "health benefits       0.50      0.14      0.22         7\n",
            "     medication       0.89      0.78      0.83        32\n",
            "        pa code       0.52      0.69      0.59        16\n",
            " staff attitude       0.50      0.50      0.50         4\n",
            "   waiting time       0.00      0.00      0.00         3\n",
            "\n",
            "       accuracy                           0.78       143\n",
            "      macro avg       0.54      0.46      0.47       143\n",
            "   weighted avg       0.75      0.78      0.75       143\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Identify the indices where predictions do not match actual labels\n",
        "incorrect_indices = np.where(y_pred != y_test)[0]\n",
        "\n",
        "# Print out the misclassified sentences along with predicted and actual labels\n",
        "print(f\"\\nTotal incorrect predictions: {len(incorrect_indices)}\")\n",
        "for index in incorrect_indices:\n",
        "    print(f\"Sentence: '{responses_test.iloc[index]}'\")\n",
        "    print(f\"Predicted: '{label_encoder.inverse_transform([y_pred[index]])[0]}', Actual: '{label_encoder.inverse_transform([y_test.iloc[index]])[0]}'\\n\")\n"
      ],
      "metadata": {
        "id": "8-ltpsyfsnIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NPS wrong answers analyzing"
      ],
      "metadata": {
        "id": "7UsvWw0_u3Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "filtered_NPS_data['filtered_category_encoded'] = label_encoder.fit_transform(filtered_NPS_data['Grouped_Sub-driver'])\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
        "clean_vectors = vectorizer.fit_transform(filtered_NPS_data['CUSTOMER_RESPONSE'])\n",
        "X_train, X_test, y_train, y_test, responses_train, responses_test = train_test_split(\n",
        "    clean_vectors,\n",
        "    filtered_NPS_data['filtered_category_encoded'],\n",
        "    filtered_NPS_data['CUSTOMER_RESPONSE'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2, responses_train2, responses_test2 = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    responses_train,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dtrain = DMatrix(X_train2, label=y_train2)\n",
        "dtest = DMatrix(X_test2, label=y_test2)\n",
        "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "# Training the XGBoost model\n",
        "trained_model = xgb.train(\n",
        "    param_grid,\n",
        "    dtrain,\n",
        "    evals=evallist,\n",
        "    num_boost_round=2000,\n",
        "    early_stopping_rounds=10\n",
        ")\n",
        "\n",
        "# Calculate predictions for the test set\n",
        "y_pred = trained_model.predict(DMatrix(X_test)).argmax(axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(\"XGBoost Classification Report with Evaluation Set:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Identify the indices where predictions do not match actual labels\n",
        "incorrect_indices = np.where(y_pred != y_test)[0]\n",
        "\n",
        "# Print out the misclassified sentences along with predicted and actual labels\n",
        "print(f\"\\nTotal incorrect predictions: {len(incorrect_indices)}\")\n",
        "for index in incorrect_indices:\n",
        "    print(f\"Sentence: '{responses_test.iloc[index]}'\")\n",
        "    print(f\"Predicted: '{label_encoder.inverse_transform([y_pred[index]])[0]}', Actual: '{label_encoder.inverse_transform([y_test.iloc[index]])[0]}'\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv-7yC4dsnFo",
        "outputId": "98a0d351-d2fd-4694-898b-4e2464569173"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-1fa633fcb126>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_NPS_data['filtered_category_encoded'] = label_encoder.fit_transform(filtered_NPS_data['Grouped_Sub-driver'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.92758\teval-mlogloss:1.92826\n",
            "[1]\ttrain-mlogloss:1.90983\teval-mlogloss:1.91130\n",
            "[2]\ttrain-mlogloss:1.89684\teval-mlogloss:1.89980\n",
            "[3]\ttrain-mlogloss:1.88176\teval-mlogloss:1.88588\n",
            "[4]\ttrain-mlogloss:1.86562\teval-mlogloss:1.87170\n",
            "[5]\ttrain-mlogloss:1.85123\teval-mlogloss:1.85948\n",
            "[6]\ttrain-mlogloss:1.83623\teval-mlogloss:1.84531\n",
            "[7]\ttrain-mlogloss:1.82182\teval-mlogloss:1.83229\n",
            "[8]\ttrain-mlogloss:1.80701\teval-mlogloss:1.81846\n",
            "[9]\ttrain-mlogloss:1.79421\teval-mlogloss:1.80807\n",
            "[10]\ttrain-mlogloss:1.78231\teval-mlogloss:1.79802\n",
            "[11]\ttrain-mlogloss:1.76754\teval-mlogloss:1.78423\n",
            "[12]\ttrain-mlogloss:1.75517\teval-mlogloss:1.77305\n",
            "[13]\ttrain-mlogloss:1.74079\teval-mlogloss:1.76009\n",
            "[14]\ttrain-mlogloss:1.72933\teval-mlogloss:1.75092\n",
            "[15]\ttrain-mlogloss:1.71601\teval-mlogloss:1.73889\n",
            "[16]\ttrain-mlogloss:1.70357\teval-mlogloss:1.72714\n",
            "[17]\ttrain-mlogloss:1.69121\teval-mlogloss:1.71568\n",
            "[18]\ttrain-mlogloss:1.67895\teval-mlogloss:1.70412\n",
            "[19]\ttrain-mlogloss:1.66695\teval-mlogloss:1.69310\n",
            "[20]\ttrain-mlogloss:1.65544\teval-mlogloss:1.68249\n",
            "[21]\ttrain-mlogloss:1.64390\teval-mlogloss:1.67270\n",
            "[22]\ttrain-mlogloss:1.63243\teval-mlogloss:1.66210\n",
            "[23]\ttrain-mlogloss:1.62170\teval-mlogloss:1.65245\n",
            "[24]\ttrain-mlogloss:1.61105\teval-mlogloss:1.64270\n",
            "[25]\ttrain-mlogloss:1.60067\teval-mlogloss:1.63286\n",
            "[26]\ttrain-mlogloss:1.58987\teval-mlogloss:1.62346\n",
            "[27]\ttrain-mlogloss:1.58050\teval-mlogloss:1.61470\n",
            "[28]\ttrain-mlogloss:1.56989\teval-mlogloss:1.60515\n",
            "[29]\ttrain-mlogloss:1.55921\teval-mlogloss:1.59543\n",
            "[30]\ttrain-mlogloss:1.55002\teval-mlogloss:1.58779\n",
            "[31]\ttrain-mlogloss:1.54000\teval-mlogloss:1.57877\n",
            "[32]\ttrain-mlogloss:1.52959\teval-mlogloss:1.56921\n",
            "[33]\ttrain-mlogloss:1.52062\teval-mlogloss:1.56188\n",
            "[34]\ttrain-mlogloss:1.51071\teval-mlogloss:1.55294\n",
            "[35]\ttrain-mlogloss:1.50165\teval-mlogloss:1.54454\n",
            "[36]\ttrain-mlogloss:1.49244\teval-mlogloss:1.53671\n",
            "[37]\ttrain-mlogloss:1.48282\teval-mlogloss:1.52825\n",
            "[38]\ttrain-mlogloss:1.47313\teval-mlogloss:1.51942\n",
            "[39]\ttrain-mlogloss:1.46383\teval-mlogloss:1.51108\n",
            "[40]\ttrain-mlogloss:1.45481\teval-mlogloss:1.50332\n",
            "[41]\ttrain-mlogloss:1.44605\teval-mlogloss:1.49529\n",
            "[42]\ttrain-mlogloss:1.43700\teval-mlogloss:1.48738\n",
            "[43]\ttrain-mlogloss:1.42811\teval-mlogloss:1.47942\n",
            "[44]\ttrain-mlogloss:1.41937\teval-mlogloss:1.47162\n",
            "[45]\ttrain-mlogloss:1.41161\teval-mlogloss:1.46505\n",
            "[46]\ttrain-mlogloss:1.40373\teval-mlogloss:1.45769\n",
            "[47]\ttrain-mlogloss:1.39555\teval-mlogloss:1.45073\n",
            "[48]\ttrain-mlogloss:1.38741\teval-mlogloss:1.44339\n",
            "[49]\ttrain-mlogloss:1.37915\teval-mlogloss:1.43595\n",
            "[50]\ttrain-mlogloss:1.37163\teval-mlogloss:1.42960\n",
            "[51]\ttrain-mlogloss:1.36375\teval-mlogloss:1.42301\n",
            "[52]\ttrain-mlogloss:1.35650\teval-mlogloss:1.41686\n",
            "[53]\ttrain-mlogloss:1.34942\teval-mlogloss:1.41146\n",
            "[54]\ttrain-mlogloss:1.34274\teval-mlogloss:1.40568\n",
            "[55]\ttrain-mlogloss:1.33571\teval-mlogloss:1.39920\n",
            "[56]\ttrain-mlogloss:1.32819\teval-mlogloss:1.39233\n",
            "[57]\ttrain-mlogloss:1.32080\teval-mlogloss:1.38589\n",
            "[58]\ttrain-mlogloss:1.31375\teval-mlogloss:1.38039\n",
            "[59]\ttrain-mlogloss:1.30667\teval-mlogloss:1.37437\n",
            "[60]\ttrain-mlogloss:1.30042\teval-mlogloss:1.36912\n",
            "[61]\ttrain-mlogloss:1.29394\teval-mlogloss:1.36401\n",
            "[62]\ttrain-mlogloss:1.28748\teval-mlogloss:1.35874\n",
            "[63]\ttrain-mlogloss:1.28054\teval-mlogloss:1.35289\n",
            "[64]\ttrain-mlogloss:1.27450\teval-mlogloss:1.34822\n",
            "[65]\ttrain-mlogloss:1.26801\teval-mlogloss:1.34297\n",
            "[66]\ttrain-mlogloss:1.26159\teval-mlogloss:1.33778\n",
            "[67]\ttrain-mlogloss:1.25520\teval-mlogloss:1.33225\n",
            "[68]\ttrain-mlogloss:1.24881\teval-mlogloss:1.32689\n",
            "[69]\ttrain-mlogloss:1.24315\teval-mlogloss:1.32227\n",
            "[70]\ttrain-mlogloss:1.23696\teval-mlogloss:1.31672\n",
            "[71]\ttrain-mlogloss:1.23079\teval-mlogloss:1.31187\n",
            "[72]\ttrain-mlogloss:1.22460\teval-mlogloss:1.30658\n",
            "[73]\ttrain-mlogloss:1.21858\teval-mlogloss:1.30152\n",
            "[74]\ttrain-mlogloss:1.21344\teval-mlogloss:1.29728\n",
            "[75]\ttrain-mlogloss:1.20755\teval-mlogloss:1.29259\n",
            "[76]\ttrain-mlogloss:1.20146\teval-mlogloss:1.28769\n",
            "[77]\ttrain-mlogloss:1.19570\teval-mlogloss:1.28292\n",
            "[78]\ttrain-mlogloss:1.18985\teval-mlogloss:1.27827\n",
            "[79]\ttrain-mlogloss:1.18459\teval-mlogloss:1.27405\n",
            "[80]\ttrain-mlogloss:1.17920\teval-mlogloss:1.26992\n",
            "[81]\ttrain-mlogloss:1.17424\teval-mlogloss:1.26642\n",
            "[82]\ttrain-mlogloss:1.16874\teval-mlogloss:1.26212\n",
            "[83]\ttrain-mlogloss:1.16302\teval-mlogloss:1.25746\n",
            "[84]\ttrain-mlogloss:1.15762\teval-mlogloss:1.25321\n",
            "[85]\ttrain-mlogloss:1.15208\teval-mlogloss:1.24852\n",
            "[86]\ttrain-mlogloss:1.14662\teval-mlogloss:1.24437\n",
            "[87]\ttrain-mlogloss:1.14136\teval-mlogloss:1.24015\n",
            "[88]\ttrain-mlogloss:1.13638\teval-mlogloss:1.23632\n",
            "[89]\ttrain-mlogloss:1.13098\teval-mlogloss:1.23221\n",
            "[90]\ttrain-mlogloss:1.12590\teval-mlogloss:1.22865\n",
            "[91]\ttrain-mlogloss:1.12076\teval-mlogloss:1.22433\n",
            "[92]\ttrain-mlogloss:1.11566\teval-mlogloss:1.22022\n",
            "[93]\ttrain-mlogloss:1.11058\teval-mlogloss:1.21646\n",
            "[94]\ttrain-mlogloss:1.10568\teval-mlogloss:1.21238\n",
            "[95]\ttrain-mlogloss:1.10057\teval-mlogloss:1.20847\n",
            "[96]\ttrain-mlogloss:1.09588\teval-mlogloss:1.20479\n",
            "[97]\ttrain-mlogloss:1.09116\teval-mlogloss:1.20132\n",
            "[98]\ttrain-mlogloss:1.08648\teval-mlogloss:1.19762\n",
            "[99]\ttrain-mlogloss:1.08206\teval-mlogloss:1.19446\n",
            "[100]\ttrain-mlogloss:1.07728\teval-mlogloss:1.19117\n",
            "[101]\ttrain-mlogloss:1.07248\teval-mlogloss:1.18796\n",
            "[102]\ttrain-mlogloss:1.06776\teval-mlogloss:1.18388\n",
            "[103]\ttrain-mlogloss:1.06318\teval-mlogloss:1.18030\n",
            "[104]\ttrain-mlogloss:1.05843\teval-mlogloss:1.17663\n",
            "[105]\ttrain-mlogloss:1.05357\teval-mlogloss:1.17307\n",
            "[106]\ttrain-mlogloss:1.04897\teval-mlogloss:1.16956\n",
            "[107]\ttrain-mlogloss:1.04437\teval-mlogloss:1.16630\n",
            "[108]\ttrain-mlogloss:1.03993\teval-mlogloss:1.16328\n",
            "[109]\ttrain-mlogloss:1.03569\teval-mlogloss:1.16013\n",
            "[110]\ttrain-mlogloss:1.03145\teval-mlogloss:1.15695\n",
            "[111]\ttrain-mlogloss:1.02717\teval-mlogloss:1.15411\n",
            "[112]\ttrain-mlogloss:1.02296\teval-mlogloss:1.15120\n",
            "[113]\ttrain-mlogloss:1.01889\teval-mlogloss:1.14814\n",
            "[114]\ttrain-mlogloss:1.01451\teval-mlogloss:1.14510\n",
            "[115]\ttrain-mlogloss:1.01022\teval-mlogloss:1.14210\n",
            "[116]\ttrain-mlogloss:1.00596\teval-mlogloss:1.13898\n",
            "[117]\ttrain-mlogloss:1.00184\teval-mlogloss:1.13602\n",
            "[118]\ttrain-mlogloss:0.99805\teval-mlogloss:1.13299\n",
            "[119]\ttrain-mlogloss:0.99381\teval-mlogloss:1.12994\n",
            "[120]\ttrain-mlogloss:0.98985\teval-mlogloss:1.12679\n",
            "[121]\ttrain-mlogloss:0.98628\teval-mlogloss:1.12413\n",
            "[122]\ttrain-mlogloss:0.98215\teval-mlogloss:1.12136\n",
            "[123]\ttrain-mlogloss:0.97849\teval-mlogloss:1.11842\n",
            "[124]\ttrain-mlogloss:0.97492\teval-mlogloss:1.11589\n",
            "[125]\ttrain-mlogloss:0.97123\teval-mlogloss:1.11342\n",
            "[126]\ttrain-mlogloss:0.96734\teval-mlogloss:1.11051\n",
            "[127]\ttrain-mlogloss:0.96353\teval-mlogloss:1.10804\n",
            "[128]\ttrain-mlogloss:0.95990\teval-mlogloss:1.10586\n",
            "[129]\ttrain-mlogloss:0.95628\teval-mlogloss:1.10339\n",
            "[130]\ttrain-mlogloss:0.95253\teval-mlogloss:1.10055\n",
            "[131]\ttrain-mlogloss:0.94878\teval-mlogloss:1.09810\n",
            "[132]\ttrain-mlogloss:0.94545\teval-mlogloss:1.09585\n",
            "[133]\ttrain-mlogloss:0.94224\teval-mlogloss:1.09348\n",
            "[134]\ttrain-mlogloss:0.93883\teval-mlogloss:1.09133\n",
            "[135]\ttrain-mlogloss:0.93527\teval-mlogloss:1.08899\n",
            "[136]\ttrain-mlogloss:0.93156\teval-mlogloss:1.08636\n",
            "[137]\ttrain-mlogloss:0.92809\teval-mlogloss:1.08432\n",
            "[138]\ttrain-mlogloss:0.92443\teval-mlogloss:1.08160\n",
            "[139]\ttrain-mlogloss:0.92122\teval-mlogloss:1.07963\n",
            "[140]\ttrain-mlogloss:0.91769\teval-mlogloss:1.07724\n",
            "[141]\ttrain-mlogloss:0.91427\teval-mlogloss:1.07494\n",
            "[142]\ttrain-mlogloss:0.91106\teval-mlogloss:1.07288\n",
            "[143]\ttrain-mlogloss:0.90789\teval-mlogloss:1.07094\n",
            "[144]\ttrain-mlogloss:0.90467\teval-mlogloss:1.06897\n",
            "[145]\ttrain-mlogloss:0.90142\teval-mlogloss:1.06677\n",
            "[146]\ttrain-mlogloss:0.89813\teval-mlogloss:1.06454\n",
            "[147]\ttrain-mlogloss:0.89482\teval-mlogloss:1.06230\n",
            "[148]\ttrain-mlogloss:0.89159\teval-mlogloss:1.05999\n",
            "[149]\ttrain-mlogloss:0.88857\teval-mlogloss:1.05789\n",
            "[150]\ttrain-mlogloss:0.88544\teval-mlogloss:1.05590\n",
            "[151]\ttrain-mlogloss:0.88245\teval-mlogloss:1.05390\n",
            "[152]\ttrain-mlogloss:0.87918\teval-mlogloss:1.05192\n",
            "[153]\ttrain-mlogloss:0.87647\teval-mlogloss:1.05026\n",
            "[154]\ttrain-mlogloss:0.87333\teval-mlogloss:1.04833\n",
            "[155]\ttrain-mlogloss:0.87003\teval-mlogloss:1.04592\n",
            "[156]\ttrain-mlogloss:0.86685\teval-mlogloss:1.04377\n",
            "[157]\ttrain-mlogloss:0.86391\teval-mlogloss:1.04242\n",
            "[158]\ttrain-mlogloss:0.86099\teval-mlogloss:1.04076\n",
            "[159]\ttrain-mlogloss:0.85807\teval-mlogloss:1.03893\n",
            "[160]\ttrain-mlogloss:0.85538\teval-mlogloss:1.03724\n",
            "[161]\ttrain-mlogloss:0.85262\teval-mlogloss:1.03531\n",
            "[162]\ttrain-mlogloss:0.84966\teval-mlogloss:1.03322\n",
            "[163]\ttrain-mlogloss:0.84658\teval-mlogloss:1.03105\n",
            "[164]\ttrain-mlogloss:0.84377\teval-mlogloss:1.02934\n",
            "[165]\ttrain-mlogloss:0.84081\teval-mlogloss:1.02716\n",
            "[166]\ttrain-mlogloss:0.83810\teval-mlogloss:1.02520\n",
            "[167]\ttrain-mlogloss:0.83543\teval-mlogloss:1.02335\n",
            "[168]\ttrain-mlogloss:0.83254\teval-mlogloss:1.02127\n",
            "[169]\ttrain-mlogloss:0.82981\teval-mlogloss:1.01980\n",
            "[170]\ttrain-mlogloss:0.82704\teval-mlogloss:1.01811\n",
            "[171]\ttrain-mlogloss:0.82438\teval-mlogloss:1.01614\n",
            "[172]\ttrain-mlogloss:0.82180\teval-mlogloss:1.01445\n",
            "[173]\ttrain-mlogloss:0.81905\teval-mlogloss:1.01278\n",
            "[174]\ttrain-mlogloss:0.81622\teval-mlogloss:1.01044\n",
            "[175]\ttrain-mlogloss:0.81340\teval-mlogloss:1.00872\n",
            "[176]\ttrain-mlogloss:0.81066\teval-mlogloss:1.00665\n",
            "[177]\ttrain-mlogloss:0.80800\teval-mlogloss:1.00491\n",
            "[178]\ttrain-mlogloss:0.80546\teval-mlogloss:1.00327\n",
            "[179]\ttrain-mlogloss:0.80290\teval-mlogloss:1.00150\n",
            "[180]\ttrain-mlogloss:0.80035\teval-mlogloss:0.99997\n",
            "[181]\ttrain-mlogloss:0.79767\teval-mlogloss:0.99807\n",
            "[182]\ttrain-mlogloss:0.79503\teval-mlogloss:0.99621\n",
            "[183]\ttrain-mlogloss:0.79245\teval-mlogloss:0.99446\n",
            "[184]\ttrain-mlogloss:0.78998\teval-mlogloss:0.99317\n",
            "[185]\ttrain-mlogloss:0.78753\teval-mlogloss:0.99185\n",
            "[186]\ttrain-mlogloss:0.78529\teval-mlogloss:0.99058\n",
            "[187]\ttrain-mlogloss:0.78284\teval-mlogloss:0.98882\n",
            "[188]\ttrain-mlogloss:0.78045\teval-mlogloss:0.98722\n",
            "[189]\ttrain-mlogloss:0.77798\teval-mlogloss:0.98582\n",
            "[190]\ttrain-mlogloss:0.77569\teval-mlogloss:0.98483\n",
            "[191]\ttrain-mlogloss:0.77330\teval-mlogloss:0.98337\n",
            "[192]\ttrain-mlogloss:0.77085\teval-mlogloss:0.98234\n",
            "[193]\ttrain-mlogloss:0.76836\teval-mlogloss:0.98063\n",
            "[194]\ttrain-mlogloss:0.76596\teval-mlogloss:0.97921\n",
            "[195]\ttrain-mlogloss:0.76351\teval-mlogloss:0.97771\n",
            "[196]\ttrain-mlogloss:0.76123\teval-mlogloss:0.97661\n",
            "[197]\ttrain-mlogloss:0.75895\teval-mlogloss:0.97511\n",
            "[198]\ttrain-mlogloss:0.75668\teval-mlogloss:0.97361\n",
            "[199]\ttrain-mlogloss:0.75444\teval-mlogloss:0.97239\n",
            "[200]\ttrain-mlogloss:0.75214\teval-mlogloss:0.97098\n",
            "[201]\ttrain-mlogloss:0.74990\teval-mlogloss:0.96963\n",
            "[202]\ttrain-mlogloss:0.74779\teval-mlogloss:0.96830\n",
            "[203]\ttrain-mlogloss:0.74560\teval-mlogloss:0.96688\n",
            "[204]\ttrain-mlogloss:0.74356\teval-mlogloss:0.96556\n",
            "[205]\ttrain-mlogloss:0.74143\teval-mlogloss:0.96441\n",
            "[206]\ttrain-mlogloss:0.73930\teval-mlogloss:0.96308\n",
            "[207]\ttrain-mlogloss:0.73711\teval-mlogloss:0.96168\n",
            "[208]\ttrain-mlogloss:0.73486\teval-mlogloss:0.96081\n",
            "[209]\ttrain-mlogloss:0.73261\teval-mlogloss:0.95940\n",
            "[210]\ttrain-mlogloss:0.73073\teval-mlogloss:0.95829\n",
            "[211]\ttrain-mlogloss:0.72870\teval-mlogloss:0.95704\n",
            "[212]\ttrain-mlogloss:0.72654\teval-mlogloss:0.95578\n",
            "[213]\ttrain-mlogloss:0.72443\teval-mlogloss:0.95479\n",
            "[214]\ttrain-mlogloss:0.72228\teval-mlogloss:0.95351\n",
            "[215]\ttrain-mlogloss:0.72017\teval-mlogloss:0.95228\n",
            "[216]\ttrain-mlogloss:0.71804\teval-mlogloss:0.95129\n",
            "[217]\ttrain-mlogloss:0.71593\teval-mlogloss:0.95049\n",
            "[218]\ttrain-mlogloss:0.71379\teval-mlogloss:0.94913\n",
            "[219]\ttrain-mlogloss:0.71181\teval-mlogloss:0.94845\n",
            "[220]\ttrain-mlogloss:0.70977\teval-mlogloss:0.94742\n",
            "[221]\ttrain-mlogloss:0.70775\teval-mlogloss:0.94621\n",
            "[222]\ttrain-mlogloss:0.70585\teval-mlogloss:0.94541\n",
            "[223]\ttrain-mlogloss:0.70389\teval-mlogloss:0.94438\n",
            "[224]\ttrain-mlogloss:0.70199\teval-mlogloss:0.94339\n",
            "[225]\ttrain-mlogloss:0.70008\teval-mlogloss:0.94242\n",
            "[226]\ttrain-mlogloss:0.69818\teval-mlogloss:0.94132\n",
            "[227]\ttrain-mlogloss:0.69622\teval-mlogloss:0.94033\n",
            "[228]\ttrain-mlogloss:0.69436\teval-mlogloss:0.93934\n",
            "[229]\ttrain-mlogloss:0.69254\teval-mlogloss:0.93842\n",
            "[230]\ttrain-mlogloss:0.69072\teval-mlogloss:0.93749\n",
            "[231]\ttrain-mlogloss:0.68885\teval-mlogloss:0.93680\n",
            "[232]\ttrain-mlogloss:0.68694\teval-mlogloss:0.93588\n",
            "[233]\ttrain-mlogloss:0.68502\teval-mlogloss:0.93464\n",
            "[234]\ttrain-mlogloss:0.68307\teval-mlogloss:0.93348\n",
            "[235]\ttrain-mlogloss:0.68127\teval-mlogloss:0.93262\n",
            "[236]\ttrain-mlogloss:0.67950\teval-mlogloss:0.93177\n",
            "[237]\ttrain-mlogloss:0.67765\teval-mlogloss:0.93083\n",
            "[238]\ttrain-mlogloss:0.67573\teval-mlogloss:0.92968\n",
            "[239]\ttrain-mlogloss:0.67388\teval-mlogloss:0.92873\n",
            "[240]\ttrain-mlogloss:0.67202\teval-mlogloss:0.92764\n",
            "[241]\ttrain-mlogloss:0.67040\teval-mlogloss:0.92694\n",
            "[242]\ttrain-mlogloss:0.66852\teval-mlogloss:0.92585\n",
            "[243]\ttrain-mlogloss:0.66679\teval-mlogloss:0.92492\n",
            "[244]\ttrain-mlogloss:0.66524\teval-mlogloss:0.92397\n",
            "[245]\ttrain-mlogloss:0.66352\teval-mlogloss:0.92321\n",
            "[246]\ttrain-mlogloss:0.66184\teval-mlogloss:0.92242\n",
            "[247]\ttrain-mlogloss:0.66016\teval-mlogloss:0.92169\n",
            "[248]\ttrain-mlogloss:0.65855\teval-mlogloss:0.92087\n",
            "[249]\ttrain-mlogloss:0.65672\teval-mlogloss:0.92023\n",
            "[250]\ttrain-mlogloss:0.65490\teval-mlogloss:0.91912\n",
            "[251]\ttrain-mlogloss:0.65309\teval-mlogloss:0.91878\n",
            "[252]\ttrain-mlogloss:0.65131\teval-mlogloss:0.91788\n",
            "[253]\ttrain-mlogloss:0.64989\teval-mlogloss:0.91714\n",
            "[254]\ttrain-mlogloss:0.64839\teval-mlogloss:0.91635\n",
            "[255]\ttrain-mlogloss:0.64690\teval-mlogloss:0.91573\n",
            "[256]\ttrain-mlogloss:0.64530\teval-mlogloss:0.91500\n",
            "[257]\ttrain-mlogloss:0.64354\teval-mlogloss:0.91386\n",
            "[258]\ttrain-mlogloss:0.64200\teval-mlogloss:0.91339\n",
            "[259]\ttrain-mlogloss:0.64044\teval-mlogloss:0.91273\n",
            "[260]\ttrain-mlogloss:0.63877\teval-mlogloss:0.91213\n",
            "[261]\ttrain-mlogloss:0.63728\teval-mlogloss:0.91128\n",
            "[262]\ttrain-mlogloss:0.63570\teval-mlogloss:0.91053\n",
            "[263]\ttrain-mlogloss:0.63408\teval-mlogloss:0.90949\n",
            "[264]\ttrain-mlogloss:0.63252\teval-mlogloss:0.90889\n",
            "[265]\ttrain-mlogloss:0.63094\teval-mlogloss:0.90807\n",
            "[266]\ttrain-mlogloss:0.62933\teval-mlogloss:0.90711\n",
            "[267]\ttrain-mlogloss:0.62777\teval-mlogloss:0.90629\n",
            "[268]\ttrain-mlogloss:0.62614\teval-mlogloss:0.90552\n",
            "[269]\ttrain-mlogloss:0.62461\teval-mlogloss:0.90480\n",
            "[270]\ttrain-mlogloss:0.62315\teval-mlogloss:0.90418\n",
            "[271]\ttrain-mlogloss:0.62164\teval-mlogloss:0.90344\n",
            "[272]\ttrain-mlogloss:0.62016\teval-mlogloss:0.90306\n",
            "[273]\ttrain-mlogloss:0.61852\teval-mlogloss:0.90229\n",
            "[274]\ttrain-mlogloss:0.61684\teval-mlogloss:0.90133\n",
            "[275]\ttrain-mlogloss:0.61523\teval-mlogloss:0.90064\n",
            "[276]\ttrain-mlogloss:0.61370\teval-mlogloss:0.90009\n",
            "[277]\ttrain-mlogloss:0.61213\teval-mlogloss:0.89956\n",
            "[278]\ttrain-mlogloss:0.61053\teval-mlogloss:0.89875\n",
            "[279]\ttrain-mlogloss:0.60903\teval-mlogloss:0.89789\n",
            "[280]\ttrain-mlogloss:0.60744\teval-mlogloss:0.89723\n",
            "[281]\ttrain-mlogloss:0.60610\teval-mlogloss:0.89685\n",
            "[282]\ttrain-mlogloss:0.60448\teval-mlogloss:0.89604\n",
            "[283]\ttrain-mlogloss:0.60300\teval-mlogloss:0.89543\n",
            "[284]\ttrain-mlogloss:0.60165\teval-mlogloss:0.89500\n",
            "[285]\ttrain-mlogloss:0.60031\teval-mlogloss:0.89456\n",
            "[286]\ttrain-mlogloss:0.59873\teval-mlogloss:0.89391\n",
            "[287]\ttrain-mlogloss:0.59732\teval-mlogloss:0.89352\n",
            "[288]\ttrain-mlogloss:0.59595\teval-mlogloss:0.89293\n",
            "[289]\ttrain-mlogloss:0.59461\teval-mlogloss:0.89259\n",
            "[290]\ttrain-mlogloss:0.59319\teval-mlogloss:0.89195\n",
            "[291]\ttrain-mlogloss:0.59197\teval-mlogloss:0.89162\n",
            "[292]\ttrain-mlogloss:0.59049\teval-mlogloss:0.89080\n",
            "[293]\ttrain-mlogloss:0.58929\teval-mlogloss:0.89037\n",
            "[294]\ttrain-mlogloss:0.58799\teval-mlogloss:0.88988\n",
            "[295]\ttrain-mlogloss:0.58660\teval-mlogloss:0.88918\n",
            "[296]\ttrain-mlogloss:0.58538\teval-mlogloss:0.88884\n",
            "[297]\ttrain-mlogloss:0.58398\teval-mlogloss:0.88814\n",
            "[298]\ttrain-mlogloss:0.58266\teval-mlogloss:0.88746\n",
            "[299]\ttrain-mlogloss:0.58139\teval-mlogloss:0.88701\n",
            "[300]\ttrain-mlogloss:0.58008\teval-mlogloss:0.88669\n",
            "[301]\ttrain-mlogloss:0.57863\teval-mlogloss:0.88644\n",
            "[302]\ttrain-mlogloss:0.57722\teval-mlogloss:0.88625\n",
            "[303]\ttrain-mlogloss:0.57612\teval-mlogloss:0.88588\n",
            "[304]\ttrain-mlogloss:0.57488\teval-mlogloss:0.88516\n",
            "[305]\ttrain-mlogloss:0.57366\teval-mlogloss:0.88479\n",
            "[306]\ttrain-mlogloss:0.57234\teval-mlogloss:0.88450\n",
            "[307]\ttrain-mlogloss:0.57107\teval-mlogloss:0.88372\n",
            "[308]\ttrain-mlogloss:0.56995\teval-mlogloss:0.88309\n",
            "[309]\ttrain-mlogloss:0.56863\teval-mlogloss:0.88273\n",
            "[310]\ttrain-mlogloss:0.56733\teval-mlogloss:0.88215\n",
            "[311]\ttrain-mlogloss:0.56614\teval-mlogloss:0.88167\n",
            "[312]\ttrain-mlogloss:0.56479\teval-mlogloss:0.88113\n",
            "[313]\ttrain-mlogloss:0.56352\teval-mlogloss:0.88071\n",
            "[314]\ttrain-mlogloss:0.56218\teval-mlogloss:0.88033\n",
            "[315]\ttrain-mlogloss:0.56088\teval-mlogloss:0.87990\n",
            "[316]\ttrain-mlogloss:0.55973\teval-mlogloss:0.87945\n",
            "[317]\ttrain-mlogloss:0.55860\teval-mlogloss:0.87891\n",
            "[318]\ttrain-mlogloss:0.55735\teval-mlogloss:0.87847\n",
            "[319]\ttrain-mlogloss:0.55608\teval-mlogloss:0.87764\n",
            "[320]\ttrain-mlogloss:0.55493\teval-mlogloss:0.87726\n",
            "[321]\ttrain-mlogloss:0.55372\teval-mlogloss:0.87676\n",
            "[322]\ttrain-mlogloss:0.55255\teval-mlogloss:0.87625\n",
            "[323]\ttrain-mlogloss:0.55133\teval-mlogloss:0.87577\n",
            "[324]\ttrain-mlogloss:0.55014\teval-mlogloss:0.87543\n",
            "[325]\ttrain-mlogloss:0.54888\teval-mlogloss:0.87497\n",
            "[326]\ttrain-mlogloss:0.54778\teval-mlogloss:0.87484\n",
            "[327]\ttrain-mlogloss:0.54667\teval-mlogloss:0.87428\n",
            "[328]\ttrain-mlogloss:0.54558\teval-mlogloss:0.87383\n",
            "[329]\ttrain-mlogloss:0.54453\teval-mlogloss:0.87320\n",
            "[330]\ttrain-mlogloss:0.54342\teval-mlogloss:0.87286\n",
            "[331]\ttrain-mlogloss:0.54232\teval-mlogloss:0.87230\n",
            "[332]\ttrain-mlogloss:0.54130\teval-mlogloss:0.87172\n",
            "[333]\ttrain-mlogloss:0.54027\teval-mlogloss:0.87169\n",
            "[334]\ttrain-mlogloss:0.53917\teval-mlogloss:0.87138\n",
            "[335]\ttrain-mlogloss:0.53792\teval-mlogloss:0.87092\n",
            "[336]\ttrain-mlogloss:0.53675\teval-mlogloss:0.87044\n",
            "[337]\ttrain-mlogloss:0.53571\teval-mlogloss:0.87003\n",
            "[338]\ttrain-mlogloss:0.53447\teval-mlogloss:0.86955\n",
            "[339]\ttrain-mlogloss:0.53324\teval-mlogloss:0.86899\n",
            "[340]\ttrain-mlogloss:0.53226\teval-mlogloss:0.86851\n",
            "[341]\ttrain-mlogloss:0.53114\teval-mlogloss:0.86805\n",
            "[342]\ttrain-mlogloss:0.53007\teval-mlogloss:0.86763\n",
            "[343]\ttrain-mlogloss:0.52900\teval-mlogloss:0.86755\n",
            "[344]\ttrain-mlogloss:0.52802\teval-mlogloss:0.86744\n",
            "[345]\ttrain-mlogloss:0.52696\teval-mlogloss:0.86695\n",
            "[346]\ttrain-mlogloss:0.52596\teval-mlogloss:0.86675\n",
            "[347]\ttrain-mlogloss:0.52487\teval-mlogloss:0.86637\n",
            "[348]\ttrain-mlogloss:0.52376\teval-mlogloss:0.86601\n",
            "[349]\ttrain-mlogloss:0.52275\teval-mlogloss:0.86584\n",
            "[350]\ttrain-mlogloss:0.52169\teval-mlogloss:0.86586\n",
            "[351]\ttrain-mlogloss:0.52076\teval-mlogloss:0.86574\n",
            "[352]\ttrain-mlogloss:0.51985\teval-mlogloss:0.86536\n",
            "[353]\ttrain-mlogloss:0.51878\teval-mlogloss:0.86526\n",
            "[354]\ttrain-mlogloss:0.51776\teval-mlogloss:0.86490\n",
            "[355]\ttrain-mlogloss:0.51688\teval-mlogloss:0.86485\n",
            "[356]\ttrain-mlogloss:0.51595\teval-mlogloss:0.86477\n",
            "[357]\ttrain-mlogloss:0.51493\teval-mlogloss:0.86441\n",
            "[358]\ttrain-mlogloss:0.51387\teval-mlogloss:0.86399\n",
            "[359]\ttrain-mlogloss:0.51294\teval-mlogloss:0.86372\n",
            "[360]\ttrain-mlogloss:0.51181\teval-mlogloss:0.86341\n",
            "[361]\ttrain-mlogloss:0.51083\teval-mlogloss:0.86333\n",
            "[362]\ttrain-mlogloss:0.50978\teval-mlogloss:0.86332\n",
            "[363]\ttrain-mlogloss:0.50881\teval-mlogloss:0.86316\n",
            "[364]\ttrain-mlogloss:0.50780\teval-mlogloss:0.86283\n",
            "[365]\ttrain-mlogloss:0.50681\teval-mlogloss:0.86270\n",
            "[366]\ttrain-mlogloss:0.50587\teval-mlogloss:0.86261\n",
            "[367]\ttrain-mlogloss:0.50501\teval-mlogloss:0.86263\n",
            "[368]\ttrain-mlogloss:0.50412\teval-mlogloss:0.86223\n",
            "[369]\ttrain-mlogloss:0.50331\teval-mlogloss:0.86188\n",
            "[370]\ttrain-mlogloss:0.50234\teval-mlogloss:0.86157\n",
            "[371]\ttrain-mlogloss:0.50132\teval-mlogloss:0.86143\n",
            "[372]\ttrain-mlogloss:0.50027\teval-mlogloss:0.86102\n",
            "[373]\ttrain-mlogloss:0.49938\teval-mlogloss:0.86083\n",
            "[374]\ttrain-mlogloss:0.49836\teval-mlogloss:0.86065\n",
            "[375]\ttrain-mlogloss:0.49736\teval-mlogloss:0.86042\n",
            "[376]\ttrain-mlogloss:0.49647\teval-mlogloss:0.86051\n",
            "[377]\ttrain-mlogloss:0.49558\teval-mlogloss:0.86050\n",
            "[378]\ttrain-mlogloss:0.49464\teval-mlogloss:0.86042\n",
            "[379]\ttrain-mlogloss:0.49371\teval-mlogloss:0.86006\n",
            "[380]\ttrain-mlogloss:0.49272\teval-mlogloss:0.85989\n",
            "[381]\ttrain-mlogloss:0.49186\teval-mlogloss:0.85971\n",
            "[382]\ttrain-mlogloss:0.49089\teval-mlogloss:0.85941\n",
            "[383]\ttrain-mlogloss:0.48998\teval-mlogloss:0.85930\n",
            "[384]\ttrain-mlogloss:0.48925\teval-mlogloss:0.85925\n",
            "[385]\ttrain-mlogloss:0.48836\teval-mlogloss:0.85887\n",
            "[386]\ttrain-mlogloss:0.48740\teval-mlogloss:0.85853\n",
            "[387]\ttrain-mlogloss:0.48657\teval-mlogloss:0.85827\n",
            "[388]\ttrain-mlogloss:0.48566\teval-mlogloss:0.85829\n",
            "[389]\ttrain-mlogloss:0.48483\teval-mlogloss:0.85778\n",
            "[390]\ttrain-mlogloss:0.48382\teval-mlogloss:0.85762\n",
            "[391]\ttrain-mlogloss:0.48294\teval-mlogloss:0.85735\n",
            "[392]\ttrain-mlogloss:0.48201\teval-mlogloss:0.85728\n",
            "[393]\ttrain-mlogloss:0.48127\teval-mlogloss:0.85695\n",
            "[394]\ttrain-mlogloss:0.48041\teval-mlogloss:0.85684\n",
            "[395]\ttrain-mlogloss:0.47950\teval-mlogloss:0.85679\n",
            "[396]\ttrain-mlogloss:0.47859\teval-mlogloss:0.85654\n",
            "[397]\ttrain-mlogloss:0.47780\teval-mlogloss:0.85648\n",
            "[398]\ttrain-mlogloss:0.47697\teval-mlogloss:0.85649\n",
            "[399]\ttrain-mlogloss:0.47616\teval-mlogloss:0.85636\n",
            "[400]\ttrain-mlogloss:0.47522\teval-mlogloss:0.85599\n",
            "[401]\ttrain-mlogloss:0.47436\teval-mlogloss:0.85571\n",
            "[402]\ttrain-mlogloss:0.47352\teval-mlogloss:0.85535\n",
            "[403]\ttrain-mlogloss:0.47271\teval-mlogloss:0.85503\n",
            "[404]\ttrain-mlogloss:0.47179\teval-mlogloss:0.85477\n",
            "[405]\ttrain-mlogloss:0.47090\teval-mlogloss:0.85472\n",
            "[406]\ttrain-mlogloss:0.47000\teval-mlogloss:0.85476\n",
            "[407]\ttrain-mlogloss:0.46911\teval-mlogloss:0.85449\n",
            "[408]\ttrain-mlogloss:0.46827\teval-mlogloss:0.85405\n",
            "[409]\ttrain-mlogloss:0.46743\teval-mlogloss:0.85387\n",
            "[410]\ttrain-mlogloss:0.46659\teval-mlogloss:0.85386\n",
            "[411]\ttrain-mlogloss:0.46583\teval-mlogloss:0.85356\n",
            "[412]\ttrain-mlogloss:0.46506\teval-mlogloss:0.85313\n",
            "[413]\ttrain-mlogloss:0.46432\teval-mlogloss:0.85293\n",
            "[414]\ttrain-mlogloss:0.46362\teval-mlogloss:0.85275\n",
            "[415]\ttrain-mlogloss:0.46282\teval-mlogloss:0.85258\n",
            "[416]\ttrain-mlogloss:0.46206\teval-mlogloss:0.85239\n",
            "[417]\ttrain-mlogloss:0.46134\teval-mlogloss:0.85222\n",
            "[418]\ttrain-mlogloss:0.46060\teval-mlogloss:0.85193\n",
            "[419]\ttrain-mlogloss:0.45982\teval-mlogloss:0.85170\n",
            "[420]\ttrain-mlogloss:0.45904\teval-mlogloss:0.85137\n",
            "[421]\ttrain-mlogloss:0.45825\teval-mlogloss:0.85142\n",
            "[422]\ttrain-mlogloss:0.45757\teval-mlogloss:0.85109\n",
            "[423]\ttrain-mlogloss:0.45679\teval-mlogloss:0.85088\n",
            "[424]\ttrain-mlogloss:0.45607\teval-mlogloss:0.85077\n",
            "[425]\ttrain-mlogloss:0.45534\teval-mlogloss:0.85068\n",
            "[426]\ttrain-mlogloss:0.45456\teval-mlogloss:0.85043\n",
            "[427]\ttrain-mlogloss:0.45385\teval-mlogloss:0.85053\n",
            "[428]\ttrain-mlogloss:0.45314\teval-mlogloss:0.85064\n",
            "[429]\ttrain-mlogloss:0.45238\teval-mlogloss:0.85030\n",
            "[430]\ttrain-mlogloss:0.45165\teval-mlogloss:0.85018\n",
            "[431]\ttrain-mlogloss:0.45097\teval-mlogloss:0.85004\n",
            "[432]\ttrain-mlogloss:0.45029\teval-mlogloss:0.84967\n",
            "[433]\ttrain-mlogloss:0.44964\teval-mlogloss:0.84972\n",
            "[434]\ttrain-mlogloss:0.44896\teval-mlogloss:0.84992\n",
            "[435]\ttrain-mlogloss:0.44824\teval-mlogloss:0.84991\n",
            "[436]\ttrain-mlogloss:0.44756\teval-mlogloss:0.84982\n",
            "[437]\ttrain-mlogloss:0.44694\teval-mlogloss:0.84955\n",
            "[438]\ttrain-mlogloss:0.44624\teval-mlogloss:0.84936\n",
            "[439]\ttrain-mlogloss:0.44559\teval-mlogloss:0.84920\n",
            "[440]\ttrain-mlogloss:0.44490\teval-mlogloss:0.84916\n",
            "[441]\ttrain-mlogloss:0.44422\teval-mlogloss:0.84893\n",
            "[442]\ttrain-mlogloss:0.44353\teval-mlogloss:0.84867\n",
            "[443]\ttrain-mlogloss:0.44282\teval-mlogloss:0.84851\n",
            "[444]\ttrain-mlogloss:0.44212\teval-mlogloss:0.84848\n",
            "[445]\ttrain-mlogloss:0.44146\teval-mlogloss:0.84863\n",
            "[446]\ttrain-mlogloss:0.44079\teval-mlogloss:0.84868\n",
            "[447]\ttrain-mlogloss:0.44016\teval-mlogloss:0.84873\n",
            "[448]\ttrain-mlogloss:0.43947\teval-mlogloss:0.84855\n",
            "[449]\ttrain-mlogloss:0.43883\teval-mlogloss:0.84828\n",
            "[450]\ttrain-mlogloss:0.43821\teval-mlogloss:0.84844\n",
            "[451]\ttrain-mlogloss:0.43756\teval-mlogloss:0.84858\n",
            "[452]\ttrain-mlogloss:0.43695\teval-mlogloss:0.84839\n",
            "[453]\ttrain-mlogloss:0.43629\teval-mlogloss:0.84831\n",
            "[454]\ttrain-mlogloss:0.43564\teval-mlogloss:0.84801\n",
            "[455]\ttrain-mlogloss:0.43501\teval-mlogloss:0.84779\n",
            "[456]\ttrain-mlogloss:0.43432\teval-mlogloss:0.84785\n",
            "[457]\ttrain-mlogloss:0.43372\teval-mlogloss:0.84782\n",
            "[458]\ttrain-mlogloss:0.43309\teval-mlogloss:0.84780\n",
            "[459]\ttrain-mlogloss:0.43238\teval-mlogloss:0.84798\n",
            "[460]\ttrain-mlogloss:0.43172\teval-mlogloss:0.84799\n",
            "[461]\ttrain-mlogloss:0.43113\teval-mlogloss:0.84812\n",
            "[462]\ttrain-mlogloss:0.43049\teval-mlogloss:0.84805\n",
            "[463]\ttrain-mlogloss:0.42991\teval-mlogloss:0.84783\n",
            "[464]\ttrain-mlogloss:0.42930\teval-mlogloss:0.84805\n",
            "[465]\ttrain-mlogloss:0.42870\teval-mlogloss:0.84778\n",
            "[466]\ttrain-mlogloss:0.42816\teval-mlogloss:0.84760\n",
            "[467]\ttrain-mlogloss:0.42753\teval-mlogloss:0.84759\n",
            "[468]\ttrain-mlogloss:0.42694\teval-mlogloss:0.84750\n",
            "[469]\ttrain-mlogloss:0.42635\teval-mlogloss:0.84718\n",
            "[470]\ttrain-mlogloss:0.42578\teval-mlogloss:0.84707\n",
            "[471]\ttrain-mlogloss:0.42520\teval-mlogloss:0.84687\n",
            "[472]\ttrain-mlogloss:0.42463\teval-mlogloss:0.84688\n",
            "[473]\ttrain-mlogloss:0.42406\teval-mlogloss:0.84692\n",
            "[474]\ttrain-mlogloss:0.42356\teval-mlogloss:0.84689\n",
            "[475]\ttrain-mlogloss:0.42303\teval-mlogloss:0.84704\n",
            "[476]\ttrain-mlogloss:0.42243\teval-mlogloss:0.84705\n",
            "[477]\ttrain-mlogloss:0.42182\teval-mlogloss:0.84693\n",
            "[478]\ttrain-mlogloss:0.42123\teval-mlogloss:0.84685\n",
            "[479]\ttrain-mlogloss:0.42070\teval-mlogloss:0.84672\n",
            "[480]\ttrain-mlogloss:0.42012\teval-mlogloss:0.84669\n",
            "[481]\ttrain-mlogloss:0.41960\teval-mlogloss:0.84692\n",
            "[482]\ttrain-mlogloss:0.41907\teval-mlogloss:0.84703\n",
            "[483]\ttrain-mlogloss:0.41855\teval-mlogloss:0.84705\n",
            "[484]\ttrain-mlogloss:0.41796\teval-mlogloss:0.84703\n",
            "[485]\ttrain-mlogloss:0.41744\teval-mlogloss:0.84710\n",
            "[486]\ttrain-mlogloss:0.41696\teval-mlogloss:0.84695\n",
            "[487]\ttrain-mlogloss:0.41641\teval-mlogloss:0.84673\n",
            "[488]\ttrain-mlogloss:0.41581\teval-mlogloss:0.84698\n",
            "[489]\ttrain-mlogloss:0.41527\teval-mlogloss:0.84689\n",
            "[490]\ttrain-mlogloss:0.41473\teval-mlogloss:0.84688\n",
            "XGBoost Classification Report with Evaluation Set:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "  Responsivenss       0.88      0.94      0.91        68\n",
            "       feedback       0.50      0.20      0.29         5\n",
            "health benefits       0.25      0.12      0.17         8\n",
            "     medication       0.70      0.81      0.75        32\n",
            "        pa code       0.75      0.52      0.62        23\n",
            " staff attitude       0.50      0.75      0.60         4\n",
            "   waiting time       0.20      0.33      0.25         3\n",
            "\n",
            "       accuracy                           0.76       143\n",
            "      macro avg       0.54      0.53      0.51       143\n",
            "   weighted avg       0.74      0.76      0.74       143\n",
            "\n",
            "\n",
            "Total incorrect predictions: 35\n",
            "Sentence: 'because i have been on an onboarding process with  a gym which you claim could take up to 3 months but its about 6 months now with no  result. you guys are just tossing me back and forth whenever i ask for update.'\n",
            "Predicted: 'health benefits', Actual: 'feedback'\n",
            "\n",
            "Sentence: 'An HMo that can’t deliver inhaler is not an HMO'\n",
            "Predicted: 'medication', Actual: 'health benefits'\n",
            "\n",
            "Sentence: 'Waiting time is very minimal.'\n",
            "Predicted: 'feedback', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'I CHOSE IT BECAUSE ANY TIME I GO FOR TREATMENT OR TAKE ANY OF MY FAMILY THERE FOR TREATMENT, THE RECEPTION IS ALWAYS GREAT AND THEY ARE ALWAYS QUICK TO ATTEND TO US WITHOUT ANY DELAY.'\n",
            "Predicted: 'health benefits', Actual: 'staff attitude'\n",
            "\n",
            "Sentence: 'For starters, slow response time. Secondly, the fact that enrollees cannot take certain wellness tests within their coverage is alarming!\n",
            "\n",
            "Before my experience, I had heard several complaints to the point that people boycott the HMO as it doesn't serve them at all.'\n",
            "Predicted: 'Responsivenss', Actual: 'health benefits'\n",
            "\n",
            "Sentence: 'Late doctors response , late payment of drugs and late pick up code been sent'\n",
            "Predicted: 'Responsivenss', Actual: 'waiting time'\n",
            "\n",
            "Sentence: '* Limited options for access to the care of a Dermatologist\n",
            "\n",
            "* Speed of delivering medication is extremely delayed.'\n",
            "Predicted: 'medication', Actual: 'health benefits'\n",
            "\n",
            "Sentence: 'Because Reliance HMO bodies are in 90% care about their client. When I got to the hospital they responded to me within 10mins because of the quick approved'\n",
            "Predicted: 'staff attitude', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'Because my wife had a terrible experience while she was pregnant. This has to do with seeking repeated approvals before drugs were given to her. Consequently, I had to start paying from my pocket to avoid story that touches the heart.'\n",
            "Predicted: 'medication', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'It's lacking the basic services I need like a dentist and an ophthalmologist.'\n",
            "Predicted: 'medication', Actual: 'health benefits'\n",
            "\n",
            "Sentence: 'Very slow response time'\n",
            "Predicted: 'Responsivenss', Actual: 'feedback'\n",
            "\n",
            "Sentence: 'Customer service is great unlike most Nigerian companies.\n",
            "\n",
            "They respond promptly and with details'\n",
            "Predicted: 'pa code', Actual: 'Responsivenss'\n",
            "\n",
            "Sentence: 'Doctors response time on chat is so slow. Most of the time I want to consult with a doctor virtually on the Reliance app,  by the time they respond I have forgotten that I booked and appointment.'\n",
            "Predicted: 'Responsivenss', Actual: 'waiting time'\n",
            "\n",
            "Sentence: 'My son was ill and ended up paying all the bills'\n",
            "Predicted: 'medication', Actual: 'health benefits'\n",
            "\n",
            "Sentence: 'Efficiency and the timely responses of the customer care staff.  Also available of wide range of hospital for customers access'\n",
            "Predicted: 'medication', Actual: 'Responsivenss'\n",
            "\n",
            "Sentence: 'The hospital that am using didn't carried out test before proscribed drugs and their drugs are not up to the standard'\n",
            "Predicted: 'staff attitude', Actual: 'medication'\n",
            "\n",
            "Sentence: 'why this that u will go to hospital no doctor to attend to you on time.time waiting.'\n",
            "Predicted: 'waiting time', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'Reliance do not have decent hospitals on its platform.'\n",
            "Predicted: 'pa code', Actual: 'medication'\n",
            "\n",
            "Sentence: 'the commitment in customer relationship and advice.\n",
            "24hrs customer service provider\n",
            "online Doctor response and medical advice.all'\n",
            "Predicted: 'waiting time', Actual: 'Responsivenss'\n",
            "\n",
            "Sentence: 'Still now I haven't heard from your customer care when (date/time) to see a dermatologist.\n",
            "\n",
            "Very poor follow up from customer care'\n",
            "Predicted: 'pa code', Actual: 'feedback'\n",
            "\n",
            "Sentence: 'you don't respond ontime and also delay of drugs'\n",
            "Predicted: 'medication', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'Your parameters for determining what tests you pay for are ridiculous. If a Doctor from a hospital in your database prescribes a test, why would you say the diagnosis and the test do not match? Are you saying you don't trust the Doctor? If you don't, why then would you allow me to be treated by that Doctor? It just shows me that you don't really care about my well-being. You guys just do lip service. Ridiculous.\n",
            "\n",
            "\n",
            "Another thing is that your pharmacy operations are slow and unreliable. Sometimes, you don't have the drug. Other times, you deliver four days after the drug was prescribed. It's like your customers' health is a joke to you. Just pay the hospital to get the drugs for patients immediately. But no, you won't do that. Only God knows why. Again, ridiculous. \n",
            "\n",
            "My hope is to be free from your service soon.'\n",
            "Predicted: 'waiting time', Actual: 'health benefits'\n",
            "\n",
            "Sentence: 'I got a Doctor's prescription and I did not receive any notification informing me to go pick up the drugs. I had to reach out to your support team some days later before the pickup code was sent to me.'\n",
            "Predicted: 'medication', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'Quick in attending to people'\n",
            "Predicted: 'Responsivenss', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'Your drug selection for patient is too poor, cheap and ineffective. Please look into it and step up. Thanks'\n",
            "Predicted: 'health benefits', Actual: 'medication'\n",
            "\n",
            "Sentence: 'orders before 8a.m come the next day, not a viable option in an emergency. almost always. not something to bank on.'\n",
            "Predicted: 'pa code', Actual: 'medication'\n",
            "\n",
            "Sentence: 'never had any issues at the hospital and response time is super fast'\n",
            "Predicted: 'Responsivenss', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'My son was sick, I spent 48 hours in the hospital and they could not get confirmation code.'\n",
            "Predicted: 'medication', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'You don’t have good hospitals, spa or gym in my location. I have sent names of the ones close by, none have been onboarded.'\n",
            "Predicted: 'medication', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'I don’t like the fact that my preferred hospitals are not on your list. But your services are good.'\n",
            "Predicted: 'staff attitude', Actual: 'medication'\n",
            "\n",
            "Sentence: 'Your medications exclude Vit c'\n",
            "Predicted: 'Responsivenss', Actual: 'health benefits'\n",
            "\n",
            "Sentence: 'Your support team doesn't deliver on their promise and you don't email response.'\n",
            "Predicted: 'Responsivenss', Actual: 'feedback'\n",
            "\n",
            "Sentence: 'Am happy with the way you people responds promptly when am in the hospital'\n",
            "Predicted: 'medication', Actual: 'Responsivenss'\n",
            "\n",
            "Sentence: 'Consultation service was on fast and drug pick was fast too'\n",
            "Predicted: 'Responsivenss', Actual: 'pa code'\n",
            "\n",
            "Sentence: 'My health care requests have been met promptly, with accurate diagnosis, Doctors willing to explain/give reason for their diagnosis with quality drugs prescription. Online though, have not been to their hospital.'\n",
            "Predicted: 'waiting time', Actual: 'medication'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNZWVjihvp-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing the wrong classied responses."
      ],
      "metadata": {
        "id": "jkv1HA-kvQT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 1:  data falls between two categories.\n",
        "\n",
        "It's mixed between both classes, thus the op should be the highest two categories.. not only the first."
      ],
      "metadata": {
        "id": "Ke4DEg11h28F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence: 'I choose that because when my family go to hospital and see doctor and when prescription comes out, the hospital will start saying that HOM is not fully covered and sometimes low grade drugs were given to them'\n",
        "# Predicted: 'medication', Actual: 'health benefits'\n",
        "\n",
        "\n",
        "# Sentence: 'I’ve been an advocate of Reliance HMO, however over the last couple of visits to the hospital, the time it takes for your officers to respond nor provide authorization codes is quite alarming. We’ve had to spent close to an hour waiting for codes, even after several personal phone calls to the customer service personnel.\n",
        "\n",
        "# In addition to the above, there has been issues regarding reliance HMo and the hospital negotiating over the price of drugs, which has seen us spend about 50mins waiting for the needless negotiations putting into consideration that the patient was in a dire situation. On one of those occasions we had to pay out of pocket to get the drugs sorted.\n",
        "\n",
        "# Furthermore, IT glitches on your mobile app, this app was one of the season why I convinced my organization to join amongst other benefits, however the recent glitches is becoming one too many which has affected the way I view your company.'\n",
        "# Predicted: 'medication', Actual: 'feedback'\n",
        "\n",
        "# Sentence: '* Late response from your Doctor and support agent\n",
        "# * Wrong prisciption of drugs\n",
        "# * Long delay in medication pick up sms'\n",
        "# Predicted: 'Responsivenss', Actual: 'waiting time'\n",
        "\n",
        "# Sentence: 'Bcs I went to the hospital 2 days ago, and you promise to get back to me on the prescription prescribed to me by the doctor.till now, hv not gotten any information about it.\n",
        "\n",
        "# Thank you'\n",
        "# Predicted: 'waiting time', Actual: 'feedback'"
      ],
      "metadata": {
        "id": "TA4xiQYgsnDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2: incorrectly labelled data."
      ],
      "metadata": {
        "id": "Iql1tFAGihi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sentence: 'Quick service received since I have been using Reliance HMO'\n",
        "# Predicted: 'Responsivenss', Actual: 'pa code'\n",
        "\n",
        "# Sentence: 'My first experience with your HMO wasn't encouraging. I picked a Pharmacy to pick-up my prescribed medication. On getting there, I was told they had informed the HMO that the drugs were not available but could be made available before my arrival if only they sent the amount. Up to the closing time of the day, the pharmacy was not contacted again, meanwhile I was sent a message to pick up the drugs there. I was very embarrassing that day.\n",
        "# At another time, I was told my drug would be delivered to me at my work station, I waited for more than 24hours before getting it after engaging the chat room over and over again.\n",
        "\n",
        "# As at this moment, the drug prescription by a doctor yesterday which I requested before 12 noon has not yet been delivered to me till now.\n",
        "\n",
        "# You can verify all my claims please'\n",
        "# Predicted: 'feedback', Actual: 'medication'\n",
        "\n",
        "\n",
        "# Sentence: 'i dont know if it applies to my package only but multi-vitamins are not been giving.also, delay in granting authorization'\n",
        "# Predicted: 'medication', Actual: 'pa code'\n",
        "\n",
        "# Sentence: 'The response to the Drs or the hospital is not as faster as to the need of a patient,also response and delivery of medications is not as prompt as expected'\n",
        "# Predicted: 'Responsivenss', Actual: 'medication'\n",
        "\n",
        "\n",
        "\n",
        "# Sentence: 'Slow and delayed response, delay delivery'\n",
        "# Predicted: 'Responsivenss', Actual: 'medication'\n",
        "\n",
        "# Sentence: 'you are bad at your service for your client who requested for a dermatologist got prescription without knowing how critical it took one month no response till date.'\n",
        "# Predicted: 'Responsivenss', Actual: 'feedback'\n",
        "\n",
        "# Sentence: 'never had any issues at the hospital and response time is super fast'\n",
        "# Predicted: 'Responsivenss', Actual: 'pa code'\n",
        "\n",
        "# Sentence: 'The response time on consult a doctor on the app or web takes a long time waiting for the doctor'\n",
        "# Predicted: 'Responsivenss', Actual: 'waiting time'\n",
        "\n",
        "# Sentence: 'The delay in response'\n",
        "# Predicted: 'Responsivenss', Actual: 'medication'\n",
        "\n",
        "# Sentence: 'The customer service is quite slow in terms of responding to enquries.I have said I wanted to go to a ear doctor but nothing done yet done'\n",
        "# Predicted: 'waiting time', Actual: 'feedback'\n",
        "\n",
        "# Sentence: 'deliver was slow'\n",
        "# Predicted: 'Responsivenss', Actual: 'medication'\n",
        "\n",
        "\n",
        "\n",
        "# Sentence: 'Because a times your doctors are not patience enough to listen and show Empathy,rather some can't wait to end the session with you,and also how come you don't prescribe sex enhancing drugs for your clients with such problem'\n",
        "# Predicted: 'medication', Actual: 'waiting time'\n",
        "\n",
        "\n",
        "# Sentence: 'Consultation service was on fast and drug pick was fast too'\n",
        "# Predicted: 'Responsivenss', Actual: 'pa code'\n",
        "\n",
        "\n",
        "# Sentence: 'Very slow response time'\n",
        "# Predicted: 'Responsivenss', Actual: 'feedback'\n"
      ],
      "metadata": {
        "id": "BfqoZB1fnnXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jzBA73HJv4ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 3: Bad prediction\n"
      ],
      "metadata": {
        "id": "rnEZVIg_nzzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence: 'Because your responding is too slow'\n",
        "# Predicted: 'feedback', Actual: 'Responsivenss'\n",
        "\n",
        "# Sentence: 'Because I have not gotten feed back based on my mail yesterday'\n",
        "# Predicted: 'medication', Actual: 'feedback'\n",
        "\n",
        "# Sentence: 'Your consultant online doctors are not nice nor efficient in their service delivery . The response time before they begin to chat with you is too long a time.\n",
        "# Then also , it’s takes too long a time to deliver drugs . I didn’t get a drug until after 2 or 3 days of request ( not over the weekend o)'\n",
        "# Predicted: 'medication', Actual: 'waiting time'\n",
        "\n",
        "\n",
        "\n",
        "# Sentence: 'I like the service, but was disappointed when the clinic R.Jolad could not give 500mg. Vit. C because HMO Policy.'\n",
        "# Predicted: 'medication', Actual: 'health benefits'\n",
        "\n",
        "# Sentence: 'Delays sometimes. Not sending the code early enough.'\n",
        "# Predicted: 'medication', Actual: 'pa code'\n",
        "\n",
        "\n",
        "# Sentence: 'because i have been on an onboarding process with  a gym which you claim could take up to 3 months but its about 6 months now with no  result. you guys are just tossing me back and forth whenever i ask for update.'\n",
        "# Predicted: 'pa code', Actual: 'feedback'\n",
        "\n",
        "# All basic care for children has been deleted from the benefits.'\n",
        "# Predicted: 'Responsivenss', Actual: 'health benefits'\n",
        "\n",
        "# Sentence: 'Staffs are accommodating and always willing to help. Customer service and follow up is good as well'\n",
        "# Predicted: 'Responsivenss', Actual: 'staff attitude'\n",
        "\n",
        "# Sentence: 'I chose that because when something is good you comment that is good. reliance hmo is one of the best HMO so far, when you call they answer as fast as possible, so i want to use this opportunity to say a very big thank you to all the staffs of reliance hmo thanks and God bless you all amen.'\n",
        "# Predicted: 'health benefits', Actual: 'staff attitude'\n",
        "\n",
        "\n",
        "# Sentence: 'My son was ill and ended up paying all the bills'\n",
        "# Predicted: 'medication', Actual: 'health benefits'\n",
        "\n",
        "# Sentence: 'I was recommended for a PTA and tympomometry test. Shockingly i was told this was not covered by Reliance.'\n",
        "# Predicted: 'medication', Actual: 'health benefits'\n",
        "\n",
        "# Sentence: 'The experience I had with you guys when I was admitted was terrible. I was in excruciating pain and for four days Reliance did not approve Oral Morphine drug for the hospital to manage the postop pain I was having. I had to resort to verbally abusing your customer care representative which was unlike me.'\n",
        "# Predicted: 'feedback', Actual: 'health benefits'\n",
        "\n",
        "\n",
        "# Sentence: 'I CHOSE IT BECAUSE ANY TIME I GO FOR TREATMENT OR TAKE ANY OF MY FAMILY THERE FOR TREATMENT, THE RECEPTION IS ALWAYS GREAT AND THEY ARE ALWAYS QUICK TO ATTEND TO US WITHOUT ANY DELAY.'\n",
        "# Predicted: 'health benefits', Actual: 'staff attitude'\n",
        "\n",
        "# Sentence: 'Your customer service and feedback/update is poor'\n",
        "# Predicted: 'Responsivenss', Actual: 'feedback'\n",
        "\n",
        "# Sentence: 'Please do include dental and eye care into your area of concern.'\n",
        "# Predicted: 'medication', Actual: 'health benefits'\n",
        "\n",
        "\n",
        "# Sentence: 'Just refund me my money for the MMR covered by my organization’s package'\n",
        "# Predicted: 'health benefits', Actual: 'feedback'\n",
        "\n",
        "# Sentence: 'Efficiency and the timely responses of the customer care staff.  Also available of wide range of hospital for customers access'\n",
        "# Predicted: 'medication', Actual: 'Responsivenss'\n",
        "\n",
        "\n",
        "# Sentence: 'The team doesn't have enough secondary health care providers. The sole focus is on medical issues that I really do not need. Your facilities provide low quality eye glasses and might need to pay as much as 50K in addition to get what suits you.\n",
        "# What I'm about to say now is outside the scope of the services you provide, but I would love if  you could partner up with sport facilities like swimming centres not just gyms.\n",
        "\n",
        "# Thank you.\n",
        "# My regards'\n",
        "# Predicted: 'medication', Actual: 'health benefits'"
      ],
      "metadata": {
        "id": "Scb4rz-on5_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 4: bad prediction and bad labelling!"
      ],
      "metadata": {
        "id": "W28kTsfStLkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence: 'I am really not happy today, because I spoke to an online Doctor to refer me to another hospital for my test instead of Jolad but no response from any of the Doctor I chatted online. I went to R. Jolad hospital today since 9:00 am from my office and they took almost all my time and yet no drugs was given to me because of the delay in response with the approval. I had to get back to work by 4:00pm, I am not just happy. I am not happy, just know it.'\n",
        "# Predicted: 'waiting time', Actual: 'pa code'\n",
        "\n",
        "# Sentence: 'The time use in dispensing drugs is too long.\n",
        "# The drugs some pharmacy do give a times is not encouraging'\n",
        "# Predicted: 'medication', Actual: 'pa code'\n",
        "\n",
        "# Sentence: 'Because of the service responses and delivery'\n",
        "# Predicted: 'medication', Actual: 'Responsivenss'\n",
        "\n",
        "# Sentence: 'You don’t have good hospitals, spa or gym in my location. I have sent names of the ones close by, none have been onboarded.'\n",
        "# Predicted: 'medication', Actual: 'pa code'\n",
        "\n",
        "# Sentence: 'Your parameters for determining what tests you pay for are ridiculous. If a Doctor from a hospital in your database prescribes a test, why would you say the diagnosis and the test do not match? Are you saying you don't trust the Doctor? If you don't, why then would you allow me to be treated by that Doctor? It just shows me that you don't really care about my well-being. You guys just do lip service. Ridiculous.\n",
        "\n",
        "\n",
        "# Another thing is that your pharmacy operations are slow and unreliable. Sometimes, you don't have the drug. Other times, you deliver four days after the drug was prescribed. It's like your customers' health is a joke to you. Just pay the hospital to get the drugs for patients immediately. But no, you won't do that. Only God knows why. Again, ridiculous.\n",
        "\n",
        "# My hope is to be free from your service soon.'\n",
        "# Predicted: 'waiting time', Actual: 'health benefits'\n",
        "\n",
        "# Sentence: 'I recently had an unsatisfactory experience with my health insurance provider that compelled me to share my concerns. The overall service has been subpar, particularly in terms of medication delivery.One of the major grievances I encountered was the consistent delay in receiving my prescribed medications. Despite assurances of timely delivery, the reality fell far short of expectations. On multiple occasions, I found myself waiting for crucial medications, causing unnecessary stress and disruptions to my health management.Moreover, the customer service offered by the insurance company was disappointingly inadequate. Attempts to address these delays and seek clarification were met with generic responses and a lack of proactive communication. It became evident that the company was not prioritizing customer satisfaction or the urgency of healthcare needs.'\n",
        "# Predicted: 'medication', Actual: 'pa code'\n"
      ],
      "metadata": {
        "id": "DlLLrv3rtLTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER_TUNING"
      ],
      "metadata": {
        "id": "Nz6QJGs1zNnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "CXItvupfv4lU"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = [\"feedback\", \"waiting time\", \"Responsiveness\", \"medication\", \"health benefits\", \"staff attitude\", \"pa code\"]\n",
        "TRAIN_DATA = [\n",
        "    (\"Because your responding is too slow\", {\"entities\": [(0, 7, \"Responsivenss\")]}),\n",
        "    (\"Because I have not gotten feed back based on my mail yesterday\", {\"entities\": [(34, 41, \"feedback\")]}),\n",
        "    (\"Your consultant online doctors are not nice nor efficient in their service delivery . The response time before they begin to chat with you is too long a time. Then also , it’s takes too long a time to deliver drugs . I didn’t get a drug until after 2 or 3 days of request ( not over the weekend o)\", {\"entities\": [(199, 210, \"waiting time\"), (246, 254, \"medication\"), (48, 62, \"Responsivenss\"), (139, 146, \"Responsivenss\")]}),\n",
        "    (\"I like the service, but was disappointed when the clinic R.Jolad could not give 500mg. Vit. C because HMO Policy.\", {\"entities\": [(0, 43, \"medication\"), (73, 85, \"health benefits\")]}),\n",
        "    (\"Delays sometimes. Not sending the code early enough.\", {\"entities\": [(0, 6, \"medication\"), (15, 38, \"pa code\")]}),\n",
        "    (\"because i have been on an onboarding process with  a gym which you claim could take up to 3 months but its about 6 months now with no  result. you guys are just tossing me back and forth whenever i ask for update.\", {\"entities\": [(87, 95, \"feedback\"), (50, 57, \"pa code\")]}),\n",
        "    (\"All basic care for children has been deleted from the benefits.\", {\"entities\": [(0, 12, \"Responsivenss\"), (35, 49, \"health benefits\")]}),\n",
        "    (\"Staffs are accommodating and always willing to help. Customer service and follow up is good as well\", {\"entities\": [(0, 13, \"staff attitude\"), (59, 75, \"Responsivenss\")]}),\n",
        "    (\"I chose that because when something is good you comment that is good. reliance hmo is one of the best HMO so far, when you call they answer as fast as possible, so i want to use this opportunity to say a very big thank you to all the staffs of reliance hmo thanks and God bless you all amen.\", {\"entities\": [(0, 13, \"staff attitude\"), (135, 148, \"health benefits\")]}),\n",
        "    (\"My son was ill and ended up paying all the bills\", {\"entities\": [(0, 19, \"medication\"), (44, 59, \"health benefits\")]}),\n",
        "    (\"I was recommended for a PTA and tympomometry test. Shockingly i was told this was not covered by Reliance.\", {\"entities\": [(25, 43, \"medication\"), (92, 104, \"health benefits\")]}),\n",
        "    (\"The experience I had with you guys when I was admitted was terrible. I was in excruciating pain and for four days Reliance did not approve Oral Morphine drug for the hospital to manage the postop pain I was having. I had to resort to verbally abusing your customer care representative which was unlike me.\", {\"entities\": [(105, 112, \"feedback\"), (147, 160, \"health benefits\")]}),\n",
        "    (\"I CHOSE IT BECAUSE ANY TIME I GO FOR TREATMENT OR TAKE ANY OF MY FAMILY THERE FOR TREATMENT, THE RECEPTION IS ALWAYS GREAT AND THEY ARE ALWAYS QUICK TO ATTEND TO US WITHOUT ANY DELAY.\", {\"entities\": [(112, 122, \"staff attitude\"), (146, 160, \"health benefits\")]}),\n",
        "    (\"Your customer service and feedback/update is poor\", {\"entities\": [(5, 22, \"Responsivenss\"), (27, 34, \"feedback\")]}),\n",
        "    (\"Please do include dental and eye care into your area of concern.\", {\"entities\": [(22, 29, \"medication\"), (0, 21, \"health benefits\")]}),\n",
        "    (\"Just refund me my money for the MMR covered by my organization’s package\", {\"entities\": [(0, 17, \"health benefits\"), (25, 41, \"feedback\")]}),\n",
        "    (\"Efficiency and the timely responses of the customer care staff. Also available of wide range of hospital for customers access\", {\"entities\": [(0, 11, \"medication\"), (49, 65, \"Responsivenss\")]}),\n",
        "    (\"The team doesn't have enough secondary health care providers. The sole focus is on medical issues that I really do not need. Your facilities provide low quality eye glasses and might need to pay as much as 50K in addition to get what suits you. What I'm about to say now is outside the scope of the services you provide, but I would love if  you could partner up with sport facilities like swimming centres not just gyms. Thank you. My regards\", {\"entities\": [(97, 111, \"medication\"), (0, 60, \"health benefits\")]}),\n",
        "]"
      ],
      "metadata": {
        "id": "e2KDkmei0E7x"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "db = DocBin() # create a DocBin object\n",
        "\n",
        "for text, annot in tqdm(TRAIN_DATA): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--FKT4BAv4i0",
        "outputId": "7c5433b7-4f74-4093-cb6b-e0559e9bea21"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [00:00<00:00, 1455.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db.to_disk(\"./train.spacy\") # save the docbin object"
      ],
      "metadata": {
        "id": "1n3ITYecv4gH"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZqMLTePv4dd",
        "outputId": "56a8be41-f451-4bfb-b4f7-3e9a514d5b5a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQweAa3-0564",
        "outputId": "4ba4fac7-c6a7-4e6a-909c-3613d7395d3d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     49.80    4.72    3.19    9.09    0.05\n",
            " 33     200        472.79   2199.61   98.46  100.00   96.97    0.98\n",
            " 74     400          0.34      2.36   98.46  100.00   96.97    0.98\n",
            "124     600          0.00      0.00   98.46  100.00   96.97    0.98\n",
            "187     800          0.00      0.00   98.46  100.00   96.97    0.98\n",
            "262    1000          0.00      0.00   98.46  100.00   96.97    0.98\n",
            "362    1200          0.00      0.00   98.46  100.00   96.97    0.98\n",
            "462    1400          0.00      0.00   98.46  100.00   96.97    0.98\n",
            "613    1600          0.00      0.00   98.46  100.00   96.97    0.98\n",
            "813    1800          0.00      0.00   98.46  100.00   96.97    0.98\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [\n",
        "    (\"Your responding is too slow\", {\"entities\": [(5, 14, \"Responsiveness\")]}),\n",
        "    (\"I haven't received any feedback yet.\", {\"entities\": [(19, 27, \"Feedback\")]}),\n",
        "    (\"The waiting time for appointments is excessive.\", {\"entities\": [(4, 15, \"Waiting_Time\")]}),\n",
        "    (\"The medication prescribed was ineffective.\", {\"entities\": [(4, 14, \"Medication\")]}),\n",
        "    (\"The health benefits provided by the plan are comprehensive.\", {\"entities\": [(4, 17, \"Health_Benefits\")]}),\n",
        "    (\"The staff attitude was very welcoming.\", {\"entities\": [(4, 16, \"Staff_Attitude\")]}),\n",
        "    (\"The PA code for the appointment is XYZ123.\", {\"entities\": [(4, 11, \"PA_Code\")]}),\n",
        "    (\"The responsiveness of the customer service team was commendable.\", {\"entities\": [(4, 17, \"Responsiveness\")]}),\n",
        "    (\"The staff were attentive and caring.\", {\"entities\": [(4, 8, \"Staff_Attitude\")]}),\n",
        "    (\"The medication provided did not address the issue.\", {\"entities\": [(4, 14, \"Medication\")]}),\n",
        "    (\"I appreciate the comprehensive health benefits offered.\", {\"entities\": [(23, 36, \"Health_Benefits\")]}),\n",
        "    (\"The waiting time at the clinic was minimal.\", {\"entities\": [(4, 15, \"Waiting_Time\")]}),\n",
        "    (\"The feedback received was constructive.\", {\"entities\": [(4, 11, \"Feedback\")]}),\n",
        "    (\"The PA code for the appointment was provided promptly.\", {\"entities\": [(4, 11, \"PA_Code\")]}),\n",
        "    (\"The responsiveness of the support team was impressive.\", {\"entities\": [(4, 17, \"Responsiveness\")]}),\n",
        "    (\"The staff demonstrated excellent attitude towards patients.\", {\"entities\": [(4, 18, \"Staff_Attitude\")]}),\n",
        "    (\"The medication prescribed was effective in alleviating symptoms.\", {\"entities\": [(4, 14, \"Medication\")]}),\n",
        "    (\"I'm satisfied with the health benefits provided by the insurance plan.\", {\"entities\": [(16, 29, \"Health_Benefits\")]}),\n",
        "    (\"The waiting time for appointments needs improvement.\", {\"entities\": [(4, 15, \"Waiting_Time\")]}),\n",
        "    (\"I appreciate the prompt feedback on my query.\", {\"entities\": [(23, 30, \"Feedback\")]}),\n",
        "    (\"The PA code for the appointment was not provided.\", {\"entities\": [(4, 11, \"PA_Code\")]}),\n",
        "    (\"The responsiveness of the team needs to be enhanced.\", {\"entities\": [(4, 17, \"Responsiveness\")]}),\n",
        "    (\"The staff exhibited a positive attitude towards patients.\", {\"entities\": [(4, 18, \"Staff_Attitude\")]}),\n",
        "    (\"The prescribed medication had adverse side effects.\", {\"entities\": [(4, 14, \"Medication\")]}),\n",
        "    (\"The health benefits offered by the plan are inadequate.\", {\"entities\": [(4, 17, \"Health_Benefits\")]}),\n",
        "    (\"The waiting time at the hospital was excessive.\", {\"entities\": [(4, 15, \"Waiting_Time\")]}),\n",
        "    (\"The feedback provided was helpful in improving the service.\", {\"entities\": [(4, 11, \"Feedback\")]}),\n",
        "    (\"The PA code for the appointment was incorrect.\", {\"entities\": [(4, 11, \"PA_Code\")]}),\n",
        "    (\"The responsiveness of the team was unsatisfactory.\", {\"entities\": [(4, 17, \"Responsiveness\")]}),\n",
        "    (\"The staff need to improve their attitude towards patients.\", {\"entities\": [(4, 18, \"Staff_Attitude\")]}),\n",
        "    (\"The prescribed medication did not address the issue effectively.\", {\"entities\": [(4, 14, \"Medication\")]}),\n",
        "    (\"The health benefits provided by the plan are satisfactory.\", {\"entities\": [(4, 17, \"Health_Benefits\")]}),\n",
        "    (\"The waiting time for appointments is reasonable.\", {\"entities\": [(4, 15, \"Waiting_Time\")]}),\n",
        "    (\"I received prompt feedback on my query.\", {\"entities\": [(16, 23, \"Feedback\")]}),\n",
        "    (\"The PA code for the appointment was provided without delay.\", {\"entities\": [(4, 11, \"PA_Code\")]}),\n",
        "    (\"The team's responsiveness needs improvement.\", {\"entities\": [(6, 19, \"Responsiveness\")]}),\n",
        "    (\"The staff's attitude towards patients needs to be more welcoming.\", {\"entities\": [(6, 18, \"Staff_Attitude\")]}),\n",
        "    (\"The prescribed medication caused allergic reactions.\", {\"entities\": [(4, 14, \"Medication\")]}),\n",
        "    (\"The health benefits provided by the plan are subpar.\", {\"entities\": [(4, 17, \"Health_Benefits\")]}),\n",
        "    (\"The waiting time for appointments is too long.\", {\"entities\": [(4, 15, \"Waiting_Time\")]}),\n",
        "    (\"The feedback received was valuable.\", {\"entities\": [(4, 11, \"Feedback\")]}),\n",
        "    (\"The PA code for the appointment was not provided on time.\", {\"entities\": [(4, 11, \"PA_Code\")]}),\n",
        "    (\"The responsiveness of the team needs urgent attention.\", {\"entities\": [(4, 17, \"Responsiveness\")]}),\n",
        "    (\"The staff's attitude towards patients was unacceptable.\", {\"entities\": [(6, 18, \"Staff_Attitude\")]}),\n",
        "    (\"The prescribed medication did not produce the desired results.\", {\"entities\": [(4, 14, \"Medication\")]}),\n",
        "    (\"The health benefits provided by the plan are excellent.\", {\"entities\": [(4, 17, \"Health_Benefits\")]}),\n",
        "    (\"The waiting time for appointments is too short.\", {\"entities\": [(4, 15, \"Waiting_Time\")]}),\n",
        "    (\"I received timely feedback on my complaint.\", {\"entities\": [(16, 23, \"Feedback\")]}),\n",
        "    (\"The PA code for the appointment was provided promptly.\", {\"entities\": [(4, 11, \"PA_Code\")]}),\n",
        "    (\"The team's responsiveness exceeded my expectations.\", {\"entities\": [(6, 19, \"Responsiveness\")]}),\n",
        "    (\"The staff's attitude towards patients was commendable.\", {\"entities\": [(6, 18, \"Staff_Attitude\")]}),\n",
        "    (\"The prescribed medication effectively treated the condition.\", {\"entities\": [(4, 14, \"Medication\")]})\n",
        "]\n"
      ],
      "metadata": {
        "id": "1wkmKtxy05zn"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = [data[0] for data in test_data]\n"
      ],
      "metadata": {
        "id": "wPzPM0Q305ww"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"/content/output/model-best\")\n",
        "\n",
        "# Function to extract entities from text\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Compare extracted entities with actual entities\n",
        "for text, annotations in test_data:\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Actual Entities:\", annotations['entities'])\n",
        "    extracted_entities = extract_entities(text)\n",
        "    print(\"Extracted Entities:\", extracted_entities)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKg8-1D505t4",
        "outputId": "7a8af447-f1c8-4498-b546-0ec9b91c641b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Your responding is too slow\n",
            "Actual Entities: [(5, 14, 'Responsiveness')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: I haven't received any feedback yet.\n",
            "Actual Entities: [(19, 27, 'Feedback')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The waiting time for appointments is excessive.\n",
            "Actual Entities: [(4, 15, 'Waiting_Time')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The medication prescribed was ineffective.\n",
            "Actual Entities: [(4, 14, 'Medication')]\n",
            "Extracted Entities: [('The medication', 'health benefits')]\n",
            "\n",
            "Text: The health benefits provided by the plan are comprehensive.\n",
            "Actual Entities: [(4, 17, 'Health_Benefits')]\n",
            "Extracted Entities: [('The health benefits', 'health benefits')]\n",
            "\n",
            "Text: The staff attitude was very welcoming.\n",
            "Actual Entities: [(4, 16, 'Staff_Attitude')]\n",
            "Extracted Entities: [('The staff attitude', 'health benefits')]\n",
            "\n",
            "Text: The PA code for the appointment is XYZ123.\n",
            "Actual Entities: [(4, 11, 'PA_Code')]\n",
            "Extracted Entities: [('The PA code for', 'health benefits')]\n",
            "\n",
            "Text: The responsiveness of the customer service team was commendable.\n",
            "Actual Entities: [(4, 17, 'Responsiveness')]\n",
            "Extracted Entities: [('service team', 'Responsivenss')]\n",
            "\n",
            "Text: The staff were attentive and caring.\n",
            "Actual Entities: [(4, 8, 'Staff_Attitude')]\n",
            "Extracted Entities: [('The staff were', 'health benefits')]\n",
            "\n",
            "Text: The medication provided did not address the issue.\n",
            "Actual Entities: [(4, 14, 'Medication')]\n",
            "Extracted Entities: [('The medication', 'health benefits')]\n",
            "\n",
            "Text: I appreciate the comprehensive health benefits offered.\n",
            "Actual Entities: [(23, 36, 'Health_Benefits')]\n",
            "Extracted Entities: [('I appreciate the comprehensive health benefits offered.', 'medication')]\n",
            "\n",
            "Text: The waiting time at the clinic was minimal.\n",
            "Actual Entities: [(4, 15, 'Waiting_Time')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The feedback received was constructive.\n",
            "Actual Entities: [(4, 11, 'Feedback')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The PA code for the appointment was provided promptly.\n",
            "Actual Entities: [(4, 11, 'PA_Code')]\n",
            "Extracted Entities: [('The PA code for', 'health benefits')]\n",
            "\n",
            "Text: The responsiveness of the support team was impressive.\n",
            "Actual Entities: [(4, 17, 'Responsiveness')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The staff demonstrated excellent attitude towards patients.\n",
            "Actual Entities: [(4, 18, 'Staff_Attitude')]\n",
            "Extracted Entities: [('The staff demonstrated excellent', 'health benefits')]\n",
            "\n",
            "Text: The medication prescribed was effective in alleviating symptoms.\n",
            "Actual Entities: [(4, 14, 'Medication')]\n",
            "Extracted Entities: [('The medication', 'health benefits')]\n",
            "\n",
            "Text: I'm satisfied with the health benefits provided by the insurance plan.\n",
            "Actual Entities: [(16, 29, 'Health_Benefits')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The waiting time for appointments needs improvement.\n",
            "Actual Entities: [(4, 15, 'Waiting_Time')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: I appreciate the prompt feedback on my query.\n",
            "Actual Entities: [(23, 30, 'Feedback')]\n",
            "Extracted Entities: [('I appreciate the prompt feedback on my query.', 'medication')]\n",
            "\n",
            "Text: The PA code for the appointment was not provided.\n",
            "Actual Entities: [(4, 11, 'PA_Code')]\n",
            "Extracted Entities: [('The PA code for', 'health benefits')]\n",
            "\n",
            "Text: The responsiveness of the team needs to be enhanced.\n",
            "Actual Entities: [(4, 17, 'Responsiveness')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The staff exhibited a positive attitude towards patients.\n",
            "Actual Entities: [(4, 18, 'Staff_Attitude')]\n",
            "Extracted Entities: [('The staff exhibited a', 'health benefits')]\n",
            "\n",
            "Text: The prescribed medication had adverse side effects.\n",
            "Actual Entities: [(4, 14, 'Medication')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The health benefits offered by the plan are inadequate.\n",
            "Actual Entities: [(4, 17, 'Health_Benefits')]\n",
            "Extracted Entities: [('The health benefits', 'health benefits')]\n",
            "\n",
            "Text: The waiting time at the hospital was excessive.\n",
            "Actual Entities: [(4, 15, 'Waiting_Time')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The feedback provided was helpful in improving the service.\n",
            "Actual Entities: [(4, 11, 'Feedback')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The PA code for the appointment was incorrect.\n",
            "Actual Entities: [(4, 11, 'PA_Code')]\n",
            "Extracted Entities: [('The PA code for', 'health benefits')]\n",
            "\n",
            "Text: The responsiveness of the team was unsatisfactory.\n",
            "Actual Entities: [(4, 17, 'Responsiveness')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The staff need to improve their attitude towards patients.\n",
            "Actual Entities: [(4, 18, 'Staff_Attitude')]\n",
            "Extracted Entities: [('The staff need', 'health benefits')]\n",
            "\n",
            "Text: The prescribed medication did not address the issue effectively.\n",
            "Actual Entities: [(4, 14, 'Medication')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The health benefits provided by the plan are satisfactory.\n",
            "Actual Entities: [(4, 17, 'Health_Benefits')]\n",
            "Extracted Entities: [('The health benefits', 'health benefits')]\n",
            "\n",
            "Text: The waiting time for appointments is reasonable.\n",
            "Actual Entities: [(4, 15, 'Waiting_Time')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: I received prompt feedback on my query.\n",
            "Actual Entities: [(16, 23, 'Feedback')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The PA code for the appointment was provided without delay.\n",
            "Actual Entities: [(4, 11, 'PA_Code')]\n",
            "Extracted Entities: [('The PA code for', 'health benefits')]\n",
            "\n",
            "Text: The team's responsiveness needs improvement.\n",
            "Actual Entities: [(6, 19, 'Responsiveness')]\n",
            "Extracted Entities: [(\"The team's\", 'health benefits')]\n",
            "\n",
            "Text: The staff's attitude towards patients needs to be more welcoming.\n",
            "Actual Entities: [(6, 18, 'Staff_Attitude')]\n",
            "Extracted Entities: [(\"The staff's\", 'health benefits')]\n",
            "\n",
            "Text: The prescribed medication caused allergic reactions.\n",
            "Actual Entities: [(4, 14, 'Medication')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The health benefits provided by the plan are subpar.\n",
            "Actual Entities: [(4, 17, 'Health_Benefits')]\n",
            "Extracted Entities: [('The health benefits', 'health benefits')]\n",
            "\n",
            "Text: The waiting time for appointments is too long.\n",
            "Actual Entities: [(4, 15, 'Waiting_Time')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The feedback received was valuable.\n",
            "Actual Entities: [(4, 11, 'Feedback')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The PA code for the appointment was not provided on time.\n",
            "Actual Entities: [(4, 11, 'PA_Code')]\n",
            "Extracted Entities: [('The PA code for', 'health benefits')]\n",
            "\n",
            "Text: The responsiveness of the team needs urgent attention.\n",
            "Actual Entities: [(4, 17, 'Responsiveness')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The staff's attitude towards patients was unacceptable.\n",
            "Actual Entities: [(6, 18, 'Staff_Attitude')]\n",
            "Extracted Entities: [(\"The staff's\", 'health benefits')]\n",
            "\n",
            "Text: The prescribed medication did not produce the desired results.\n",
            "Actual Entities: [(4, 14, 'Medication')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The health benefits provided by the plan are excellent.\n",
            "Actual Entities: [(4, 17, 'Health_Benefits')]\n",
            "Extracted Entities: [('The health benefits', 'health benefits')]\n",
            "\n",
            "Text: The waiting time for appointments is too short.\n",
            "Actual Entities: [(4, 15, 'Waiting_Time')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: I received timely feedback on my complaint.\n",
            "Actual Entities: [(16, 23, 'Feedback')]\n",
            "Extracted Entities: []\n",
            "\n",
            "Text: The PA code for the appointment was provided promptly.\n",
            "Actual Entities: [(4, 11, 'PA_Code')]\n",
            "Extracted Entities: [('The PA code for', 'health benefits')]\n",
            "\n",
            "Text: The team's responsiveness exceeded my expectations.\n",
            "Actual Entities: [(6, 19, 'Responsiveness')]\n",
            "Extracted Entities: [(\"The team's\", 'health benefits')]\n",
            "\n",
            "Text: The staff's attitude towards patients was commendable.\n",
            "Actual Entities: [(6, 18, 'Staff_Attitude')]\n",
            "Extracted Entities: [(\"The staff's\", 'health benefits')]\n",
            "\n",
            "Text: The prescribed medication effectively treated the condition.\n",
            "Actual Entities: [(4, 14, 'Medication')]\n",
            "Extracted Entities: []\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cyxpohsbsNOw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}